{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Kinetic Core","text":"<p>The core engine for Salesforce AI agents. A comprehensive, production-ready Python library for Salesforce integration.</p> <p>Part of the KineticMCP ecosystem - AI-powered Salesforce integration tools by Antonio Trento</p> <p>[!IMPORTANT] Legal Disclaimer: This project is an independent open-source library and is not affiliated with, sponsored by, or endorsed by Salesforce, Inc. \"Salesforce\" is a trademark of Salesforce, Inc.</p> <p>[!WARNING] Deprecation Notice: The package <code>salesforce-toolkit</code> is deprecated. Please use <code>kinetic-core</code> instead.</p> <p> </p>"},{"location":"#features","title":"\ud83d\ude80 Features","text":""},{"location":"#core-capabilities","title":"Core Capabilities","text":"<ul> <li>\ud83d\udd10 Multiple Authentication Methods</li> <li>JWT Bearer Flow (recommended for production)</li> <li>OAuth 2.0 Password Flow</li> <li> <p>Environment-based configuration</p> </li> <li> <p>\ud83d\udcca Complete CRUD Operations</p> </li> <li>Works with any Salesforce object (standard or custom)</li> <li>Create, Read, Update, Delete, Upsert</li> <li>Bulk operations via Composite API</li> <li> <p>Query with automatic pagination</p> </li> <li> <p>\u26a1 Bulk API v2 Support (NEW in v2.0.0)</p> </li> <li>Process millions of records efficiently</li> <li>Full support for all Bulk API v2 operations</li> <li>Smart exponential backoff polling</li> <li>Progress tracking with callbacks</li> <li>Comprehensive per-record error reporting</li> <li> <p>Async job processing</p> </li> <li> <p>\ud83d\uddfa\ufe0f Flexible Field Mapping</p> </li> <li>Simple field renaming</li> <li>Value transformations with custom functions</li> <li>Default values</li> <li>Nested field access (dot notation)</li> <li> <p>Conditional mapping</p> </li> <li> <p>\ud83d\udd04 ETL Pipeline Framework</p> </li> <li>Configuration-driven sync pipelines</li> <li>Multiple sync modes (INSERT, UPDATE, UPSERT, DELETE)</li> <li>Batch processing</li> <li>Progress tracking with callbacks</li> <li> <p>Comprehensive error handling</p> </li> <li> <p>\ud83d\udcdd Production-Ready Logging</p> </li> <li>File and console output</li> <li>Automatic log rotation</li> <li>Colored console output</li> <li>Contextual logging</li> <li> <p>Configurable log levels</p> </li> <li> <p>\ud83d\udee0\ufe0f Command-Line Interface</p> </li> <li>Query, create, update, delete from terminal</li> <li>Run sync pipelines from YAML config</li> <li>Describe Salesforce objects</li> <li>Test authentication</li> </ul>"},{"location":"#installation","title":"\ud83d\udce6 Installation","text":""},{"location":"#from-pypi","title":"From PyPI","text":"<pre><code>pip install kinetic-core\n</code></pre>"},{"location":"#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/yourusername/kinetic-core.git\ncd kinetic-core\npip install -e .\n</code></pre>"},{"location":"#with-optional-dependencies","title":"With Optional Dependencies","text":"<pre><code># Database support\npip install kinetic-core[database]\n\n# Data manipulation (pandas, numpy)\npip install kinetic-core[data]\n\n# Development tools\npip install kinetic-core[dev]\n</code></pre>"},{"location":"#quick-start","title":"\ud83c\udfaf Quick Start","text":""},{"location":"#1-setup-environment-variables","title":"1. Setup Environment Variables","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># JWT Authentication (Recommended)\nSF_CLIENT_ID=3MVG9...\nSF_USERNAME=user@example.com.sandbox\nSF_PRIVATE_KEY_PATH=/path/to/server.key\nSF_LOGIN_URL=https://test.salesforce.com\n\n# Logging\n# Logging\nLOG_DIR=./logs\nLOG_LEVEL=INFO\n\n# Optional: Salesforce API Version\nSF_API_VERSION=v62.0  # Defaults to v62.0 if not set\n</code></pre>"},{"location":"#2-basic-usage","title":"2. Basic Usage","text":"<pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\n\n# Authenticate\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\n\n# Create client\nclient = SalesforceClient(session)\n\n# Create a record\naccount_id = client.create(\"Account\", {\n    \"Name\": \"ACME Corporation\",\n    \"Industry\": \"Technology\"\n})\n\n# Query records\naccounts = client.query(\"SELECT Id, Name FROM Account LIMIT 10\")\n\n# Update a record\nclient.update(\"Account\", account_id, {\"Phone\": \"555-1234\"})\n\n# Delete a record\nclient.delete(\"Account\", account_id)\n</code></pre>"},{"location":"#3-data-sync-pipeline","title":"3. Data Sync Pipeline","text":"<pre><code>from kinetic_core import (\n    JWTAuthenticator,\n    SalesforceClient,\n    FieldMapper,\n    SyncPipeline,\n    SyncMode\n)\n\n# Authenticate\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\n# Define field mapping\nmapper = FieldMapper({\n    \"customer_name\": \"Name\",\n    \"customer_email\": \"Email\",\n    \"industry_code\": (\"Industry\", lambda x: x.title())  # Transform\n})\n\n# Create pipeline\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT,\n    batch_size=200\n)\n\n# Sync data\nsource_data = [\n    {\"customer_name\": \"ACME\", \"customer_email\": \"info@acme.com\"},\n    {\"customer_name\": \"Globex\", \"customer_email\": \"contact@globex.com\"}\n]\n\nresult = pipeline.sync(source_data)\nprint(f\"Synced {result.success_count}/{result.total_records} records\")\n</code></pre>"},{"location":"#4-bulk-api-v2-high-volume-operations","title":"4. Bulk API v2 (High-Volume Operations)","text":"<p>\u2728 NEW in v2.0.0 - Process millions of records efficiently:</p> <pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\n\n# Authenticate\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\n# Bulk insert 10,000 records\nrecords = [\n    {\"Name\": f\"Account {i}\", \"Industry\": \"Technology\"}\n    for i in range(10000)\n]\n\nresult = client.bulk.insert(\"Account\", records)\nprint(f\"\u2713 Success: {result.success_count}\")\nprint(f\"\u2717 Failed: {result.failed_count}\")\n\n# Bulk query for large exports\nquery = \"SELECT Id, Name FROM Account WHERE CreatedDate = THIS_YEAR\"\nresult = client.bulk.query(query)\nprint(f\"Retrieved {result.record_count} records\")\n\n# Bulk update with external ID\nupdates = [\n    {\"External_Key__c\": \"EXT001\", \"Name\": \"Updated Name 1\"},\n    {\"External_Key__c\": \"EXT002\", \"Name\": \"Updated Name 2\"}\n]\nresult = client.bulk.upsert(\"Account\", updates, \"External_Key__c\")\n</code></pre> <p>Key Features: - \u26a1 Up to 150 million records per job - \ud83d\udd04 Async processing with progress tracking - \ud83d\udcca Detailed per-record error reporting - \ud83c\udfaf Smart retry and exponential backoff</p> <p>\ud83d\udcd6 Complete Bulk API Documentation \u2192</p>"},{"location":"#5-command-line-interface","title":"5. Command-Line Interface","text":"<pre><code># Test authentication\nsf-toolkit auth --method jwt\n\n# Query Salesforce\nsf-toolkit query \"SELECT Id, Name FROM Account LIMIT 10\"\n\n# Create a record\nsf-toolkit create Account --data '{\"Name\": \"ACME Corp\"}'\n\n# Run a sync pipeline\nsf-toolkit sync --config sync_config.yaml\n\n# Describe an object\nsf-toolkit describe Account --fields\n</code></pre>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":""},{"location":"#complete-guides","title":"\ud83d\udcd6 Complete Guides","text":""},{"location":"#bulk-api-v2-new","title":"Bulk API v2 (NEW)","text":"<ul> <li>Complete API Reference - Full API documentation</li> <li>Quick Start Guide - Get started in 5 minutes</li> <li>Practical Examples - Real-world use cases</li> </ul>"},{"location":"#core-documentation","title":"Core Documentation","text":"<ul> <li>User Guide - Complete usage documentation</li> <li>Quick Start - Getting started guide</li> <li>Salesforce Setup - Configure Salesforce</li> <li>Testing Guide - Test your integration</li> <li>Docker Guide - Containerized deployment</li> </ul>"},{"location":"#authentication","title":"Authentication","text":""},{"location":"#jwt-bearer-flow-recommended","title":"JWT Bearer Flow (Recommended)","text":"<pre><code>from kinetic_core import JWTAuthenticator\n\n# From environment variables\nauth = JWTAuthenticator.from_env()\n\n# Or manual configuration\nauth = JWTAuthenticator(\n    client_id=\"3MVG9...\",\n    username=\"user@example.com\",\n    private_key_path=\"/path/to/server.key\",\n    login_url=\"https://test.salesforce.com\"\n)\n\nsession = auth.authenticate()\n</code></pre>"},{"location":"#oauth-password-flow","title":"OAuth Password Flow","text":"<pre><code>from kinetic_core import OAuthAuthenticator\n\n# From environment variables\nauth = OAuthAuthenticator.from_env()\n\n# Or manual configuration\nauth = OAuthAuthenticator(\n    client_id=\"3MVG9...\",\n    client_secret=\"1234567890ABCDEF\",\n    username=\"user@example.com\",\n    password=\"your_password\",\n    security_token=\"ABC123\",\n    login_url=\"https://login.salesforce.com\"\n)\n\nsession = auth.authenticate()\n</code></pre>"},{"location":"#crud-operations","title":"CRUD Operations","text":""},{"location":"#create-records","title":"Create Records","text":"<pre><code># Single record\naccount_id = client.create(\"Account\", {\n    \"Name\": \"ACME Corp\",\n    \"Industry\": \"Technology\"\n})\n\n# Batch create (up to 200 records)\nresults = client.create_batch(\"Contact\", [\n    {\"FirstName\": \"John\", \"LastName\": \"Doe\"},\n    {\"FirstName\": \"Jane\", \"LastName\": \"Smith\"}\n])\n</code></pre>"},{"location":"#query-records","title":"Query Records","text":"<pre><code># SOQL query with automatic pagination\naccounts = client.query(\n    \"SELECT Id, Name, Industry FROM Account WHERE Industry = 'Technology'\"\n)\n\n# Query first result\naccount = client.query_one(\n    \"SELECT Id, Name FROM Account WHERE Name = 'ACME Corp'\"\n)\n\n# Get by ID\naccount = client.get(\"Account\", \"001XXXXXXXXXXXX\")\n\n# Count records\ntotal = client.count(\"Account\")\ntech_count = client.count(\"Account\", \"Industry = 'Technology'\")\n</code></pre>"},{"location":"#update-records","title":"Update Records","text":"<pre><code># Update by ID\nclient.update(\"Account\", \"001XXXXXXXXXXXX\", {\n    \"Phone\": \"555-9999\",\n    \"Industry\": \"Manufacturing\"\n})\n\n# Upsert (requires External ID field)\naccount_id = client.upsert(\n    \"Account\",\n    \"External_Key__c\",\n    \"EXT-12345\",\n    {\"Name\": \"ACME Corp\", \"Industry\": \"Tech\"}\n)\n</code></pre>"},{"location":"#delete-records","title":"Delete Records","text":"<pre><code>client.delete(\"Account\", \"001XXXXXXXXXXXX\")\n</code></pre>"},{"location":"#field-mapping","title":"Field Mapping","text":""},{"location":"#basic-mapping","title":"Basic Mapping","text":"<pre><code>from kinetic_core import FieldMapper\n\nmapper = FieldMapper({\n    \"first_name\": \"FirstName\",\n    \"last_name\": \"LastName\",\n    \"email\": \"Email\"\n})\n\nsource = {\"first_name\": \"John\", \"last_name\": \"Doe\", \"email\": \"john@example.com\"}\ntarget = mapper.transform(source)\n# Result: {\"FirstName\": \"John\", \"LastName\": \"Doe\", \"Email\": \"john@example.com\"}\n</code></pre>"},{"location":"#advanced-mapping-with-transformations","title":"Advanced Mapping with Transformations","text":"<pre><code>mapper = FieldMapper({\n    # Simple rename\n    \"customer_name\": \"Name\",\n\n    # With transformation\n    \"email\": (\"Email\", lambda x: x.lower()),\n\n    # With default value\n    \"status\": (\"Status__c\", None, \"Active\"),\n\n    # With both transformation and default\n    \"created_at\": (\n        \"CreatedDate\",\n        lambda x: x.strftime(\"%Y-%m-%d\") if x else None,\n        datetime.now().strftime(\"%Y-%m-%d\")\n    ),\n\n    # Nested field access\n    \"address.city\": \"BillingCity\",\n    \"address.state\": \"BillingState\"\n})\n</code></pre>"},{"location":"#built-in-transformations","title":"Built-in Transformations","text":"<pre><code># Available via YAML configuration\ntransforms = [\n    \"lowercase\",    # Convert to lowercase\n    \"uppercase\",    # Convert to uppercase\n    \"strip\",        # Strip whitespace\n    \"int\",          # Convert to integer\n    \"float\",        # Convert to float\n    \"bool\",         # Convert to boolean\n    \"date_iso\",     # Format date as YYYY-MM-DD\n    \"datetime_iso\"  # Format datetime as ISO 8601\n]\n</code></pre>"},{"location":"#sync-pipeline","title":"Sync Pipeline","text":""},{"location":"#basic-pipeline","title":"Basic Pipeline","text":"<pre><code>from kinetic_core import SyncPipeline, SyncMode\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT,\n    batch_size=200,\n    stop_on_error=False\n)\n\nresult = pipeline.sync(source_data)\n</code></pre>"},{"location":"#pipeline-with-callbacks","title":"Pipeline with Callbacks","text":"<pre><code>def on_record_success(record, salesforce_id):\n    print(f\"\u2713 Synced: {record['name']} -&gt; {salesforce_id}\")\n\ndef on_record_error(record, error):\n    print(f\"\u2717 Failed: {record['name']} - {error}\")\n\ndef on_batch_complete(batch_num, total_batches, result):\n    print(f\"Batch {batch_num}/{total_batches} done\")\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT,\n    callbacks={\n        \"on_record_success\": on_record_success,\n        \"on_record_error\": on_record_error,\n        \"on_batch_complete\": on_batch_complete\n    }\n)\n</code></pre>"},{"location":"#pipeline-from-yaml-configuration","title":"Pipeline from YAML Configuration","text":"<pre><code># sync_config.yaml\nsource:\n  type: json\n  path: data/accounts.json\n\npipeline:\n  sobject: Account\n  mode: upsert\n  external_id_field: External_Key__c\n  batch_size: 200\n  mapping:\n    customer_name: Name\n    customer_email: Email\n    industry_code:\n      target: Industry\n      transform: uppercase\n</code></pre> <pre><code>import yaml\nfrom kinetic_core import SyncPipeline\n\nwith open(\"sync_config.yaml\") as f:\n    config = yaml.safe_load(f)\n\npipeline = SyncPipeline.from_config(config[\"pipeline\"], client)\nresult = pipeline.sync(source_data)\n</code></pre>"},{"location":"#logging","title":"Logging","text":""},{"location":"#basic-logger-setup","title":"Basic Logger Setup","text":"<pre><code>from kinetic_core.logging import setup_logger\nimport logging\n\nlogger = setup_logger(\n    name=\"my_app\",\n    log_dir=\"./logs\",\n    log_level=logging.INFO,\n    console_colors=True\n)\n\nlogger.info(\"Application started\")\nlogger.error(\"An error occurred\", exc_info=True)\n</code></pre>"},{"location":"#contextual-logging","title":"Contextual Logging","text":"<pre><code>from kinetic_core.logging import ContextLogger, setup_logger\n\nbase_logger = setup_logger(\"my_app\")\ncontext_logger = ContextLogger(base_logger, context={\n    \"transaction_id\": \"TX-12345\",\n    \"user_id\": \"user@example.com\"\n})\n\ncontext_logger.info(\"Processing record\")\n# Logs: \"Processing record [transaction_id=TX-12345, user_id=user@example.com]\"\n</code></pre>"},{"location":"#utilities","title":"Utilities","text":"<pre><code>from kinetic_core.utils import (\n    sanitize_soql,\n    build_soql_query,\n    validate_salesforce_id,\n    format_datetime_for_sf,\n    generate_external_id,\n    batch_records\n)\n\n# Sanitize SOQL\nsafe_name = sanitize_soql(\"O'Brien &amp; Associates\")\n\n# Build SOQL query\nquery = build_soql_query(\n    sobject=\"Account\",\n    fields=[\"Id\", \"Name\", \"Industry\"],\n    where=\"Industry = 'Technology'\",\n    limit=100\n)\n\n# Validate Salesforce ID\nif validate_salesforce_id(\"001XXXXXXXXXXXXXXX\"):\n    print(\"Valid ID\")\n\n# Format datetime\nsf_datetime = format_datetime_for_sf(datetime.now())\n\n# Generate external ID\next_id = generate_external_id(\"CUST\", timestamp=True)\n# Returns: \"CUST-20251205-103000-abc123\"\n\n# Batch records\nbatches = batch_records(records, batch_size=200)\n</code></pre>"},{"location":"#examples","title":"\ud83c\udfa8 Examples","text":"<p>The <code>examples/</code> directory contains comprehensive examples:</p> <ol> <li>01_basic_authentication.py - Authentication methods</li> <li>02_crud_operations.py - CRUD operations</li> <li>03_data_sync_pipeline.py - Data synchronization</li> </ol> <p>Run an example: <pre><code>cd examples\npython 01_basic_authentication.py\n</code></pre></p>"},{"location":"#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"#environment-variables","title":"Environment Variables","text":"<p>Copy config/.env.example to <code>.env</code> and configure:</p> <pre><code># Salesforce\nSF_CLIENT_ID=your_consumer_key\nSF_USERNAME=user@example.com\nSF_PRIVATE_KEY_PATH=/path/to/server.key\nSF_LOGIN_URL=https://test.salesforce.com\n\n# Logging\nLOG_DIR=./logs\nLOG_LEVEL=INFO\n</code></pre>"},{"location":"#yaml-configuration","title":"YAML Configuration","text":"<p>See config/sync_config_example.yaml for pipeline configuration.</p>"},{"location":"#testing","title":"\ud83e\uddea Testing","text":"<pre><code># Install dev dependencies\npip install -e \".[dev]\"\n\n# Run tests\npytest\n\n# Run tests with coverage\npytest --cov=salesforce_toolkit --cov-report=html\n\n# Run linter\nflake8 salesforce_toolkit/\n\n# Run type checker\nmypy salesforce_toolkit/\n\n# Format code\nblack salesforce_toolkit/\n</code></pre>"},{"location":"#api-reference","title":"\ud83d\udcd6 API Reference","text":""},{"location":"#core-classes","title":"Core Classes","text":"<ul> <li><code>SalesforceSession</code> - Authenticated session object</li> <li><code>SalesforceClient</code> - Main API client for CRUD operations</li> <li><code>JWTAuthenticator</code> - JWT Bearer Flow authentication</li> <li><code>OAuthAuthenticator</code> - OAuth Password Flow authentication</li> <li><code>FieldMapper</code> - Field mapping and transformation engine</li> <li><code>SyncPipeline</code> - ETL pipeline for data synchronization</li> </ul>"},{"location":"#modules","title":"Modules","text":"<ul> <li><code>salesforce_toolkit.auth</code> - Authentication providers</li> <li><code>salesforce_toolkit.core</code> - Core client and session management</li> <li><code>salesforce_toolkit.mapping</code> - Field mapping engine</li> <li><code>salesforce_toolkit.pipeline</code> - Sync pipeline framework</li> <li><code>salesforce_toolkit.logging</code> - Logging system</li> <li><code>salesforce_toolkit.utils</code> - Utility functions</li> </ul>"},{"location":"#roadmap","title":"\ud83d\udee3\ufe0f Roadmap","text":"<ul> <li>[ ] Support for Bulk API 2.0 (async bulk operations)</li> <li>[ ] Metadata API support (deploy/retrieve)</li> <li>[ ] Streaming API (PushTopic, Generic Streaming)</li> <li>[ ] Built-in retry mechanism with exponential backoff</li> <li>[ ] Dry-run mode for pipelines</li> <li>[ ] Performance monitoring and metrics</li> <li>[ ] Integration with popular ORMs (SQLAlchemy, Django)</li> </ul>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Contributions are welcome! Please follow these steps:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li> <li>Commit your changes (<code>git commit -m 'Add amazing feature'</code>)</li> <li>Push to the branch (<code>git push origin feature/amazing-feature</code>)</li> <li>Open a Pull Request</li> </ol>"},{"location":"#development-setup","title":"Development Setup","text":"<pre><code>git clone https://github.com/yourusername/kinetic-core.git\ncd kinetic-core\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -e \".[dev]\"\n</code></pre>"},{"location":"#part-of-kineticmcp","title":"\ud83c\udf10 Part of KineticMCP","text":"<p>Kinetic Core is the foundational library powering KineticMCP, an AI-powered Salesforce integration platform.</p> <p>KineticMCP combines the capabilities of Kinetic Core with the Model Context Protocol (MCP) to enable intelligent automation, natural language interactions, and advanced data management for Salesforce.</p> <ul> <li>\ud83c\udf10 Website: kineticmcp.com</li> <li>\ud83e\udd16 AI Integration: Natural language Salesforce operations</li> <li>\ud83d\udd0c MCP Protocol: Seamless integration with AI assistants</li> <li>\ud83d\udcca Advanced Analytics: AI-driven insights and reporting</li> </ul> <p>Built and maintained by Antonio Trento - connecting Salesforce with the future of AI.</p>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p> <p>Copyright (c) 2025 Antonio Trento. All rights reserved.</p> <p>See COPYRIGHT for detailed attribution and trademark information.</p>"},{"location":"#author","title":"\ud83d\udc64 Author","text":"<p>Antonio Trento</p> <ul> <li>GitHub: @antoniotrento</li> <li>LinkedIn: Antonio Trento</li> <li>Portfolio: Salesforce Toolkit Case Study</li> </ul>"},{"location":"#acknowledgments","title":"\ud83d\ude4f Acknowledgments","text":"<ul> <li>Inspired by Simple Salesforce</li> <li>Built with Requests</li> <li>Powered by PyJWT</li> </ul>"},{"location":"#project-stats","title":"\ud83d\udcca Project Stats","text":"<p>   Made with \u2764\ufe0f by Antonio Trento </p>"},{"location":"BULK_API_ANALYSIS/","title":"Bulk API Analysis - Kinetic Core","text":"<p>Data Analisi: 2025-12-28 Versione Kinetic Core: 1.1.0 Analista: Code Review Completo</p>"},{"location":"BULK_API_ANALYSIS/#domanda","title":"\ud83c\udfaf DOMANDA","text":"<p>Le affermazioni di ChatGPT sul supporto Bulk API in Kinetic Core sono corrette?</p>"},{"location":"BULK_API_ANALYSIS/#risposta-si-sono-corrette","title":"\u2705 RISPOSTA: S\u00cc, SONO CORRETTE","text":"<p>Dopo aver analizzato il codice sorgente di Kinetic Core, confermo che ChatGPT ha ragione:</p>"},{"location":"BULK_API_ANALYSIS/#stato-attuale-verificato","title":"\ud83d\udcca STATO ATTUALE VERIFICATO","text":"Feature Presente in Kinetic Core Salesforce Bulk API v2 Endpoint usato <code>/composite/sobjects</code> <code>/jobs/ingest</code> Tipo chiamata Sincrona Asincrona (job-based) Formato JSON CSV o JSON Limite record ~200 per batch Milioni Job management \u274c No \u2705 S\u00ec Polling status \u274c No \u2705 S\u00ec File upload \u274c No \u2705 S\u00ec"},{"location":"BULK_API_ANALYSIS/#codice-attuale-verificato","title":"\ud83d\udd0d CODICE ATTUALE (VERIFICATO)","text":""},{"location":"BULK_API_ANALYSIS/#cosa-usa-kinetic-core-oggi","title":"Cosa usa Kinetic Core oggi","text":"<p>File: <code>kinetic_core/core/client.py:139</code></p> <pre><code>def create_batch(self, sobject: str, records: List[Dict[str, Any]]):\n    \"\"\"Create multiple records in a single request (composite API).\"\"\"\n    url = f\"{self.session.base_url}/composite/sobjects\"  # \ud83d\udc48 COMPOSITE API\n\n    payload = {\n        \"allOrNone\": False,\n        \"records\": [{\"attributes\": {\"type\": sobject}, **record} for record in records]\n    }\n\n    response = requests.post(url, headers=headers, json=payload, timeout=60)\n</code></pre> <p>Questo \u00e8 Composite API, NON Bulk API!</p>"},{"location":"BULK_API_ANALYSIS/#differenze-chiave","title":"\ud83d\udccb DIFFERENZE CHIAVE","text":""},{"location":"BULK_API_ANALYSIS/#composite-api-quello-che-hai-ora","title":"Composite API (quello che hai ORA) \u2705","text":"<pre><code># Endpoint\nPOST /services/data/v62.0/composite/sobjects\n\n# Payload\n{\n  \"allOrNone\": false,\n  \"records\": [\n    {\"attributes\": {\"type\": \"Account\"}, \"Name\": \"Test 1\"},\n    {\"attributes\": {\"type\": \"Account\"}, \"Name\": \"Test 2\"}\n  ]\n}\n\n# Limite: ~200 record\n# Tipo: Sincrono\n# Risposta: Immediata\n</code></pre>"},{"location":"BULK_API_ANALYSIS/#bulk-api-v2-quello-che-non-hai","title":"Bulk API v2 (quello che NON hai) \u274c","text":"<pre><code># 1. Create Job\nPOST /services/data/v62.0/jobs/ingest\n{\n  \"object\": \"Account\",\n  \"operation\": \"insert\",\n  \"contentType\": \"CSV\"\n}\n\n# 2. Upload CSV\nPUT /services/data/v62.0/jobs/ingest/{jobId}/batches\nContent-Type: text/csv\n\nId,Name,Industry\n001...,ACME Corp,Technology\n001...,Globex Inc,Manufacturing\n\n# 3. Close Job\nPATCH /services/data/v62.0/jobs/ingest/{jobId}\n{\"state\": \"UploadComplete\"}\n\n# 4. Poll Status\nGET /services/data/v62.0/jobs/ingest/{jobId}\n\n# Limite: Milioni di record\n# Tipo: Asincrono\n# Risposta: Polling richiesto\n</code></pre>"},{"location":"BULK_API_ANALYSIS/#test-pratico","title":"\ud83e\uddea TEST PRATICO","text":"<p>Ho eseguito i test di integrazione e posso confermare:</p>"},{"location":"BULK_API_ANALYSIS/#cosa-funziona","title":"\u2705 Cosa Funziona","text":"<pre><code># Test: test_12_create_batch_accounts\nresults = client.create_batch(\"Account\", [\n    {\"Name\": \"Batch 1\"},\n    {\"Name\": \"Batch 2\"},\n    {\"Name\": \"Batch 3\"}\n])\n\n# RISULTATO: \u2705 PASSED\n# Tempo: 0.5 secondi\n# Record: 3/3 creati\n# Metodo: Composite API\n</code></pre>"},{"location":"BULK_API_ANALYSIS/#cosa-non-funziona-perche-non-esiste","title":"\u274c Cosa NON Funziona (perch\u00e9 non esiste)","text":"<pre><code># Questo NON esiste in Kinetic Core\njob_id = client.bulk.create_job(\"Account\", \"insert\")  # \u274c AttributeError\nclient.bulk.upload_csv(job_id, csv_data)             # \u274c Non implementato\nclient.bulk.close_job(job_id)                        # \u274c Non implementato\nresult = client.bulk.get_results(job_id)             # \u274c Non implementato\n</code></pre>"},{"location":"BULK_API_ANALYSIS/#performance-verificata","title":"\ud83d\udcca PERFORMANCE VERIFICATA","text":""},{"location":"BULK_API_ANALYSIS/#test-batch-performance-dai-nostri-test","title":"Test Batch Performance (dai nostri test)","text":"<pre><code>Test: test_90_batch_performance\nRecords: 10 accounts\nTime: 0.61 seconds\nThroughput: 16.32 records/second\nMethod: Composite API \u2705\nStatus: PASSED \u2705\n</code></pre> <p>Questo \u00e8 ottimo per &lt;1000 record, MA:</p>"},{"location":"BULK_API_ANALYSIS/#scenario-bulk-api-cosa-servirebbe-per-grandi-volumi","title":"Scenario Bulk API (cosa servirebbe per grandi volumi)","text":"<pre><code>Records: 100,000 accounts\nEstimated Time with Composite: 1h 42min (100k / 16 = 6,250 secondi)\nEstimated Time with Bulk API v2: 2-5 minutes\n</code></pre> <p>Differenza: 20-50x pi\u00f9 veloce con Bulk API!</p>"},{"location":"BULK_API_ANALYSIS/#verifica-affermazioni-chatgpt","title":"\ud83c\udfaf VERIFICA AFFERMAZIONI CHATGPT","text":""},{"location":"BULK_API_ANALYSIS/#affermazione-1-kinetic-core-non-supporta-bulk-api","title":"Affermazione 1: \"kinetic-core non supporta Bulk API\"","text":"<p>\u2705 VERO - Verificato nel codice: - \u274c Nessun file <code>bulk.py</code> - \u274c Nessun endpoint <code>/jobs/ingest</code> - \u274c Nessuna funzione job-based - \u2705 Solo Composite API presente</p>"},{"location":"BULK_API_ANALYSIS/#affermazione-2-usa-composite-api-non-bulk-api","title":"Affermazione 2: \"Usa Composite API, non Bulk API\"","text":"<p>\u2705 VERO - Codice conferma: <pre><code># File: client.py:139\nurl = f\"{self.session.base_url}/composite/sobjects\"\n</code></pre></p>"},{"location":"BULK_API_ANALYSIS/#affermazione-3-limite-200-record-per-batch","title":"Affermazione 3: \"Limite ~200 record per batch\"","text":"<p>\u2705 VERO - Documentazione Salesforce: - Composite API: max 200 subrequests - Bulk API v2: praticamente illimitato</p>"},{"location":"BULK_API_ANALYSIS/#affermazione-4-non-ha-job-asincroni-polling-csv-upload","title":"Affermazione 4: \"Non ha job asincroni, polling, CSV upload\"","text":"<p>\u2705 VERO - Codice conferma assenza di: - \u274c Job creation - \u274c Status polling - \u274c CSV serialization/upload - \u274c Result fetching asincrono</p>"},{"location":"BULK_API_ANALYSIS/#struttura-codice-attuale","title":"\ud83d\udcc1 STRUTTURA CODICE ATTUALE","text":"<pre><code>kinetic_core/\n\u251c\u2500\u2500 auth/\n\u2502   \u251c\u2500\u2500 jwt_auth.py         \u2705 JWT auth\n\u2502   \u2514\u2500\u2500 oauth_auth.py       \u2705 OAuth auth\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 client.py           \u2705 REST + Composite API\n\u2502   \u2514\u2500\u2500 session.py          \u2705 Session management\n\u251c\u2500\u2500 mapping/\n\u2502   \u2514\u2500\u2500 field_mapper.py     \u2705 Field mapping\n\u251c\u2500\u2500 pipeline/\n\u2502   \u2514\u2500\u2500 sync_pipeline.py    \u2705 ETL pipeline\n\u251c\u2500\u2500 logging/\n\u2502   \u2514\u2500\u2500 logger.py           \u2705 Logging\n\u2514\u2500\u2500 utils/\n    \u2514\u2500\u2500 helpers.py          \u2705 Utilities\n\n\u274c MANCA: bulk/\n\u274c MANCA: bulk_v2.py\n\u274c MANCA: job_manager.py\n</code></pre>"},{"location":"BULK_API_ANALYSIS/#cosa-serve-per-bulk-api-v2","title":"\ud83d\ude80 COSA SERVE PER BULK API v2","text":""},{"location":"BULK_API_ANALYSIS/#componenti-necessari","title":"Componenti Necessari","text":"<ol> <li> <p>BulkClient Module <pre><code># kinetic_core/bulk/client.py\nclass BulkClient:\n    def create_job(self, object, operation, content_type=\"CSV\")\n    def upload_data(self, job_id, data)\n    def close_job(self, job_id)\n    def get_job_status(self, job_id)\n    def get_results(self, job_id)\n</code></pre></p> </li> <li> <p>CSV Serializer <pre><code># kinetic_core/bulk/serializer.py\nclass CSVSerializer:\n    def to_csv(self, records) -&gt; str\n    def from_csv(self, csv_data) -&gt; List[Dict]\n</code></pre></p> </li> <li> <p>Job Manager <pre><code># kinetic_core/bulk/job_manager.py\nclass JobManager:\n    def create_and_execute(self, object, operation, records)\n    def poll_until_complete(self, job_id)\n    def get_success_and_failures(self, job_id)\n</code></pre></p> </li> <li> <p>Smart Router (killer feature!) <pre><code># kinetic_core/core/client.py\ndef smart_create(self, sobject, records):\n    if len(records) &lt; 200:\n        return self.create_batch(sobject, records)  # Composite\n    else:\n        return self.bulk.insert(sobject, records)   # Bulk API\n</code></pre></p> </li> </ol>"},{"location":"BULK_API_ANALYSIS/#performance-comparison","title":"\ud83d\udcc8 PERFORMANCE COMPARISON","text":""},{"location":"BULK_API_ANALYSIS/#scenario-10000-record-insert","title":"Scenario: 10,000 Record Insert","text":"Method Time Throughput Best For Single REST ~2h 46min 1 rec/sec &lt;10 records Composite API ~10 minutes 16 rec/sec 10-1000 records Bulk API v2 ~30 seconds 333 rec/sec &gt;1000 records"},{"location":"BULK_API_ANALYSIS/#raccomandazioni","title":"\u2705 RACCOMANDAZIONI","text":""},{"location":"BULK_API_ANALYSIS/#1-per-ora-senza-bulk-api","title":"1. Per ora (senza Bulk API)","text":"<pre><code># Usa Composite API con chunking intelligente\nfrom kinetic_core import SalesforceClient\n\nclient = SalesforceClient(session)\n\n# Chunk grandi dataset\nchunks = [records[i:i+200] for i in range(0, len(records), 200)]\n\nfor chunk in chunks:\n    results = client.create_batch(\"Account\", chunk)\n    # Process results...\n</code></pre> <p>Limite: max ~10,000 record ragionevolmente Performance: 16 rec/sec (dai test)</p>"},{"location":"BULK_API_ANALYSIS/#2-implementare-bulk-api-v2-consigliato","title":"2. Implementare Bulk API v2 (consigliato!)","text":"<pre><code># kinetic_core/bulk/client.py (da creare)\n\nclass BulkV2Client:\n    def __init__(self, session):\n        self.session = session\n        self.base_url = f\"{session.instance_url}/services/data/{session.api_version}\"\n\n    def insert(self, sobject, records):\n        # 1. Create job\n        job_id = self._create_job(sobject, \"insert\")\n\n        # 2. Upload CSV\n        csv_data = self._serialize_csv(records)\n        self._upload_data(job_id, csv_data)\n\n        # 3. Close job\n        self._close_job(job_id)\n\n        # 4. Poll &amp; return results\n        return self._wait_for_completion(job_id)\n</code></pre>"},{"location":"BULK_API_ANALYSIS/#3-smart-routing-best-practice","title":"3. Smart Routing (best practice!)","text":"<pre><code>def smart_insert(self, sobject, records):\n    \"\"\"Auto-select best method based on record count.\"\"\"\n    count = len(records)\n\n    if count == 1:\n        return [{\"id\": self.create(sobject, records[0])}]\n\n    elif count &lt; 200:\n        return self.create_batch(sobject, records)\n\n    else:\n        # Auto-chunk for Bulk API\n        return self.bulk.insert(sobject, records)\n</code></pre>"},{"location":"BULK_API_ANALYSIS/#conclusioni","title":"\ud83c\udfaf CONCLUSIONI","text":""},{"location":"BULK_API_ANALYSIS/#chatgpt-aveva-ragione","title":"\u2705 CHATGPT AVEVA RAGIONE","text":"<ol> <li>\u2705 Kinetic Core NON supporta Bulk API v2</li> <li>\u2705 Usa solo Composite API per batch</li> <li>\u2705 Limite pratico ~200 record per chiamata</li> <li>\u2705 Nessun job asincrono implementato</li> <li>\u2705 Nessun CSV upload/download</li> </ol>"},{"location":"BULK_API_ANALYSIS/#stato-attuale","title":"\ud83d\udcca STATO ATTUALE","text":"<p>Kinetic Core \u00e8 eccellente per: - \u2705 CRUD singoli (&lt;10 record) - \u2705 Batch medi (10-1000 record) - \u2705 Query complesse - \u2705 ETL pipeline configurabili - \u2705 Autenticazione robusta</p> <p>Kinetic Core NON \u00e8 ottimale per: - \u274c Bulk insert &gt;10,000 record - \u274c Data migration massivi - \u274c Export/import grandi volumi - \u274c Processi batch notturni pesanti</p>"},{"location":"BULK_API_ANALYSIS/#prossimi-passi","title":"\ud83d\ude80 PROSSIMI PASSI","text":"<p>Per renderlo production-ready su grandi volumi:</p> <p>Priority 1: Implementare Bulk API v2 - Modulo <code>bulk/client.py</code> - CSV serialization - Job management - Result parsing</p> <p>Priority 2: Smart routing automatico - Auto-select Composite vs Bulk - Threshold configurabile - Fallback su errori</p> <p>Priority 3: Advanced features - Query Bulk API (export grandi dataset) - Parallel job execution - Progress callbacks</p>"},{"location":"BULK_API_ANALYSIS/#file-da-creare","title":"\ud83d\udcdd FILE DA CREARE","text":"<pre><code>kinetic_core/\n\u2514\u2500\u2500 bulk/                          \ud83d\udc48 NUOVO\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 client.py                  # BulkV2Client\n    \u251c\u2500\u2500 serializer.py              # CSV handling\n    \u251c\u2500\u2500 job_manager.py             # Job lifecycle\n    \u2514\u2500\u2500 models.py                  # BulkJob, BulkResult\n</code></pre>"},{"location":"BULK_API_ANALYSIS/#esempio-implementazione-bulk","title":"\ud83d\udca1 ESEMPIO IMPLEMENTAZIONE BULK","text":"<pre><code># kinetic_core/bulk/client.py (schema base)\n\nclass BulkV2Client:\n    \"\"\"Salesforce Bulk API v2 client.\"\"\"\n\n    def __init__(self, session):\n        self.session = session\n        self.base_url = f\"{session.instance_url}/services/data/{session.api_version}\"\n\n    def insert(self, sobject: str, records: List[Dict]) -&gt; BulkResult:\n        \"\"\"Bulk insert records.\"\"\"\n        job = self._create_job(sobject, \"insert\", \"CSV\")\n        csv_data = CSVSerializer.to_csv(records)\n        self._upload_csv(job.id, csv_data)\n        self._close_job(job.id)\n        return self._poll_and_get_results(job.id)\n\n    def _create_job(self, sobject, operation, content_type):\n        url = f\"{self.base_url}/jobs/ingest\"\n        payload = {\n            \"object\": sobject,\n            \"operation\": operation,\n            \"contentType\": content_type\n        }\n        response = requests.post(url, headers=self.session.auth_header, json=payload)\n        return Job(**response.json())\n\n    def _upload_csv(self, job_id, csv_data):\n        url = f\"{self.base_url}/jobs/ingest/{job_id}/batches\"\n        headers = {**self.session.auth_header, \"Content-Type\": \"text/csv\"}\n        requests.put(url, headers=headers, data=csv_data)\n\n    def _close_job(self, job_id):\n        url = f\"{self.base_url}/jobs/ingest/{job_id}\"\n        requests.patch(url, headers=self.session.auth_header, json={\"state\": \"UploadComplete\"})\n\n    def _poll_and_get_results(self, job_id):\n        # Poll status every 2 seconds until complete\n        # Parse results CSV\n        # Return BulkResult(success=[], failed=[], errors={})\n        pass\n</code></pre> <p>CONCLUSIONE FINALE:</p> <p>\u2705 ChatGPT aveva assolutamente ragione \u2705 Il codice conferma tutte le sue affermazioni \u2705 Implementare Bulk API v2 \u00e8 la mossa giusta \u2705 Hai tutti gli strumenti per farlo bene</p> <p>Report generato: 2025-12-28 Codice analizzato: kinetic-core v1.1.0 Linee di codice controllate: ~3000 Metodi verificati: 10/10 core methods</p>"},{"location":"BULK_API_ANALYSIS/#configurazione-salesforce-external-app","title":"\ud83d\udd10 CONFIGURAZIONE SALESFORCE EXTERNAL APP","text":""},{"location":"BULK_API_ANALYSIS/#domanda-critica-serve-una-external-app-separata-per-bulk-api-v2","title":"\u26a0\ufe0f DOMANDA CRITICA: Serve una External App separata per Bulk API v2?","text":"<p>Risposta completa: Vedi SALESFORCE_BULK_CONFIG.md</p>"},{"location":"BULK_API_ANALYSIS/#tldr-risposta-rapida","title":"TL;DR (Risposta Rapida)","text":"<p>\u274c NO - Usa la stessa Connected App esistente</p> <p>MA aggiungi:</p> <ol> <li>\u2705 OAuth Scope <code>full</code> (o <code>web</code>) nella Connected App</li> <li>\u2705 User Permission <code>Bulk API Hard Delete</code></li> <li>\u2705 User Permission <code>Modify All Data</code></li> <li>\u2705 Rigenera JWT token dopo le modifiche</li> <li>\u23f1 Attendi 5-10 minuti per propagazione</li> </ol>"},{"location":"BULK_API_ANALYSIS/#configurazione-minima-vs-completa","title":"Configurazione Minima vs Completa","text":"Componente REST API (attuale) REST + Bulk API v2 OAuth Scopes api, refresh_token api, refresh_token, full \u2b50 Bulk API Hard Delete \u274c \u2705 \u2b50 View All Data \u274c \u2705 \u2b50 Modify All Data \u26a0\ufe0f \u2705 \u2b50 Token regen \u274c \u2705 Obbligatorio"},{"location":"BULK_API_ANALYSIS/#procedura-completa","title":"Procedura Completa","text":"<p>Per la guida dettagliata passo-passo con: - \u2705 Screenshots configurazione - \u2705 Troubleshooting errori comuni - \u2705 Script di verifica automatica - \u2705 Best practices production</p> <p>\ud83d\udc49 Leggi: SALESFORCE_BULK_CONFIG.md</p>"},{"location":"DOCKER_GUIDE/","title":"Docker Usage Guide","text":"<p>This guide explains how to run the Salesforce Toolkit in an isolated Docker environment, which avoids the need to install Python or dependencies on your local machine.</p>"},{"location":"DOCKER_GUIDE/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed on your machine.</li> <li>Docker Compose (usually included with Docker Desktop).</li> </ul>"},{"location":"DOCKER_GUIDE/#quick-start","title":"Quick Start","text":""},{"location":"DOCKER_GUIDE/#1-build-the-image","title":"1. Build the Image","text":"<p>Build the Docker image containing the toolkit and all dependencies:</p> <pre><code>docker-compose build\n</code></pre>"},{"location":"DOCKER_GUIDE/#2-run-tests","title":"2. Run Tests","text":"<p>Execute the unit tests inside the container to verify everything is working:</p> <p><pre><code>docker-compose run tests\n</code></pre> Expected Output: You should see <code>pytest</code> output showing passing tests (green).</p>"},{"location":"DOCKER_GUIDE/#3-usage-via-cli","title":"3. Usage via CLI","text":"<p>You can run any <code>sf-toolkit</code> CLI command using <code>docker-compose run toolkit [command]</code>.</p> <p>Display Help: <pre><code>docker-compose run toolkit --help\n</code></pre></p> <p>Test Authentication: <pre><code># Ensure your .env file is configured first!\ndocker-compose run toolkit auth --method jwt\n</code></pre></p>"},{"location":"DOCKER_GUIDE/#configuration","title":"Configuration","text":"<p>The Docker setup uses your local <code>.env</code> file. </p> <ol> <li>Create a <code>.env</code> file in the project root (see <code>config/.env.example</code>).</li> <li>Docker Compose automatically loads this file.</li> </ol>"},{"location":"DOCKER_GUIDE/#certificates","title":"Certificates","text":"<p>If you are using JWT authentication with a certificate file (e.g., <code>server.key</code>):</p> <ol> <li>Place the key file inside the project directory (e.g., inside a <code>certs/</code> folder).</li> <li>In your <code>.env</code> file, use the path relative to the container, which maps to <code>/app</code>.</li> </ol> <p>Example: If your local structure is: <pre><code>project/\n  certs/\n    server.key\n  .env\n</code></pre></p> <p>Your <code>.env</code> should look like this: <pre><code>SF_PRIVATE_KEY_PATH=/app/certs/server.key\n</code></pre> (Note: <code>/app</code> is where the project folder is mounted inside the container)</p>"},{"location":"DOCKER_GUIDE/#troubleshooting","title":"Troubleshooting","text":"<p>Permission Issues (Linux): If you encounter permission errors with file mounts, you may need to run docker-compose with <code>sudo</code>.</p> <p>\"File not found\" for keys: Ensure that your <code>SF_PRIVATE_KEY_PATH</code> in <code>.env</code> points to a path inside the container (starting with <code>/app/</code>), not your local host path.</p>"},{"location":"INSTALLATION/","title":"Installation Guide","text":"<p>Complete installation guide for Salesforce Toolkit.</p>"},{"location":"INSTALLATION/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Requirements</li> <li>Installation Methods</li> <li>Salesforce Setup</li> <li>Configuration</li> <li>Verification</li> <li>Troubleshooting</li> </ol>"},{"location":"INSTALLATION/#requirements","title":"Requirements","text":""},{"location":"INSTALLATION/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.8 or higher</li> <li>Operating System: Windows, macOS, or Linux</li> <li>Disk Space: ~50 MB</li> </ul>"},{"location":"INSTALLATION/#salesforce-requirements","title":"Salesforce Requirements","text":"<ul> <li>Salesforce Edition: Any edition with API access</li> <li>User Permissions:</li> <li>API Enabled</li> <li>Modify All Data (or specific object permissions)</li> <li>Connected App: Required for authentication</li> </ul>"},{"location":"INSTALLATION/#installation-methods","title":"Installation Methods","text":""},{"location":"INSTALLATION/#method-1-install-from-pypi-recommended","title":"Method 1: Install from PyPI (Recommended)","text":"<pre><code>pip install salesforce-toolkit\n</code></pre>"},{"location":"INSTALLATION/#method-2-install-from-source","title":"Method 2: Install from Source","text":"<pre><code># Clone the repository\ngit clone https://github.com/yourusername/salesforce-toolkit.git\ncd salesforce-toolkit\n\n# Install in development mode\npip install -e .\n</code></pre>"},{"location":"INSTALLATION/#method-3-install-with-optional-dependencies","title":"Method 3: Install with Optional Dependencies","text":"<pre><code># With database support\npip install salesforce-toolkit[database]\n\n# With data manipulation tools\npip install salesforce-toolkit[data]\n\n# With development tools\npip install salesforce-toolkit[dev]\n\n# Install all extras\npip install salesforce-toolkit[database,data,dev]\n</code></pre>"},{"location":"INSTALLATION/#salesforce-setup","title":"Salesforce Setup","text":""},{"location":"INSTALLATION/#step-1-create-a-connected-app","title":"Step 1: Create a Connected App","text":"<ol> <li>Log in to Salesforce</li> <li>Navigate to Setup \u2192 Apps \u2192 App Manager</li> <li>Click New Connected App</li> <li>Fill in the required fields:</li> <li>Connected App Name: <code>My Salesforce Integration</code></li> <li>API Name: <code>My_Salesforce_Integration</code></li> <li>Contact Email: your@email.com</li> <li>Enable OAuth Settings:</li> <li>Callback URL: <code>https://localhost</code></li> <li>Selected OAuth Scopes:<ul> <li>Full access (full)</li> <li>Perform requests on your behalf at any time (refresh_token, offline_access)</li> </ul> </li> <li>Save and note your Consumer Key (Client ID)</li> </ol>"},{"location":"INSTALLATION/#step-2-setup-jwt-authentication-recommended","title":"Step 2: Setup JWT Authentication (Recommended)","text":""},{"location":"INSTALLATION/#a-generate-rsa-key-pair","title":"A. Generate RSA Key Pair","text":"<pre><code># Generate private key (2048-bit RSA)\nopenssl genrsa -out server.key 2048\n\n# Generate certificate signing request\nopenssl req -new -key server.key -out server.csr\n\n# Generate self-signed certificate (valid for 365 days)\nopenssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt\n</code></pre>"},{"location":"INSTALLATION/#b-upload-certificate-to-salesforce","title":"B. Upload Certificate to Salesforce","text":"<ol> <li>Go to your Connected App</li> <li>Click Edit</li> <li>Enable Use digital signatures</li> <li>Upload <code>server.crt</code></li> <li>Save</li> </ol>"},{"location":"INSTALLATION/#c-pre-authorize-user","title":"C. Pre-authorize User","text":"<ol> <li>Go to your Connected App</li> <li>Click Manage</li> <li>Click Edit Policies</li> <li>Under OAuth Policies:</li> <li>Permitted Users: Admin approved users are pre-authorized</li> <li>Save</li> <li>Go to Manage Profiles or Manage Permission Sets</li> <li>Add your user's profile/permission set</li> </ol>"},{"location":"INSTALLATION/#step-3-setup-oauth-password-flow-alternative","title":"Step 3: Setup OAuth Password Flow (Alternative)","text":"<p>If using OAuth Password Flow instead of JWT:</p> <ol> <li>In your Connected App, enable OAuth Settings</li> <li>Enable Enable OAuth Settings for API Integration</li> <li>Copy your Consumer Key and Consumer Secret</li> <li>If required, reset your Security Token:</li> <li>Go to Setup \u2192 My Personal Information \u2192 Reset My Security Token</li> <li>Check your email for the new token</li> </ol>"},{"location":"INSTALLATION/#configuration","title":"Configuration","text":""},{"location":"INSTALLATION/#step-1-create-environment-file","title":"Step 1: Create Environment File","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># Copy the example file\ncp config/.env.example .env\n</code></pre>"},{"location":"INSTALLATION/#step-2-configure-environment-variables","title":"Step 2: Configure Environment Variables","text":""},{"location":"INSTALLATION/#for-jwt-authentication-recommended","title":"For JWT Authentication (Recommended):","text":"<pre><code># Salesforce JWT Configuration\nSF_CLIENT_ID=3MVG9...YOUR_CONSUMER_KEY_HERE\nSF_USERNAME=user@example.com.sandbox\nSF_PRIVATE_KEY_PATH=/absolute/path/to/server.key\nSF_LOGIN_URL=https://test.salesforce.com\n\n# API Configuration\nSF_API_VERSION=v60.0\n\n# Logging Configuration\nLOG_DIR=./logs\nLOG_LEVEL=INFO\nLOG_CONSOLE_OUTPUT=true\nLOG_CONSOLE_COLORS=true\n</code></pre>"},{"location":"INSTALLATION/#for-oauth-password-flow-alternative","title":"For OAuth Password Flow (Alternative):","text":"<pre><code># Salesforce OAuth Configuration\nSF_CLIENT_ID=3MVG9...YOUR_CONSUMER_KEY_HERE\nSF_CLIENT_SECRET=1234567890ABCDEF...YOUR_CONSUMER_SECRET\nSF_USERNAME=user@example.com\nSF_PASSWORD=your_password\nSF_SECURITY_TOKEN=ABC123...YOUR_SECURITY_TOKEN\nSF_LOGIN_URL=https://login.salesforce.com\n\n# API Configuration\nSF_API_VERSION=v60.0\n\n# Logging Configuration\nLOG_DIR=./logs\nLOG_LEVEL=INFO\n</code></pre>"},{"location":"INSTALLATION/#important-notes","title":"Important Notes","text":"<ul> <li>Sandbox URL: Use <code>https://test.salesforce.com</code> for sandboxes</li> <li>Production URL: Use <code>https://login.salesforce.com</code> for production</li> <li>Private Key Path: Must be an absolute path</li> <li>Security Token: Only needed for OAuth password flow</li> </ul>"},{"location":"INSTALLATION/#verification","title":"Verification","text":""},{"location":"INSTALLATION/#test-installation","title":"Test Installation","text":"<pre><code># test_installation.py\nfrom salesforce_toolkit import __version__\n\nprint(f\"Salesforce Toolkit version: {__version__}\")\n</code></pre> <pre><code>python test_installation.py\n</code></pre>"},{"location":"INSTALLATION/#test-authentication","title":"Test Authentication","text":"<pre><code># test_auth.py\nfrom salesforce_toolkit import JWTAuthenticator\n\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\n\nprint(f\"\u2713 Authentication successful!\")\nprint(f\"Instance URL: {session.instance_url}\")\nprint(f\"API Version: {session.api_version}\")\n</code></pre> <pre><code>python test_auth.py\n</code></pre>"},{"location":"INSTALLATION/#test-cli","title":"Test CLI","text":"<pre><code># Test authentication via CLI\nsf-toolkit auth --method jwt\n\n# Query Salesforce\nsf-toolkit query \"SELECT Id, Name FROM Account LIMIT 5\"\n</code></pre>"},{"location":"INSTALLATION/#troubleshooting","title":"Troubleshooting","text":""},{"location":"INSTALLATION/#common-issues","title":"Common Issues","text":""},{"location":"INSTALLATION/#1-modulenotfounderror","title":"1. ModuleNotFoundError","text":"<p>Error: <code>ModuleNotFoundError: No module named 'salesforce_toolkit'</code></p> <p>Solution: <pre><code># Reinstall the package\npip uninstall salesforce-toolkit\npip install salesforce-toolkit\n\n# Or install in development mode\npip install -e .\n</code></pre></p>"},{"location":"INSTALLATION/#2-authentication-failed-invalid_grant","title":"2. Authentication Failed: invalid_grant","text":"<p>Error: <code>Authentication failed: invalid_grant</code></p> <p>Possible Causes: - Consumer Key is incorrect - User is not pre-authorized - Certificate doesn't match private key - Wrong login URL (check sandbox vs production)</p> <p>Solutions: 1. Verify Consumer Key in <code>.env</code> matches Salesforce 2. Check user is pre-authorized in Connected App 3. Regenerate certificate and re-upload to Salesforce 4. Use <code>https://test.salesforce.com</code> for sandboxes</p>"},{"location":"INSTALLATION/#3-private-key-not-found","title":"3. Private Key Not Found","text":"<p>Error: <code>FileNotFoundError: Private key file not found</code></p> <p>Solution: - Use absolute path in <code>SF_PRIVATE_KEY_PATH</code> - Verify file exists: <code>ls -la /path/to/server.key</code> - Check file permissions: <code>chmod 600 server.key</code></p>"},{"location":"INSTALLATION/#4-import-error-pyjwt","title":"4. Import Error: PyJWT","text":"<p>Error: <code>ModuleNotFoundError: No module named 'jwt'</code></p> <p>Solution: <pre><code>pip install PyJWT cryptography\n</code></pre></p>"},{"location":"INSTALLATION/#5-permission-denied","title":"5. Permission Denied","text":"<p>Error: <code>Permission denied: '/logs/salesforce_toolkit.log'</code></p> <p>Solution: <pre><code># Create logs directory\nmkdir -p logs\nchmod 755 logs\n\n# Or change LOG_DIR in .env\nLOG_DIR=./logs\n</code></pre></p>"},{"location":"INSTALLATION/#6-api-version-not-supported","title":"6. API Version Not Supported","text":"<p>Error: <code>API version v56.0 is not supported</code></p> <p>Solution: - Update <code>SF_API_VERSION</code> in <code>.env</code> to a supported version (v60.0 recommended) - Check Salesforce release notes for available API versions</p>"},{"location":"INSTALLATION/#platform-specific-instructions","title":"Platform-Specific Instructions","text":""},{"location":"INSTALLATION/#windows","title":"Windows","text":"<pre><code># Install Python (if not installed)\n# Download from https://www.python.org/downloads/\n\n# Install package\npip install salesforce-toolkit\n\n# Generate keys (requires OpenSSL for Windows)\n# Download: https://slproweb.com/products/Win32OpenSSL.html\nopenssl genrsa -out server.key 2048\nopenssl req -new -x509 -key server.key -out server.crt -days 365\n</code></pre>"},{"location":"INSTALLATION/#macos","title":"macOS","text":"<pre><code># Install Python (if not installed)\nbrew install python3\n\n# Install package\npip3 install salesforce-toolkit\n\n# Generate keys (OpenSSL pre-installed)\nopenssl genrsa -out server.key 2048\nopenssl req -new -x509 -key server.key -out server.crt -days 365\n</code></pre>"},{"location":"INSTALLATION/#linux","title":"Linux","text":"<pre><code># Install Python (if not installed)\nsudo apt-get update\nsudo apt-get install python3 python3-pip\n\n# Install package\npip3 install salesforce-toolkit\n\n# Generate keys (OpenSSL pre-installed)\nopenssl genrsa -out server.key 2048\nopenssl req -new -x509 -key server.key -out server.crt -days 365\n</code></pre>"},{"location":"INSTALLATION/#docker-installation-optional","title":"Docker Installation (Optional)","text":"<pre><code># Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Install dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application\nCOPY . .\n\n# Install package\nRUN pip install -e .\n\nCMD [\"python\", \"your_script.py\"]\n</code></pre> <pre><code># Build image\ndocker build -t salesforce-toolkit .\n\n# Run container\ndocker run -it --env-file .env salesforce-toolkit\n</code></pre>"},{"location":"INSTALLATION/#upgrade","title":"Upgrade","text":""},{"location":"INSTALLATION/#upgrade-to-latest-version","title":"Upgrade to Latest Version","text":"<pre><code>pip install --upgrade salesforce-toolkit\n</code></pre>"},{"location":"INSTALLATION/#verify-upgrade","title":"Verify Upgrade","text":"<pre><code>from salesforce_toolkit import __version__\nprint(f\"Version: {__version__}\")\n</code></pre>"},{"location":"INSTALLATION/#uninstall","title":"Uninstall","text":"<pre><code>pip uninstall salesforce-toolkit\n</code></pre>"},{"location":"INSTALLATION/#next-steps","title":"Next Steps","text":"<p>After successful installation:</p> <ol> <li>\u2705 Read the Quick Start Guide</li> <li>\u2705 Try the Examples</li> <li>\u2705 Read the README for full documentation</li> <li>\u2705 Configure your first Sync Pipeline</li> </ol>"},{"location":"INSTALLATION/#support","title":"Support","text":"<p>Need help? Check these resources:</p> <ul> <li>Documentation: README.md</li> <li>GitHub Issues: https://github.com/yourusername/salesforce-toolkit/issues</li> <li>Examples: examples/</li> <li>Quick Start: docs/QUICK_START.md</li> </ul> <p>Installation complete! \ud83c\udf89</p>"},{"location":"PROJECT_SUMMARY/","title":"Salesforce Toolkit - Project Summary","text":""},{"location":"PROJECT_SUMMARY/#overview","title":"Overview","text":"<p>Salesforce Toolkit is a comprehensive, production-ready Python library for Salesforce integration. It provides a flexible, configuration-driven framework for working with any Salesforce object, field mapping, and ETL pipelines.</p>"},{"location":"PROJECT_SUMMARY/#key-features","title":"\ud83c\udfaf Key Features","text":""},{"location":"PROJECT_SUMMARY/#1-multiple-authentication-methods","title":"1. Multiple Authentication Methods","text":"<ul> <li>JWT Bearer Flow (recommended for production)</li> <li>OAuth 2.0 Password Flow</li> <li>Environment-based configuration</li> </ul>"},{"location":"PROJECT_SUMMARY/#2-universal-salesforce-client","title":"2. Universal Salesforce Client","text":"<ul> <li>Works with any Salesforce object (standard or custom)</li> <li>Complete CRUD operations (Create, Read, Update, Delete, Upsert)</li> <li>Bulk operations via Composite API</li> <li>SOQL queries with automatic pagination</li> <li>Metadata describe operations</li> </ul>"},{"location":"PROJECT_SUMMARY/#3-flexible-field-mapping","title":"3. Flexible Field Mapping","text":"<ul> <li>Simple field renaming</li> <li>Custom transformation functions</li> <li>Built-in transformations (lowercase, uppercase, date formatting, etc.)</li> <li>Default values</li> <li>Nested field access (dot notation)</li> <li>Conditional mapping</li> </ul>"},{"location":"PROJECT_SUMMARY/#4-etl-pipeline-framework","title":"4. ETL Pipeline Framework","text":"<ul> <li>Configuration-driven sync pipelines</li> <li>Multiple sync modes (INSERT, UPDATE, UPSERT, DELETE)</li> <li>Batch processing</li> <li>Progress tracking with callbacks</li> <li>Comprehensive error handling and reporting</li> </ul>"},{"location":"PROJECT_SUMMARY/#5-production-ready-logging","title":"5. Production-Ready Logging","text":"<ul> <li>File and console output</li> <li>Automatic log rotation</li> <li>Colored console output</li> <li>Contextual logging</li> <li>Configurable log levels</li> </ul>"},{"location":"PROJECT_SUMMARY/#6-command-line-interface","title":"6. Command-Line Interface","text":"<ul> <li>Query, create, update, delete from terminal</li> <li>Run sync pipelines from YAML config</li> <li>Describe Salesforce objects</li> <li>Test authentication</li> </ul>"},{"location":"PROJECT_SUMMARY/#project-structure","title":"\ud83d\udcc1 Project Structure","text":"<pre><code>salesforce-toolkit/\n\u251c\u2500\u2500 salesforce_toolkit/          # Main library package\n\u2502   \u251c\u2500\u2500 __init__.py              # Package initialization\n\u2502   \u251c\u2500\u2500 auth/                    # Authentication providers\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 jwt_auth.py          # JWT Bearer Flow\n\u2502   \u2502   \u2514\u2500\u2500 oauth_auth.py        # OAuth Password Flow\n\u2502   \u251c\u2500\u2500 core/                    # Core functionality\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 session.py           # Session management\n\u2502   \u2502   \u2514\u2500\u2500 client.py            # Salesforce API client\n\u2502   \u251c\u2500\u2500 mapping/                 # Field mapping engine\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 field_mapper.py      # Mapper with transformations\n\u2502   \u251c\u2500\u2500 pipeline/                # ETL pipeline framework\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 sync_pipeline.py     # Sync pipeline implementation\n\u2502   \u251c\u2500\u2500 logging/                 # Logging system\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 logger.py            # Logging configuration\n\u2502   \u2514\u2500\u2500 utils/                   # Utilities\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 helpers.py           # Helper functions\n\u251c\u2500\u2500 config/                      # Configuration templates\n\u2502   \u251c\u2500\u2500 .env.example             # Environment variables template\n\u2502   \u2514\u2500\u2500 sync_config_example.yaml # Sync pipeline config template\n\u251c\u2500\u2500 examples/                    # Usage examples\n\u2502   \u251c\u2500\u2500 01_basic_authentication.py\n\u2502   \u251c\u2500\u2500 02_crud_operations.py\n\u2502   \u2514\u2500\u2500 03_data_sync_pipeline.py\n\u251c\u2500\u2500 docs/                        # Documentation\n\u2502   \u2514\u2500\u2500 QUICK_START.md           # Quick start guide\n\u251c\u2500\u2500 tests/                       # Unit tests (to be added)\n\u251c\u2500\u2500 cli.py                       # Command-line interface\n\u251c\u2500\u2500 setup.py                     # Package setup configuration\n\u251c\u2500\u2500 requirements.txt             # Production dependencies\n\u251c\u2500\u2500 README.md                    # Main documentation\n\u251c\u2500\u2500 LICENSE                      # MIT License\n\u251c\u2500\u2500 CHANGELOG.md                 # Version history\n\u251c\u2500\u2500 MANIFEST.in                  # Package manifest\n\u251c\u2500\u2500 .gitignore                   # Git ignore rules\n\u251c\u2500\u2500 PROJECT_SUMMARY.md           # This file\n</code></pre>"},{"location":"PROJECT_SUMMARY/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"PROJECT_SUMMARY/#installation","title":"Installation","text":"<pre><code>pip install salesforce-toolkit\n</code></pre>"},{"location":"PROJECT_SUMMARY/#basic-usage","title":"Basic Usage","text":"<pre><code>from salesforce_toolkit import JWTAuthenticator, SalesforceClient\n\n# Authenticate\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\n\n# Create client\nclient = SalesforceClient(session)\n\n# Create a record\naccount_id = client.create(\"Account\", {\n    \"Name\": \"ACME Corporation\",\n    \"Industry\": \"Technology\"\n})\n\n# Query records\naccounts = client.query(\"SELECT Id, Name FROM Account LIMIT 10\")\n\n# Update a record\nclient.update(\"Account\", account_id, {\"Phone\": \"555-1234\"})\n</code></pre>"},{"location":"PROJECT_SUMMARY/#data-sync-pipeline","title":"Data Sync Pipeline","text":"<pre><code>from salesforce_toolkit import FieldMapper, SyncPipeline, SyncMode\n\n# Define mapping\nmapper = FieldMapper({\n    \"customer_name\": \"Name\",\n    \"customer_email\": \"Email\"\n})\n\n# Create pipeline\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT\n)\n\n# Sync data\nresult = pipeline.sync(source_data)\n</code></pre>"},{"location":"PROJECT_SUMMARY/#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>README.md - Complete documentation</li> <li>QUICK_START.md - Quick start guide</li> <li>Examples - Code examples</li> <li>Config Templates - Configuration examples</li> </ul>"},{"location":"PROJECT_SUMMARY/#design-principles","title":"\ud83c\udfa8 Design Principles","text":""},{"location":"PROJECT_SUMMARY/#1-simplicity","title":"1. Simplicity","text":"<ul> <li>Clean, intuitive API</li> <li>Sensible defaults</li> <li>Minimal configuration required</li> </ul>"},{"location":"PROJECT_SUMMARY/#2-flexibility","title":"2. Flexibility","text":"<ul> <li>Works with any Salesforce object</li> <li>Customizable field mapping</li> <li>Extensible pipeline framework</li> </ul>"},{"location":"PROJECT_SUMMARY/#3-robustness","title":"3. Robustness","text":"<ul> <li>Comprehensive error handling</li> <li>Automatic retries (planned)</li> <li>Detailed logging</li> </ul>"},{"location":"PROJECT_SUMMARY/#4-performance","title":"4. Performance","text":"<ul> <li>Batch operations</li> <li>Automatic pagination</li> <li>Efficient data processing</li> </ul>"},{"location":"PROJECT_SUMMARY/#5-developer-experience","title":"5. Developer Experience","text":"<ul> <li>Type hints throughout</li> <li>Clear documentation</li> <li>Rich examples</li> </ul>"},{"location":"PROJECT_SUMMARY/#technical-stack","title":"\ud83d\udd27 Technical Stack","text":""},{"location":"PROJECT_SUMMARY/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>requests (2.31.0+) - HTTP client for REST API</li> <li>PyJWT (2.8.0+) - JWT token generation</li> <li>cryptography (41.0.7+) - RSA key handling</li> <li>PyYAML (6.0.1+) - YAML configuration</li> <li>python-dotenv (1.0.0+) - Environment variables</li> </ul>"},{"location":"PROJECT_SUMMARY/#optional-dependencies","title":"Optional Dependencies","text":"<ul> <li>mysql-connector-python - MySQL support</li> <li>psycopg2-binary - PostgreSQL support</li> <li>pymongo - MongoDB support</li> <li>pandas - Data manipulation</li> <li>numpy - Numerical operations</li> </ul>"},{"location":"PROJECT_SUMMARY/#development-tools","title":"Development Tools","text":"<ul> <li>pytest - Testing framework</li> <li>pytest-cov - Code coverage</li> <li>black - Code formatter</li> <li>flake8 - Linter</li> <li>mypy - Type checker</li> <li>sphinx - Documentation generator</li> </ul>"},{"location":"PROJECT_SUMMARY/#testing","title":"\ud83e\uddea Testing","text":"<pre><code># Run tests\npytest\n\n# With coverage\npytest --cov=salesforce_toolkit --cov-report=html\n\n# Linting\nflake8 salesforce_toolkit/\n\n# Type checking\nmypy salesforce_toolkit/\n\n# Code formatting\nblack salesforce_toolkit/\n</code></pre>"},{"location":"PROJECT_SUMMARY/#roadmap","title":"\ud83d\udee3\ufe0f Roadmap","text":""},{"location":"PROJECT_SUMMARY/#version-11-planned","title":"Version 1.1 (Planned)","text":"<ul> <li>[ ] Bulk API 2.0 support</li> <li>[ ] Built-in retry mechanism with exponential backoff</li> <li>[ ] Dry-run mode for pipelines</li> <li>[ ] Performance metrics</li> </ul>"},{"location":"PROJECT_SUMMARY/#version-12-planned","title":"Version 1.2 (Planned)","text":"<ul> <li>[ ] Metadata API support</li> <li>[ ] Streaming API (PushTopic, Generic Streaming)</li> <li>[ ] Integration with popular ORMs</li> <li>[ ] Advanced caching strategies</li> </ul>"},{"location":"PROJECT_SUMMARY/#version-20-future","title":"Version 2.0 (Future)","text":"<ul> <li>[ ] Async/await support</li> <li>[ ] GraphQL API support</li> <li>[ ] Real-time change data capture</li> <li>[ ] Advanced data validation</li> </ul>"},{"location":"PROJECT_SUMMARY/#architecture","title":"\ud83d\udcca Architecture","text":""},{"location":"PROJECT_SUMMARY/#authentication-layer","title":"Authentication Layer","text":"<pre><code>JWTAuthenticator / OAuthAuthenticator\n    \u2193\nSalesforceSession (instance_url, access_token, api_version)\n    \u2193\nSalesforceClient (CRUD operations)\n</code></pre>"},{"location":"PROJECT_SUMMARY/#data-sync-flow","title":"Data Sync Flow","text":"<pre><code>Source Data\n    \u2193\nFieldMapper (transform)\n    \u2193\nSyncPipeline (batch processing)\n    \u2193\nSalesforceClient (create/update/upsert/delete)\n    \u2193\nSyncResult (success/error tracking)\n</code></pre>"},{"location":"PROJECT_SUMMARY/#logging-flow","title":"Logging Flow","text":"<pre><code>Application Code\n    \u2193\nsetup_logger() \u2192 Logger Instance\n    \u2193\n    \u251c\u2500\u2192 File Handler (with rotation)\n    \u2514\u2500\u2192 Console Handler (with colors)\n</code></pre>"},{"location":"PROJECT_SUMMARY/#security-best-practices","title":"\ud83d\udd10 Security Best Practices","text":"<ol> <li>Never commit credentials - Use <code>.env</code> files (in <code>.gitignore</code>)</li> <li>Use JWT for production - More secure than password flow</li> <li>Rotate certificates regularly - JWT certificates should be rotated</li> <li>Restrict Connected App - Limit IP ranges and profiles</li> <li>Use field-level security - Control access at Salesforce level</li> <li>Validate external data - Always validate data from external sources</li> <li>Log security events - Track authentication and data access</li> </ol>"},{"location":"PROJECT_SUMMARY/#contributing","title":"\ud83e\udd1d Contributing","text":"<p>We welcome contributions! Please see our contributing guidelines:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Add tests</li> <li>Submit a pull request</li> </ol>"},{"location":"PROJECT_SUMMARY/#development-setup","title":"Development Setup","text":"<pre><code>git clone https://github.com/yourusername/salesforce-toolkit.git\ncd salesforce-toolkit\npython -m venv venv\nsource venv/bin/activate\npip install -e \".[dev]\"\n</code></pre>"},{"location":"PROJECT_SUMMARY/#license","title":"\ud83d\udcdc License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"PROJECT_SUMMARY/#author","title":"\ud83d\udc64 Author","text":"<p>Antonio Trento</p> <ul> <li>GitHub: @antoniotrento</li> <li>LinkedIn: Antonio Trento</li> <li>Email: info@antoniotrento.net</li> </ul>"},{"location":"PROJECT_SUMMARY/#credits","title":"\ud83d\ude4f Credits","text":"<ul> <li>Inspired by Simple Salesforce</li> <li>Built with Requests</li> <li>Powered by PyJWT</li> </ul>"},{"location":"PROJECT_SUMMARY/#project-stats","title":"\ud83d\udcc8 Project Stats","text":"<ul> <li>Lines of Code: ~3,500+</li> <li>Modules: 11</li> <li>Classes: 10+</li> <li>Functions: 100+</li> <li>Examples: 3 comprehensive examples</li> <li>Documentation Pages: 5+</li> </ul> <p>Last Updated: 2025-12-05 Version: 1.0.0</p>"},{"location":"PUBLISHING_GUIDE/","title":"Publishing Guide","text":"<p>This guide explains how to package your toolkit as a library and publish it to the Python Package Index (PyPI), making it installable via <code>pip install salesforce-toolkit</code>.</p>"},{"location":"PUBLISHING_GUIDE/#1-prerequisites","title":"1. Prerequisites","text":"<p>You need a generic \"build\" environment. Since we added <code>build</code> and <code>twine</code> to <code>setup.py</code>, you can install them:</p> <p>On your machine (or Docker): <pre><code>pip install build twine\n</code></pre></p>"},{"location":"PUBLISHING_GUIDE/#2-configuration-setuppy","title":"2. Configuration (<code>setup.py</code>)","text":"<p>I have already updated your <code>setup.py</code> with your information: - Name: <code>salesforce-toolkit</code> - Version: <code>1.0.0</code> - Author: <code>Antonio Trento</code> - URL: <code>https://github.com/antonio-backend-projects/salesforce-toolkit</code></p> <p>Note: If the name <code>salesforce-toolkit</code> is already taken on PyPI (which is likely), you will need to change the <code>name</code> argument in <code>setup.py</code> to something unique, like <code>antonio-salesforce-toolkit</code> or <code>sf-toolkit-pro</code>.</p>"},{"location":"PUBLISHING_GUIDE/#3-build-the-package","title":"3. Build the Package","text":"<p>Run this command to generate the distribution files (<code>.tar.gz</code> and <code>.whl</code>) in the <code>dist/</code> folder:</p> <pre><code>python -m build\n</code></pre> <p>You should see: <pre><code>dist/\n  salesforce_toolkit-1.0.0-py3-none-any.whl\n  salesforce-toolkit-1.0.0.tar.gz\n</code></pre></p>"},{"location":"PUBLISHING_GUIDE/#4-test-publishing-testpypi","title":"4. Test Publishing (TestPyPI)","text":"<p>It is highly recommended to upload to TestPyPI first to check if everything looks right.</p> <ol> <li>Register: Go to test.pypi.org and create an account.</li> <li>Create Token: Go to Account Settings \u2192 API Tokens \u2192 Create a new token (Scope: Entire account). Copy it.</li> <li>Upload: <pre><code>python -m twine upload --repository testpypi dist/*\n</code></pre></li> <li> <p>Enter Credentials:</p> <ul> <li>Username: <code>__token__</code></li> <li>Password: <code>&lt;your-api-token&gt;</code></li> </ul> </li> <li> <p>Verify: Try installing it in a new virtual environment:     <pre><code>pip install --index-url https://test.pypi.org/simple/ salesforce-toolkit\n</code></pre></p> </li> </ol>"},{"location":"PUBLISHING_GUIDE/#5-publish-to-production-pypi","title":"5. Publish to Production (PyPI)","text":"<p>Once verified:</p> <ol> <li>Register: Go to pypi.org and create an account.</li> <li>Create Token: Account Settings \u2192 API Tokens.</li> <li>Upload: <pre><code>python -m twine upload dist/*\n</code></pre></li> <li>Success! Your package is now live. Anyone can run:     <pre><code>pip install salesforce-toolkit\n</code></pre></li> </ol>"},{"location":"PUBLISHING_GUIDE/#6-alternative-install-from-github","title":"6. Alternative: Install from GitHub","text":"<p>If you don't want to publish to PyPI publicly, users can install directly from your GitHub repository:</p> <pre><code>pip install git+https://github.com/antoniotrento/salesforce-toolkit.git\n</code></pre> <p>This is great for private testing or internal tools.</p>"},{"location":"QUICK_START/","title":"Quick Start Guide","text":"<p>Get up and running with Salesforce Toolkit in 5 minutes!</p>"},{"location":"QUICK_START/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation</li> <li>Setup</li> <li>Authentication</li> <li>Basic Operations</li> <li>Data Sync</li> <li>CLI Usage</li> <li>Next Steps</li> </ol>"},{"location":"QUICK_START/#installation","title":"Installation","text":"<pre><code>pip install salesforce-toolkit\n</code></pre> <p>Or install from source:</p> <pre><code>git clone https://github.com/yourusername/salesforce-toolkit.git\ncd salesforce-toolkit\npip install -e .\n</code></pre>"},{"location":"QUICK_START/#setup","title":"Setup","text":""},{"location":"QUICK_START/#1-create-a-connected-app-in-salesforce","title":"1. Create a Connected App in Salesforce","text":"<ol> <li>Go to Setup \u2192 App Manager \u2192 New Connected App</li> <li>Fill in basic information:</li> <li>Connected App Name: <code>My Integration</code></li> <li>API Name: <code>My_Integration</code></li> <li>Contact Email: your@email.com</li> <li>Enable OAuth Settings:</li> <li>Callback URL: <code>https://localhost</code></li> <li>Selected OAuth Scopes: <code>Full access (full)</code></li> <li>Enable Use digital signatures and upload your certificate</li> <li>Save and note your Consumer Key</li> </ol>"},{"location":"QUICK_START/#2-generate-rsa-key-pair-for-jwt","title":"2. Generate RSA Key Pair (for JWT)","text":"<pre><code># Generate private key\nopenssl genrsa -out server.key 2048\n\n# Generate certificate\nopenssl req -new -x509 -key server.key -out server.crt -days 365\n\n# Upload server.crt to Salesforce Connected App\n</code></pre>"},{"location":"QUICK_START/#3-create-env-file","title":"3. Create .env File","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code>SF_CLIENT_ID=3MVG9...YOUR_CONSUMER_KEY\nSF_USERNAME=user@example.com.sandbox\nSF_PRIVATE_KEY_PATH=/path/to/server.key\nSF_LOGIN_URL=https://test.salesforce.com\n</code></pre>"},{"location":"QUICK_START/#authentication","title":"Authentication","text":"<pre><code>from salesforce_toolkit import JWTAuthenticator\n\n# Authenticate using .env configuration\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\n\nprint(f\"\u2713 Connected to: {session.instance_url}\")\n</code></pre>"},{"location":"QUICK_START/#basic-operations","title":"Basic Operations","text":""},{"location":"QUICK_START/#create-a-record","title":"Create a Record","text":"<pre><code>from salesforce_toolkit import JWTAuthenticator, SalesforceClient\n\n# Setup\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\n# Create Account\naccount_id = client.create(\"Account\", {\n    \"Name\": \"ACME Corporation\",\n    \"Industry\": \"Technology\",\n    \"Phone\": \"555-0100\"\n})\n\nprint(f\"Created Account: {account_id}\")\n</code></pre>"},{"location":"QUICK_START/#query-records","title":"Query Records","text":"<pre><code># Query Accounts\naccounts = client.query(\n    \"SELECT Id, Name, Industry FROM Account WHERE Industry = 'Technology' LIMIT 10\"\n)\n\nfor account in accounts:\n    print(f\"{account['Name']} ({account['Id']})\")\n</code></pre>"},{"location":"QUICK_START/#update-a-record","title":"Update a Record","text":"<pre><code>client.update(\"Account\", account_id, {\n    \"Phone\": \"555-9999\",\n    \"Website\": \"https://acme.com\"\n})\n\nprint(f\"Updated Account: {account_id}\")\n</code></pre>"},{"location":"QUICK_START/#delete-a-record","title":"Delete a Record","text":"<pre><code>client.delete(\"Account\", account_id)\nprint(f\"Deleted Account: {account_id}\")\n</code></pre>"},{"location":"QUICK_START/#data-sync","title":"Data Sync","text":"<p>Sync data from any source to Salesforce:</p> <pre><code>from salesforce_toolkit import FieldMapper, SyncPipeline, SyncMode\n\n# Define field mapping\nmapper = FieldMapper({\n    \"customer_name\": \"Name\",\n    \"customer_email\": \"Email\",\n    \"customer_phone\": \"Phone\",\n    \"industry_code\": (\"Industry\", lambda x: x.title())  # Transform to title case\n})\n\n# Create pipeline\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT,\n    batch_size=200\n)\n\n# Your source data (from database, CSV, API, etc.)\nsource_data = [\n    {\n        \"customer_name\": \"Tech Innovations Inc\",\n        \"customer_email\": \"contact@techinnovations.com\",\n        \"customer_phone\": \"555-1001\",\n        \"industry_code\": \"technology\"\n    },\n    {\n        \"customer_name\": \"Global Manufacturing Co\",\n        \"customer_email\": \"info@globalmanufacturing.com\",\n        \"customer_phone\": \"555-1002\",\n        \"industry_code\": \"manufacturing\"\n    }\n]\n\n# Run sync\nresult = pipeline.sync(source_data)\n\nprint(f\"Synced {result.success_count}/{result.total_records} records\")\nprint(f\"Success Rate: {result.success_rate:.1f}%\")\n</code></pre>"},{"location":"QUICK_START/#cli-usage","title":"CLI Usage","text":"<p>The toolkit includes a powerful CLI for common operations:</p>"},{"location":"QUICK_START/#test-authentication","title":"Test Authentication","text":"<pre><code>sf-toolkit auth --method jwt\n</code></pre>"},{"location":"QUICK_START/#query-salesforce","title":"Query Salesforce","text":"<pre><code>sf-toolkit query \"SELECT Id, Name FROM Account LIMIT 10\"\n</code></pre>"},{"location":"QUICK_START/#create-a-record_1","title":"Create a Record","text":"<pre><code>sf-toolkit create Account --data '{\"Name\": \"ACME Corp\", \"Industry\": \"Technology\"}'\n</code></pre>"},{"location":"QUICK_START/#run-a-sync-pipeline","title":"Run a Sync Pipeline","text":"<p>Create a <code>sync_config.yaml</code> file:</p> <pre><code>source:\n  type: json\n  path: data/accounts.json\n\npipeline:\n  sobject: Account\n  mode: insert\n  batch_size: 200\n  mapping:\n    customer_name: Name\n    customer_email: Email\n    industry_code:\n      target: Industry\n      transform: uppercase\n</code></pre> <p>Run the sync:</p> <pre><code>sf-toolkit sync --config sync_config.yaml\n</code></pre>"},{"location":"QUICK_START/#describe-a-salesforce-object","title":"Describe a Salesforce Object","text":"<pre><code>sf-toolkit describe Account --fields\n</code></pre>"},{"location":"QUICK_START/#next-steps","title":"Next Steps","text":""},{"location":"QUICK_START/#learn-more","title":"Learn More","text":"<ul> <li>README.md - Complete documentation</li> <li>Examples - Code examples for all features</li> <li>API Reference - Detailed API documentation</li> <li>Configuration Guide - Advanced configuration options</li> </ul>"},{"location":"QUICK_START/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Field Mapping - Learn about transformations and nested fields</li> <li>Error Handling - Implement robust error handling</li> <li>Batch Operations - Optimize performance with batching</li> <li>Custom Pipelines - Build custom ETL pipelines</li> <li>Logging - Configure logging for production</li> </ul>"},{"location":"QUICK_START/#get-help","title":"Get Help","text":"<ul> <li>GitHub Issues: https://github.com/yourusername/salesforce-toolkit/issues</li> <li>Documentation: https://github.com/yourusername/salesforce-toolkit#readme</li> <li>Examples: examples/</li> </ul>"},{"location":"QUICK_START/#common-issues","title":"Common Issues","text":""},{"location":"QUICK_START/#authentication-failed","title":"Authentication Failed","text":"<p>Problem: <code>Authentication failed: invalid_grant</code></p> <p>Solution: - Verify your Consumer Key is correct - Ensure the username is pre-authorized in the Connected App - Check that your certificate matches the private key - For sandboxes, use <code>https://test.salesforce.com</code> as login URL</p>"},{"location":"QUICK_START/#private-key-not-found","title":"Private Key Not Found","text":"<p>Problem: <code>FileNotFoundError: Private key file not found</code></p> <p>Solution: - Use absolute path in <code>SF_PRIVATE_KEY_PATH</code> - Verify the file exists: <code>ls -la /path/to/server.key</code> - Check file permissions</p>"},{"location":"QUICK_START/#field-not-found","title":"Field Not Found","text":"<p>Problem: <code>Invalid field: CustomField__c</code></p> <p>Solution: - Verify the field exists in Salesforce - Check field API name (it should end with <code>__c</code> for custom fields) - Ensure you have read/write permissions on the field</p> <p>Ready to build? Start with the examples or dive into the full documentation!</p>"},{"location":"SALESFORCE_BULK_CONFIG/","title":"Salesforce External App Configuration for Bulk API v2","text":"<p>Data: 2025-12-28 Scope: Configurazione Connected App per supportare Bulk API v2 Domanda: Serve una External App separata per Bulk API?</p>"},{"location":"SALESFORCE_BULK_CONFIG/#risposta-rapida","title":"\ud83c\udfaf RISPOSTA RAPIDA","text":""},{"location":"SALESFORCE_BULK_CONFIG/#serve-creare-una-nuova-external-app","title":"Serve creare una nuova External App?","text":"<p>\u274c NO - Puoi usare la stessa Connected App esistente</p> <p>MA devi aggiungere:</p> <ol> <li>\u2705 OAuth Scope \"full\" (o \"web\")</li> <li>\u2705 User Permission \"Bulk API Hard Delete\"</li> <li>\u2705 User Permission \"Modify All Data\"</li> <li>\u2705 Rigenerare il JWT token dopo le modifiche</li> </ol>"},{"location":"SALESFORCE_BULK_CONFIG/#configurazione-attuale-vs-bulk-api-v2","title":"\ud83d\udcca CONFIGURAZIONE ATTUALE vs BULK API v2","text":""},{"location":"SALESFORCE_BULK_CONFIG/#configurazione-attuale-rest-api-funzionante","title":"\u2705 Configurazione Attuale (REST API funzionante)","text":"<p>Tua Connected App: <pre><code>Connected App: Kinetic-Core\n\u251c\u2500\u2500 OAuth Scopes\n\u2502   \u251c\u2500\u2500 api              \u2705 Funziona per REST\n\u2502   \u2514\u2500\u2500 refresh_token    \u2705 Funziona per refresh\n\u2502\n\u251c\u2500\u2500 JWT Bearer Flow: Enabled\n\u251c\u2500\u2500 Certificate: Installato\n\u2514\u2500\u2500 Permessi Base: API Enabled\n</code></pre></p> <p>Funziona per: - \u2705 REST API standard - \u2705 Composite API (batch &lt;200) - \u2705 Query/SOQL - \u2705 CRUD operations</p> <p>NON funziona per: - \u274c Bulk API v2 jobs - \u274c Upload CSV massivi - \u274c Processi asincroni bulk</p>"},{"location":"SALESFORCE_BULK_CONFIG/#modifiche-necessarie-per-bulk-api-v2","title":"\ud83d\udea8 MODIFICHE NECESSARIE PER BULK API v2","text":""},{"location":"SALESFORCE_BULK_CONFIG/#1-oauth-scopes-critico","title":"1\ufe0f\u20e3 OAuth Scopes (CRITICO!)","text":""},{"location":"SALESFORCE_BULK_CONFIG/#configurazione-attuale-insufficiente","title":"\u274c Configurazione Attuale (insufficiente)","text":"<pre><code>OAuth Scopes:\n  - api              # \u2705 REST funziona\n  - refresh_token    # \u2705 Refresh funziona\n</code></pre> <p>Problema: Salesforce restituisce 403 Forbidden su <code>/jobs/ingest</code></p>"},{"location":"SALESFORCE_BULK_CONFIG/#configurazione-corretta-bulk-api-v2","title":"\u2705 Configurazione Corretta (Bulk API v2)","text":"<pre><code>OAuth Scopes richiesti:\n  - api              # \u2705 REST API base\n  - refresh_token    # \u2705 Token refresh\n  - full             # \u2b50 OBBLIGATORIO per Bulk API v2\n</code></pre> <p>ALTERNATIVA (pi\u00f9 granulare):</p> <pre><code>OAuth Scopes alternativi:\n  - api              # \u2705 REST API base\n  - refresh_token    # \u2705 Token refresh\n  - web              # \u2b50 Include accesso Bulk API\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#attenzione-rigenerare-token","title":"\u26a0\ufe0f ATTENZIONE: Rigenerare Token!","text":"<pre><code># Dopo aver modificato gli scope OAuth nella Connected App:\n\n1. Salva modifiche in Salesforce\n2. Attendi 2-10 minuti (propagazione cache Salesforce)\n3. Rigenera un nuovo JWT token\n4. NON riutilizzare token cached/salvati\n\n# I token esistenti NON acquisiscono automaticamente i nuovi scope!\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#2-user-permissions-profilepermission-set","title":"2\ufe0f\u20e3 User Permissions (Profile/Permission Set)","text":""},{"location":"SALESFORCE_BULK_CONFIG/#permessi-attuali-rest-api","title":"\u2705 Permessi Attuali (REST API)","text":"<pre><code>User Permissions (minimo per REST):\n  - API Enabled                     \u2705 Base\n  - View Setup and Configuration    \u2705 Setup\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#permessi-aggiuntivi-per-bulk-api-v2","title":"\u2705 Permessi Aggiuntivi per Bulk API v2","text":"<pre><code>User Permissions OBBLIGATORI per Bulk:\n  - API Enabled                     \u2705 Gi\u00e0 presente\n  - Bulk API Hard Delete            \u2b50 NUOVO - Obbligatorio\n  - View All Data                   \u2b50 NUOVO - Per query bulk\n  - Modify All Data                 \u2b50 NUOVO - Per insert/update/delete bulk\n</code></pre> <p>Dove configurarli:</p> <pre><code>Setup \u2192 Users \u2192 Permission Sets \u2192 Create New\n\nName: Bulk API Access\nAPI Name: Bulk_API_Access\n\nSystem Permissions:\n\u2611 API Enabled\n\u2611 Bulk API Hard Delete        \u2b50 CRITICO\n\u2611 View All Data               \u2b50 Per query bulk\n\u2611 Modify All Data             \u2b50 Per operazioni bulk\n\nAssigned Users:\n\u2192 Aggiungi l'utente JWT/OAuth\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#3-object-level-security-ols","title":"3\ufe0f\u20e3 Object-Level Security (OLS)","text":""},{"location":"SALESFORCE_BULK_CONFIG/#per-ogni-oggetto-usato-con-bulk-api","title":"Per ogni oggetto usato con Bulk API:","text":"<pre><code>Setup \u2192 Object Manager \u2192 Account (esempio)\n\nObject Permissions richiesti:\n  - Read         \u2705 Per query\n  - Create       \u2705 Per insert/upsert\n  - Edit         \u2705 Per update/upsert\n  - Delete       \u2705 Per delete\n  - View All     \u2b50 CONSIGLIATO per Bulk\n  - Modify All   \u2b50 CONSIGLIATO per Bulk\n</code></pre> <p>Configurazione tramite Permission Set:</p> <pre><code>Permission Set \u2192 Object Settings \u2192 Account\n\n\u2611 Read\n\u2611 Create\n\u2611 Edit\n\u2611 Delete\n\u2611 View All Records      \u2b50 Evita SOQL restrictions\n\u2611 Modify All Records    \u2b50 Evita sharing restrictions\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#guida-step-by-step","title":"\ud83d\udd27 GUIDA STEP-BY-STEP","text":""},{"location":"SALESFORCE_BULK_CONFIG/#step-1-modifica-connected-app-esistente","title":"Step 1: Modifica Connected App Esistente","text":"<pre><code>Setup \u2192 App Manager \u2192 [Your Connected App] \u2192 Edit\n\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\nSection: OAuth Policies\n\nSelected OAuth Scopes:\n  Disponibili                    Selezionati\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500              \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Access and manage data (api)  \u2192  [MOVE] \u2192  api \u2705\n  Perform requests at any time  \u2192  [MOVE] \u2192  refresh_token \u2705\n  Full access (full)            \u2192  [MOVE] \u2192  full \u2b50 NUOVO\n\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\nSection: Permitted Users\n  \u2611 Admin approved users are pre-authorized\n\nSection: IP Relaxation\n  Development: \u2611 Relax IP restrictions\n  Production:  \u2611 Enforce IP restrictions (whitelist)\n\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n[Save]\n</code></pre> <p>\u23f1 Tempo di propagazione: 2-10 minuti</p>"},{"location":"SALESFORCE_BULK_CONFIG/#step-2-crea-permission-set-per-bulk-api","title":"Step 2: Crea Permission Set per Bulk API","text":"<pre><code>Setup \u2192 Permission Sets \u2192 New\n\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\nLabel: Bulk API Access\nAPI Name: Bulk_API_Access\nLicense: --None--\n\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n[Save] \u2192 [System Permissions]\n\nSystem Permissions to Enable:\n  \u2611 API Enabled\n  \u2611 Bulk API Hard Delete              \u2b50 CRITICO\n  \u2611 View All Data                     \u2b50 Per query bulk\n  \u2611 Modify All Data                   \u2b50 Per operazioni bulk\n\n[Save]\n\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n[Object Settings] \u2192 Edit \u2192 Account\n\nAccount Object Permissions:\n  \u2611 Read\n  \u2611 Create\n  \u2611 Edit\n  \u2611 Delete\n  \u2611 View All Records                  \u2b50 Bulk queries\n  \u2611 Modify All Records                \u2b50 Bulk operations\n\n[Save]\n\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\n[Manage Assignments] \u2192 Add Assignments\n\nSelect Users:\n  \u2611 [Your JWT/OAuth User]\n\n[Assign]\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#step-3-rigenera-jwt-token","title":"Step 3: Rigenera JWT Token","text":"<pre><code># Attendi 5-10 minuti dopo modifiche scope\n# Poi rigenera token con kinetic-core:\n\nfrom kinetic_core import JWTAuthenticator\n\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()  # Nuovo token con scope \"full\"\n\nprint(f\"New token generated: {session.access_token[:30]}...\")\nprint(f\"Instance URL: {session.instance_url}\")\n</code></pre> <p>\u26a0\ufe0f IMPORTANTE: - Elimina token cached - Non riutilizzare vecchi token - Il nuovo token contiene i nuovi scope</p>"},{"location":"SALESFORCE_BULK_CONFIG/#step-4-test-bulk-api-access","title":"Step 4: Test Bulk API Access","text":"<pre><code>import requests\n\n# Test creazione job Bulk API v2\nheaders = {\n    \"Authorization\": f\"Bearer {session.access_token}\",\n    \"Content-Type\": \"application/json\"\n}\n\nurl = f\"{session.instance_url}/services/data/v62.0/jobs/ingest\"\n\nresponse = requests.post(\n    url,\n    headers=headers,\n    json={\n        \"object\": \"Account\",\n        \"operation\": \"insert\",\n        \"contentType\": \"CSV\"\n    }\n)\n\nprint(f\"Status: {response.status_code}\")\n\nif response.status_code == 201:\n    print(\"\u2705 Bulk API v2 WORKS!\")\n    job = response.json()\n    print(f\"Job ID: {job['id']}\")\n    print(f\"State: {job['state']}\")\n\n    # Cleanup: abort test job\n    requests.patch(\n        f\"{url}/{job['id']}\",\n        headers=headers,\n        json={\"state\": \"Aborted\"}\n    )\n    print(\"Test job aborted\")\n\nelif response.status_code == 403:\n    print(\"\u274c FAILED: Missing permissions\")\n    print(\"\u2192 Add 'Bulk API Hard Delete' permission\")\n    print(\"\u2192 Add 'Modify All Data' permission\")\n\nelif response.status_code == 400 and \"invalid_grant\" in response.text:\n    print(\"\u274c FAILED: OAuth scope issue\")\n    print(\"\u2192 Add 'full' scope to Connected App\")\n    print(\"\u2192 Wait 5-10 minutes\")\n    print(\"\u2192 Regenerate JWT token\")\n\nelse:\n    print(f\"\u274c Error: {response.text}\")\n</code></pre> <p>Output atteso:</p> <pre><code>Status: 201\n\u2705 Bulk API v2 WORKS!\nJob ID: 750XXXXXXXXXXXXXXX\nState: Open\nTest job aborted\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#troubleshooting","title":"\ud83d\udd0d TROUBLESHOOTING","text":""},{"location":"SALESFORCE_BULK_CONFIG/#errore-403-forbidden","title":"Errore: 403 Forbidden","text":"<pre><code>{\n  \"errorCode\": \"INSUFFICIENT_ACCESS\",\n  \"message\": \"Insufficient privileges\"\n}\n</code></pre> <p>Diagnosi: Mancano permessi utente</p> <p>Soluzione: 1. \u2705 Verifica Permission Set assegnato 2. \u2705 Aggiungi \"Bulk API Hard Delete\" 3. \u2705 Aggiungi \"Modify All Data\" 4. \u2705 Verifica Object Permissions (View All, Modify All)</p>"},{"location":"SALESFORCE_BULK_CONFIG/#errore-400-invalid_grant","title":"Errore: 400 invalid_grant","text":"<pre><code>{\n  \"error\": \"invalid_grant\",\n  \"error_description\": \"user hasn't approved this consumer\"\n}\n</code></pre> <p>Diagnosi: Scope OAuth insufficienti o token non aggiornato</p> <p>Soluzione: 1. \u2705 Aggiungi scope \"full\" alla Connected App 2. \u2705 Attendi 5-10 minuti (propagazione) 3. \u2705 Rigenera nuovo JWT token 4. \u2705 NON usare token cached</p>"},{"location":"SALESFORCE_BULK_CONFIG/#errore-404-not-found","title":"Errore: 404 Not Found","text":"<pre><code>{\n  \"errorCode\": \"NOT_FOUND\",\n  \"message\": \"The requested resource does not exist\"\n}\n</code></pre> <p>Diagnosi: Endpoint sbagliato o API version troppo vecchia</p> <p>Soluzione: 1. \u2705 Usa API version &gt;= v52.0 2. \u2705 Endpoint corretto: <code>/services/data/v62.0/jobs/ingest</code> 3. \u2705 Non confondere con Bulk API v1 (<code>/async/</code>)</p>"},{"location":"SALESFORCE_BULK_CONFIG/#errore-token-funziona-per-rest-ma-non-per-bulk","title":"Errore: Token funziona per REST ma non per Bulk","text":"<p>Diagnosi: Token generato prima di aggiungere scope \"full\"</p> <p>Soluzione: <pre><code># 1. Verifica scope nella Connected App\nSetup \u2192 App Manager \u2192 [App] \u2192 View \u2192 OAuth Scopes\n\n# Deve contenere \"full\" o \"web\"\n\n# 2. Elimina token cached\nrm .token_cache  # o equivalente\n\n# 3. Rigenera token\npython -c \"from kinetic_core import JWTAuthenticator;\nauth = JWTAuthenticator.from_env();\nauth.authenticate()\"\n</code></pre></p>"},{"location":"SALESFORCE_BULK_CONFIG/#checklist-completa","title":"\ud83d\udccb CHECKLIST COMPLETA","text":""},{"location":"SALESFORCE_BULK_CONFIG/#connected-app","title":"\u2705 Connected App","text":"<ul> <li>[ ] OAuth Scope \"api\" presente</li> <li>[ ] OAuth Scope \"refresh_token\" presente</li> <li>[ ] OAuth Scope \"full\" o \"web\" aggiunto \u2b50 NUOVO</li> <li>[ ] Certificate JWT configurato</li> <li>[ ] Permitted Users configurati</li> <li>[ ] IP Relaxation configurata</li> </ul>"},{"location":"SALESFORCE_BULK_CONFIG/#permission-set","title":"\u2705 Permission Set","text":"<ul> <li>[ ] Permission Set \"Bulk API Access\" creato</li> <li>[ ] System Permission: API Enabled</li> <li>[ ] System Permission: Bulk API Hard Delete \u2b50 NUOVO</li> <li>[ ] System Permission: View All Data \u2b50 NUOVO</li> <li>[ ] System Permission: Modify All Data \u2b50 NUOVO</li> <li>[ ] Permission Set assegnato all'utente JWT</li> </ul>"},{"location":"SALESFORCE_BULK_CONFIG/#object-permissions-per-ogni-oggetto","title":"\u2705 Object Permissions (per ogni oggetto)","text":"<ul> <li>[ ] Read permission</li> <li>[ ] Create permission</li> <li>[ ] Edit permission</li> <li>[ ] Delete permission</li> <li>[ ] View All Records \u2b50 CONSIGLIATO</li> <li>[ ] Modify All Records \u2b50 CONSIGLIATO</li> </ul>"},{"location":"SALESFORCE_BULK_CONFIG/#testing","title":"\u2705 Testing","text":"<ul> <li>[ ] Atteso 5-10 minuti dopo modifiche</li> <li>[ ] Rigenerato JWT token</li> <li>[ ] Testato endpoint: <code>POST /jobs/ingest</code></li> <li>[ ] Ottenuto risposta 201 Created</li> <li>[ ] Verificato Job ID valido</li> </ul>"},{"location":"SALESFORCE_BULK_CONFIG/#una-app-o-due-app","title":"\ud83d\udca1 UNA APP o DUE APP?","text":""},{"location":"SALESFORCE_BULK_CONFIG/#opzione-1-una-sola-app-consigliato","title":"Opzione 1: Una Sola App (\u2705 CONSIGLIATO)","text":"<pre><code>Connected App: Kinetic-Core\n  OAuth Scopes:\n    - api           # REST API\n    - refresh_token # Refresh\n    - full          # Bulk API v2\n\n  Permessi Utente:\n    - API Enabled\n    - Bulk API Hard Delete\n    - View All Data\n    - Modify All Data\n</code></pre> <p>Vantaggi: - \u2705 Gestione semplificata - \u2705 Un solo token per tutto - \u2705 Meno configurazione - \u2705 Stesso auth flow</p> <p>Quando usare: - \u2705 La maggior parte dei casi - \u2705 Sviluppo e test - \u2705 Applicazioni che usano sia REST che Bulk</p>"},{"location":"SALESFORCE_BULK_CONFIG/#opzione-2-due-app-separate-solo-casi-specifici","title":"Opzione 2: Due App Separate (\u26a0\ufe0f Solo casi specifici)","text":"<pre><code>App 1: Kinetic-Core-REST\n  OAuth Scopes: [api, refresh_token]\n  Uso: CRUD, Query, Composite\n\nApp 2: Kinetic-Core-Bulk\n  OAuth Scopes: [api, refresh_token, full]\n  Uso: Solo Bulk API v2\n</code></pre> <p>Quando usare: - \u26a0\ufe0f Policy di sicurezza che separano REST da Bulk - \u26a0\ufe0f Audit trail separati richiesti - \u26a0\ufe0f Team diversi gestiscono REST e Bulk - \u26a0\ufe0f Limiti API da separare</p> <p>Svantaggi: - \u274c Doppia gestione - \u274c Due token da gestire - \u274c Pi\u00f9 complessit\u00e0 - \u274c Pi\u00f9 certificati/configurazioni</p>"},{"location":"SALESFORCE_BULK_CONFIG/#best-practice-production","title":"\ud83c\udfaf BEST PRACTICE PRODUCTION","text":""},{"location":"SALESFORCE_BULK_CONFIG/#configurazione-raccomandata-una-app","title":"Configurazione Raccomandata (Una App)","text":"<pre><code>\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nConnected App: Kinetic-Core\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\nOAuth Configuration:\n  Scopes:\n    - api              # Base REST API\n    - refresh_token    # Token refresh\n    - full             # Bulk API v2 + advanced features\n\n  Permitted Users:\n    - Admin approved users are pre-authorized\n\n  IP Restrictions:\n    Development: Relaxed\n    Production: Enforced (whitelist IP ranges)\n\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nPermission Set: Kinetic Core API Access\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n\nSystem Permissions:\n  \u2705 API Enabled\n  \u2705 Bulk API Hard Delete\n  \u2705 View All Data\n  \u2705 Modify All Data\n\nObject Permissions (Account, Contact, etc):\n  \u2705 Read\n  \u2705 Create\n  \u2705 Edit\n  \u2705 Delete\n  \u2705 View All Records\n  \u2705 Modify All Records\n\nAssigned To:\n  - JWT Service User (lantoniotrento343@agentforce.com)\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#script-di-verifica-automatica","title":"\ud83e\uddea SCRIPT DI VERIFICA AUTOMATICA","text":"<p>Salva come: <code>tests/verify_bulk_config.py</code></p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nVerify Salesforce configuration for Bulk API v2.\n\nTests:\n1. JWT Authentication\n2. Bulk API endpoint access\n3. Job creation\n4. Permissions check\n\"\"\"\n\nimport requests\nimport sys\nfrom kinetic_core import JWTAuthenticator\n\n\ndef test_authentication():\n    \"\"\"Test JWT authentication.\"\"\"\n    print(\"\\n1\ufe0f\u20e3 Testing JWT Authentication...\")\n    try:\n        auth = JWTAuthenticator.from_env()\n        session = auth.authenticate()\n        print(f\"   \u2705 Authenticated: {session.instance_url}\")\n        print(f\"   \u2705 User: {auth.username}\")\n        print(f\"   \u2705 API Version: {session.api_version}\")\n        return session\n    except Exception as e:\n        print(f\"   \u274c FAILED: {e}\")\n        return None\n\n\ndef test_bulk_api_access(session):\n    \"\"\"Test Bulk API v2 endpoint access.\"\"\"\n    print(\"\\n2\ufe0f\u20e3 Testing Bulk API v2 Access...\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {session.access_token}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    url = f\"{session.instance_url}/services/data/{session.api_version}/jobs/ingest\"\n\n    # Create test job\n    response = requests.post(\n        url,\n        headers=headers,\n        json={\n            \"object\": \"Account\",\n            \"operation\": \"insert\",\n            \"contentType\": \"CSV\"\n        }\n    )\n\n    if response.status_code == 201:\n        job = response.json()\n        print(f\"   \u2705 Bulk API v2 accessible\")\n        print(f\"   \u2705 Job created: {job['id']}\")\n        print(f\"   \u2705 State: {job['state']}\")\n\n        # Cleanup: abort test job\n        requests.patch(\n            f\"{url}/{job['id']}\",\n            headers=headers,\n            json={\"state\": \"Aborted\"}\n        )\n        print(f\"   \u2705 Test job aborted\")\n        return True\n\n    else:\n        print(f\"   \u274c FAILED: HTTP {response.status_code}\")\n        print(f\"   Error: {response.text[:200]}\")\n\n        # Diagnose\n        if response.status_code == 403:\n            print(\"\\n   \ud83d\udca1 Missing permissions:\")\n            print(\"   \u2192 Add 'Bulk API Hard Delete' to Permission Set\")\n            print(\"   \u2192 Add 'Modify All Data' to Permission Set\")\n            print(\"   \u2192 Verify Permission Set is assigned to user\")\n\n        elif \"invalid_grant\" in response.text:\n            print(\"\\n   \ud83d\udca1 OAuth scope issue:\")\n            print(\"   \u2192 Add 'full' scope to Connected App\")\n            print(\"   \u2192 Wait 5-10 minutes for propagation\")\n            print(\"   \u2192 Regenerate JWT token\")\n\n        elif response.status_code == 404:\n            print(\"\\n   \ud83d\udca1 Endpoint issue:\")\n            print(\"   \u2192 Check API version &gt;= v52.0\")\n            print(\"   \u2192 Verify endpoint: /jobs/ingest\")\n\n        return False\n\n\ndef test_permissions(session):\n    \"\"\"Test user permissions.\"\"\"\n    print(\"\\n3\ufe0f\u20e3 Testing User Permissions...\")\n\n    # This is informational - we can't directly query permissions via API\n    # but we infer from Bulk API access test\n\n    print(\"   \u2139\ufe0f  Permission verification via Bulk API test\")\n    print(\"   \u2139\ufe0f  If Bulk API works, permissions are correct\")\n    return True\n\n\ndef main():\n    \"\"\"Run all verification tests.\"\"\"\n    print(\"=\" * 70)\n    print(\"  Salesforce Bulk API v2 Configuration Verification\")\n    print(\"=\" * 70)\n\n    # Test 1: Authentication\n    session = test_authentication()\n    if not session:\n        print(\"\\n\u274c Authentication failed. Fix .env configuration.\")\n        return 1\n\n    # Test 2: Bulk API Access\n    bulk_works = test_bulk_api_access(session)\n    if not bulk_works:\n        print(\"\\n\u274c Bulk API not accessible. Check configuration above.\")\n        return 1\n\n    # Test 3: Permissions\n    test_permissions(session)\n\n    # Summary\n    print(\"\\n\" + \"=\" * 70)\n    print(\"  \u2705 ALL TESTS PASSED\")\n    print(\"=\" * 70)\n    print(\"\\n  Salesforce is correctly configured for Bulk API v2!\")\n    print(\"\\n  Connected App Scopes: \u2705\")\n    print(\"  User Permissions: \u2705\")\n    print(\"  Bulk API Access: \u2705\")\n    print(\"\\n  You can now implement Bulk API v2 in kinetic-core.\")\n    print(\"=\" * 70)\n\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n</code></pre> <p>Esegui:</p> <pre><code>python tests/verify_bulk_config.py\n</code></pre> <p>Output atteso (successo):</p> <pre><code>======================================================================\n  Salesforce Bulk API v2 Configuration Verification\n======================================================================\n\n1\ufe0f\u20e3 Testing JWT Authentication...\n   \u2705 Authenticated: https://your-instance.salesforce.com\n   \u2705 User: your-user@example.com\n   \u2705 API Version: v62.0\n\n2\ufe0f\u20e3 Testing Bulk API v2 Access...\n   \u2705 Bulk API v2 accessible\n   \u2705 Job created: 750XXXXXXXXXXXXXXX\n   \u2705 State: Open\n   \u2705 Test job aborted\n\n3\ufe0f\u20e3 Testing User Permissions...\n   \u2139\ufe0f  Permission verification via Bulk API test\n   \u2139\ufe0f  If Bulk API works, permissions are correct\n\n======================================================================\n  \u2705 ALL TESTS PASSED\n======================================================================\n\n  Salesforce is correctly configured for Bulk API v2!\n\n  Connected App Scopes: \u2705\n  User Permissions: \u2705\n  Bulk API Access: \u2705\n\n  You can now implement Bulk API v2 in kinetic-core.\n======================================================================\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#configurazione-finale-riassunta","title":"\ud83d\udcca CONFIGURAZIONE FINALE RIASSUNTA","text":""},{"location":"SALESFORCE_BULK_CONFIG/#prima-rest-api-only","title":"Prima (REST API only)","text":"<pre><code>Connected App OAuth Scopes:\n  - api\n  - refresh_token\n\nUser Permissions:\n  - API Enabled\n\nFunziona:\n  \u2705 REST API\n  \u2705 Composite API (&lt;200 records)\n  \u274c Bulk API v2\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#dopo-rest-bulk-api-v2","title":"Dopo (REST + Bulk API v2)","text":"<pre><code>Connected App OAuth Scopes:\n  - api\n  - refresh_token\n  - full              \u2b50 AGGIUNTO\n\nUser Permissions:\n  - API Enabled\n  - Bulk API Hard Delete        \u2b50 AGGIUNTO\n  - View All Data               \u2b50 AGGIUNTO\n  - Modify All Data             \u2b50 AGGIUNTO\n\nFunziona:\n  \u2705 REST API\n  \u2705 Composite API\n  \u2705 Bulk API v2     \u2b50 NUOVO\n</code></pre>"},{"location":"SALESFORCE_BULK_CONFIG/#conclusione","title":"\u2705 CONCLUSIONE","text":""},{"location":"SALESFORCE_BULK_CONFIG/#risposta-alla-domanda-originale","title":"Risposta alla Domanda Originale","text":"<p>Serve una External App separata per Bulk API v2?</p> <p>\u274c NO - Una sola Connected App \u00e8 sufficiente e consigliata</p>"},{"location":"SALESFORCE_BULK_CONFIG/#cosa-serve-fare","title":"Cosa Serve Fare","text":"<ol> <li>\u2705 Aggiungere scope OAuth \"full\" alla Connected App esistente</li> <li>\u2705 Creare Permission Set con permessi Bulk API</li> <li>\u2705 Assegnare Permission Set all'utente JWT</li> <li>\u2705 Rigenerare JWT token (IMPORTANTE!)</li> <li>\u2705 Testare con script di verifica</li> </ol>"},{"location":"SALESFORCE_BULK_CONFIG/#tempo-richiesto","title":"Tempo Richiesto","text":"<ul> <li>Modifica Connected App: 5 minuti</li> <li>Creazione Permission Set: 10 minuti</li> <li>Propagazione Salesforce: 5-10 minuti</li> <li>Test e verifica: 5 minuti</li> </ul> <p>Totale: ~30 minuti</p>"},{"location":"SALESFORCE_BULK_CONFIG/#benefici","title":"Benefici","text":"<ul> <li>\u2705 Un solo token per REST e Bulk</li> <li>\u2705 Configurazione pi\u00f9 semplice</li> <li>\u2705 Meno overhead di gestione</li> <li>\u2705 Performance 20-50x migliori su grandi volumi</li> </ul> <p>Documento creato: 2025-12-28 Configurazione testata: Salesforce Developer Edition Kinetic Core version: 1.1.0 Status: \u2705 Pronto per implementazione Bulk API v2</p> <p>bene ora rileggi l'intero workspace</p> <p>oltre kinetic-core ho aggiunto kinetincmcp</p> <p>praticamente l'aggiornamento di Kinetic-Core serve per essere integrato in kineticmcp</p> <p>quindi leggi la codebase di kineticmcp e dimmi gli impatti generati da questo upgrade</p> <p>e fammi capire quanti e quali step di implementazione dovremo compiere per avere l'aggiornamento bulk api v2 completo anzi direi tutte le funzionalit\u00e0 possibili per connttere il server mcp a salesforce</p>"},{"location":"SALESFORCE_SETUP_GUIDE/","title":"Salesforce Setup Guide - Complete Walkthrough","text":"<p>Step-by-step guide to configure Salesforce access for the Salesforce Toolkit</p> <p>This guide will walk you through every single step to set up authentication with Salesforce, from creating a Connected App to testing your first API call.</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Method 1: JWT Bearer Flow (Recommended)</li> <li>Method 2: OAuth Password Flow</li> <li>Testing Your Setup</li> <li>Troubleshooting</li> <li>Security Best Practices</li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#prerequisites","title":"Prerequisites","text":"<p>Before starting, make sure you have:</p> <ul> <li>\u2705 Salesforce Account with admin access (or API permissions)</li> <li>\u2705 Python 3.8+ installed</li> <li>\u2705 OpenSSL installed (for JWT method)</li> <li>Windows: Download from slproweb.com</li> <li>macOS: Pre-installed</li> <li>Linux: Pre-installed (or <code>sudo apt-get install openssl</code>)</li> <li>\u2705 Salesforce Toolkit installed (<code>pip install salesforce-toolkit</code>)</li> </ul>"},{"location":"SALESFORCE_SETUP_GUIDE/#method-1-jwt-bearer-flow-recommended","title":"Method 1: JWT Bearer Flow (Recommended)","text":"<p>Why JWT? - \u2705 More secure (no passwords stored) - \u2705 No security token needed - \u2705 Recommended for production - \u2705 Supports server-to-server integration</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-1-generate-rsa-key-pair","title":"Step 1: Generate RSA Key Pair","text":"<p>Open your terminal and run:</p> <pre><code># Navigate to your project directory\ncd /path/to/your/project\n\n# Create a directory for certificates (optional but recommended)\nmkdir certs\ncd certs\n\n# Generate private key (2048-bit RSA)\nopenssl genrsa -out server.key 2048\n\n# Generate self-signed certificate (valid for 365 days)\nopenssl req -new -x509 -key server.key -out server.crt -days 365\n</code></pre> <p>When prompted, enter: <pre><code>Country Name (2 letter code): IT\nState or Province Name: Lombardia\nLocality Name: Milan\nOrganization Name: Your Company\nOrganizational Unit Name: IT\nCommon Name: localhost\nEmail Address: your@email.com\n</code></pre></p> <p>Result: You'll have two files: - <code>server.key</code> - Private key (NEVER share this!) - <code>server.crt</code> - Certificate (upload to Salesforce)</p> <p>Important: Note the absolute path to <code>server.key</code>. You'll need it later.</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-2-create-connected-app-in-salesforce","title":"Step 2: Create Connected App in Salesforce","text":""},{"location":"SALESFORCE_SETUP_GUIDE/#21-navigate-to-app-manager","title":"2.1 Navigate to App Manager","text":"<ol> <li>Login to your Salesforce org</li> <li>Click the \u2699\ufe0f gear icon (top right) \u2192 Setup</li> <li>In the Quick Find box (left sidebar), type: \"App Manager\"</li> <li>Click \"App Manager\" under Platform Tools \u2192 Apps</li> <li>Click \"New Connected App\" button (top right)</li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#22-fill-basic-information","title":"2.2 Fill Basic Information","text":"<p>In the Basic Information section:</p> <pre><code>Connected App Name: My Salesforce Integration\nAPI Name: My_Salesforce_Integration (auto-generated, leave as is)\nContact Email: your@email.com\nDescription: Integration for Salesforce Toolkit (optional)\n</code></pre>"},{"location":"SALESFORCE_SETUP_GUIDE/#23-configure-api-enable-oauth-settings","title":"2.3 Configure API (Enable OAuth Settings)","text":"<p>Scroll down to API (Enable OAuth Settings):</p> <ol> <li> <p>\u2705 Check \"Enable OAuth Settings\"</p> </li> <li> <p>Callback URL: Enter <code>https://localhost</code></p> </li> <li> <p>Note: For JWT, the callback URL doesn't matter, but it's required</p> </li> <li> <p>Selected OAuth Scopes: Click \"Add\" to move these from Available to Selected:</p> </li> <li><code>Access the identity URL service (id, profile, email, address, phone)</code></li> <li><code>Full access (full)</code></li> <li> <p><code>Perform requests at any time (refresh_token, offline_access)</code></p> </li> <li> <p>\u2705 Check \"Use digital signatures\"</p> </li> <li> <p>Upload Certificate:</p> </li> <li>Click \"Choose File\"</li> <li>Select <code>server.crt</code> (the certificate, NOT server.key!)</li> <li> <p>The file will upload</p> </li> <li> <p>\u2705 Check \"Require Proof Key for Code Exchange (PKCE)\" (optional, for extra security)</p> </li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#24-save-and-wait","title":"2.4 Save and Wait","text":"<ol> <li>Click \"Save\" at the bottom</li> <li>Click \"Continue\" on the confirmation screen</li> <li>\u23f0 IMPORTANT: Wait 2-10 minutes for Salesforce to process your Connected App</li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-3-copy-consumer-key","title":"Step 3: Copy Consumer Key","text":"<p>After waiting 2-10 minutes:</p> <ol> <li>Go back to Setup \u2192 App Manager</li> <li>Find your Connected App in the list</li> <li>Click the \u25bc dropdown at the right \u2192 \"View\"</li> <li>You'll see the API (Enable OAuth Settings) section</li> <li>Copy the \"Consumer Key\"</li> <li>It's a long string like: <code>3MVG9XPlQYHF2jxAtyNlZrULLGJ06jOs...</code></li> <li>Keep this safe! You'll need it in your <code>.env</code> file</li> </ol> <p>Tip: Click the copy icon (\ud83d\udccb) next to Consumer Key to copy it.</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-4-pre-authorize-users-critical","title":"Step 4: Pre-Authorize Users (CRITICAL!)","text":"<p>This is the most commonly missed step!</p> <p>Without pre-authorization, you'll get an <code>invalid_grant</code> error.</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#41-edit-policies","title":"4.1 Edit Policies","text":"<ol> <li>In the Connected App view, click \"Manage\" (top of page)</li> <li>Click \"Edit Policies\"</li> <li>Scroll to \"OAuth Policies\" section</li> <li>Permitted Users: Change from \"All users may self-authorize\" to:</li> <li>\"Admin approved users are pre-authorized\"</li> <li>Click \"Save\"</li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#42-add-user-profilespermission-sets","title":"4.2 Add User Profiles/Permission Sets","text":"<ol> <li>Scroll down on the same page</li> <li>You'll see two sections:</li> <li>Profiles (Manage Profiles)</li> <li> <p>Permission Sets (Manage Permission Sets)</p> </li> <li> <p>Click \"Manage Profiles\"</p> </li> <li>Add your user's profile:</li> <li>For admin users: Select \"System Administrator\"</li> <li>For regular users: Select their profile (e.g., \"Standard User\")</li> <li>Click \"Save\"</li> </ol> <p>Alternative: If using Permission Sets: 1. Click \"Manage Permission Sets\" 2. Select the appropriate permission set 3. Click \"Save\"</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-5-configure-environment-variables","title":"Step 5: Configure Environment Variables","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># Salesforce JWT Authentication\nSF_CLIENT_ID=3MVG9XPlQYHF2jxAtyNlZrULLGJ...YOUR_CONSUMER_KEY_HERE\nSF_USERNAME=your.username@company.com.sandbox\nSF_PRIVATE_KEY_PATH=/absolute/path/to/certs/server.key\nSF_LOGIN_URL=https://test.salesforce.com\n\n# API Version\nSF_API_VERSION=v60.0\n\n# Logging\nLOG_DIR=./logs\nLOG_LEVEL=INFO\nLOG_CONSOLE_OUTPUT=true\nLOG_CONSOLE_COLORS=true\n</code></pre> <p>Replace with your values:</p> Variable Value Example <code>SF_CLIENT_ID</code> Consumer Key from Step 3 <code>3MVG9XPlQYHF2jx...</code> <code>SF_USERNAME</code> Your Salesforce username <code>admin@vuscom.com.dev1</code> <code>SF_PRIVATE_KEY_PATH</code> ABSOLUTE path to server.key <code>/Users/antonio/project/certs/server.key</code> <code>SF_LOGIN_URL</code> Sandbox: <code>https://test.salesforce.com</code>Production: <code>https://login.salesforce.com</code> <code>https://test.salesforce.com</code> <p>Critical: <code>SF_PRIVATE_KEY_PATH</code> must be an absolute path, not relative!</p> <p>How to get absolute path: - Windows: <code>C:\\Users\\YourName\\project\\certs\\server.key</code> - macOS/Linux: Run <code>pwd</code> in the certs folder, then append <code>/server.key</code></p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-6-test-authentication","title":"Step 6: Test Authentication","text":"<p>Create a test script <code>test_auth.py</code>:</p> <pre><code>from salesforce_toolkit import JWTAuthenticator\n\nprint(\"Testing JWT authentication...\")\n\ntry:\n    # Authenticate using .env configuration\n    auth = JWTAuthenticator.from_env()\n    session = auth.authenticate()\n\n    print(\"\\n\u2705 SUCCESS! Authentication successful!\")\n    print(f\"\ud83d\udccd Instance URL: {session.instance_url}\")\n    print(f\"\ud83d\udd27 API Version: {session.api_version}\")\n    print(f\"\ud83d\udc64 Username: {session.username}\")\n    print(f\"\ud83d\udd11 Access Token: {session.access_token[:20]}...\")\n\nexcept FileNotFoundError as e:\n    print(f\"\\n\u274c ERROR: Private key file not found\")\n    print(f\"   Make sure SF_PRIVATE_KEY_PATH in .env is an absolute path\")\n    print(f\"   Current value causes error: {e}\")\n\nexcept Exception as e:\n    print(f\"\\n\u274c ERROR: Authentication failed\")\n    print(f\"   Error: {e}\")\n    print(\"\\n\ud83d\udca1 Common issues:\")\n    print(\"   1. Consumer Key is incorrect\")\n    print(\"   2. User is not pre-authorized (Step 4)\")\n    print(\"   3. Wrong login URL (sandbox vs production)\")\n    print(\"   4. Connected App not fully processed (wait 10 minutes)\")\n</code></pre> <p>Run the test:</p> <pre><code>python test_auth.py\n</code></pre> <p>Expected output: <pre><code>Testing JWT authentication...\n\n\u2705 SUCCESS! Authentication successful!\n\ud83d\udccd Instance URL: https://vuscom--dev1.sandbox.my.salesforce.com\n\ud83d\udd27 API Version: v60.0\n\ud83d\udc64 Username: admin@vuscom.com.dev1\n\ud83d\udd11 Access Token: 00D5e000000abcd!AR...\n</code></pre></p>"},{"location":"SALESFORCE_SETUP_GUIDE/#method-2-oauth-password-flow","title":"Method 2: OAuth Password Flow","text":"<p>When to use: Development/testing only (not recommended for production)</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-1-create-connected-app","title":"Step 1: Create Connected App","text":"<p>Follow Steps 2.1 and 2.2 from JWT method above, BUT:</p> <p>In Step 2.3 (OAuth Settings): - \u2705 Enable OAuth Settings - Callback URL: <code>https://localhost</code> - Selected OAuth Scopes: Same as JWT - \u274c DO NOT check \"Use digital signatures\"</p> <p>Click \"Save\" and wait 2-10 minutes.</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-2-get-consumer-key-and-secret","title":"Step 2: Get Consumer Key and Secret","text":"<ol> <li>Go to Setup \u2192 App Manager \u2192 Your Connected App \u2192 View</li> <li>In the API (Enable OAuth Settings) section:</li> <li>Copy \"Consumer Key\"</li> <li>Click \"Click to reveal\" next to \"Consumer Secret\"</li> <li>Or click \"Manage Consumer Details\"</li> <li>Verify your identity (code via email)</li> <li>Copy \"Consumer Secret\"</li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-3-get-security-token","title":"Step 3: Get Security Token","text":"<ol> <li>Click your profile picture (top right) \u2192 \"Settings\"</li> <li>In the left menu, search for \"Reset My Security Token\"</li> <li>Or navigate: My Personal Information \u2192 Reset My Security Token</li> <li>Click \"Reset Security Token\"</li> <li>Check your email - you'll receive the new Security Token</li> <li>Copy the Security Token</li> </ol> <p>Note: The Security Token is appended to your password when authenticating.</p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-4-configure-env","title":"Step 4: Configure .env","text":"<pre><code># Salesforce OAuth Password Flow\nSF_CLIENT_ID=3MVG9XPlQYHF2jx...CONSUMER_KEY\nSF_CLIENT_SECRET=1234567890ABCDEF...CONSUMER_SECRET\nSF_USERNAME=your.username@company.com.sandbox\nSF_PASSWORD=YourPassword\nSF_SECURITY_TOKEN=ABC123XYZ...TOKEN_FROM_EMAIL\nSF_LOGIN_URL=https://test.salesforce.com\n\n# Logging\nLOG_DIR=./logs\nLOG_LEVEL=INFO\n</code></pre> <p>Important: - For sandbox, use <code>https://test.salesforce.com</code> - For production, use <code>https://login.salesforce.com</code></p>"},{"location":"SALESFORCE_SETUP_GUIDE/#step-5-test-authentication","title":"Step 5: Test Authentication","text":"<pre><code>from salesforce_toolkit import OAuthAuthenticator\n\nprint(\"Testing OAuth authentication...\")\n\ntry:\n    auth = OAuthAuthenticator.from_env()\n    session = auth.authenticate()\n\n    print(\"\\n\u2705 SUCCESS! Authentication successful!\")\n    print(f\"\ud83d\udccd Instance URL: {session.instance_url}\")\n    print(f\"\ud83d\udc64 Username: {session.username}\")\n\nexcept Exception as e:\n    print(f\"\\n\u274c ERROR: {e}\")\n</code></pre>"},{"location":"SALESFORCE_SETUP_GUIDE/#testing-your-setup","title":"Testing Your Setup","text":"<p>Once authenticated, test basic operations:</p> <pre><code>from salesforce_toolkit import JWTAuthenticator, SalesforceClient\n\n# Authenticate\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\n# Test 1: Query existing records\nprint(\"\\n\ud83d\udcca Test 1: Querying Accounts...\")\naccounts = client.query(\"SELECT Id, Name FROM Account LIMIT 5\")\nprint(f\"\u2705 Found {len(accounts)} accounts\")\nfor acc in accounts:\n    print(f\"  - {acc['Name']} ({acc['Id']})\")\n\n# Test 2: Create a test record\nprint(\"\\n\u2795 Test 2: Creating test Account...\")\naccount_id = client.create(\"Account\", {\n    \"Name\": \"Test Account - DELETE ME\",\n    \"Phone\": \"555-0100\"\n})\nprint(f\"\u2705 Created Account: {account_id}\")\n\n# Test 3: Update the record\nprint(\"\\n\u270f\ufe0f Test 3: Updating Account...\")\nclient.update(\"Account\", account_id, {\"Phone\": \"555-9999\"})\nprint(f\"\u2705 Updated Account\")\n\n# Test 4: Delete the record\nprint(\"\\n\ud83d\uddd1\ufe0f Test 4: Deleting Account...\")\nclient.delete(\"Account\", account_id)\nprint(f\"\u2705 Deleted Account\")\n\nprint(\"\\n\ud83c\udf89 All tests passed!\")\n</code></pre>"},{"location":"SALESFORCE_SETUP_GUIDE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"SALESFORCE_SETUP_GUIDE/#error-invalid_grant","title":"Error: \"invalid_grant\"","text":"<p>Symptoms: <code>Authentication failed: invalid_grant</code></p> <p>Causes &amp; Solutions:</p> <ol> <li>User not pre-authorized (most common)</li> <li>\u2705 Go to Connected App \u2192 Manage \u2192 Edit Policies</li> <li>\u2705 Set \"Permitted Users\" to \"Admin approved users are pre-authorized\"</li> <li> <p>\u2705 Add user profile via \"Manage Profiles\"</p> </li> <li> <p>Consumer Key is incorrect</p> </li> <li>\u2705 Double-check <code>SF_CLIENT_ID</code> in <code>.env</code></li> <li> <p>\u2705 Make sure you copied the entire key</p> </li> <li> <p>Certificate mismatch (JWT only)</p> </li> <li>\u2705 Regenerate certificate and re-upload to Salesforce</li> <li> <p>\u2705 Make sure <code>server.crt</code> and <code>server.key</code> are from the same generation</p> </li> <li> <p>Wrong login URL</p> </li> <li>\u2705 Sandbox: <code>https://test.salesforce.com</code></li> <li> <p>\u2705 Production: <code>https://login.salesforce.com</code></p> </li> <li> <p>Connected App not ready</p> </li> <li>\u2705 Wait 2-10 minutes after creating/editing the Connected App</li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#error-filenotfounderror-private-key-file-not-found","title":"Error: \"FileNotFoundError: Private key file not found\"","text":"<p>Cause: <code>SF_PRIVATE_KEY_PATH</code> is incorrect or relative</p> <p>Solutions: <pre><code># Get absolute path (macOS/Linux)\ncd /path/to/certs\npwd  # Copy this path\n# Then in .env: SF_PRIVATE_KEY_PATH=/absolute/path/to/certs/server.key\n\n# Get absolute path (Windows)\ncd C:\\path\\to\\certs\ncd  # Shows current directory\n# Then in .env: SF_PRIVATE_KEY_PATH=C:\\path\\to\\certs\\server.key\n</code></pre></p>"},{"location":"SALESFORCE_SETUP_GUIDE/#error-invalid_client_id","title":"Error: \"invalid_client_id\"","text":"<p>Cause: Consumer Key is incorrect</p> <p>Solution: 1. Go to Setup \u2192 App Manager \u2192 Your App \u2192 View 2. Copy \"Consumer Key\" again 3. Update <code>SF_CLIENT_ID</code> in <code>.env</code></p>"},{"location":"SALESFORCE_SETUP_GUIDE/#error-invalid_client_credentials-oauth-only","title":"Error: \"invalid_client_credentials\" (OAuth only)","text":"<p>Cause: Consumer Secret is incorrect</p> <p>Solution: 1. Go to Setup \u2192 App Manager \u2192 Your App \u2192 View 2. Click \"Manage Consumer Details\" 3. Verify identity 4. Copy \"Consumer Secret\" 5. Update <code>SF_CLIENT_SECRET</code> in <code>.env</code></p>"},{"location":"SALESFORCE_SETUP_GUIDE/#error-authentication-failure-oauth-only","title":"Error: \"authentication failure\" (OAuth only)","text":"<p>Cause: Incorrect password or security token</p> <p>Solution: 1. Verify <code>SF_PASSWORD</code> is correct 2. Reset Security Token (Settings \u2192 Reset My Security Token) 3. Update <code>SF_SECURITY_TOKEN</code> in <code>.env</code></p>"},{"location":"SALESFORCE_SETUP_GUIDE/#security-best-practices","title":"Security Best Practices","text":""},{"location":"SALESFORCE_SETUP_GUIDE/#do","title":"DO \u2705","text":"<ol> <li> <p>Store keys securely <pre><code>chmod 600 certs/server.key  # Restrict access\n</code></pre></p> </li> <li> <p>Use .gitignore <pre><code>.env\ncerts/server.key\n*.key\n*.pem\n</code></pre></p> </li> <li> <p>Rotate certificates regularly</p> </li> <li> <p>Regenerate every 6-12 months</p> </li> <li> <p>Use separate Connected Apps</p> </li> <li>One for development</li> <li> <p>One for production</p> </li> <li> <p>Restrict IP ranges (if possible)</p> </li> <li> <p>Connected App \u2192 Manage \u2192 Edit Policies \u2192 IP Relaxation</p> </li> <li> <p>Monitor API usage</p> </li> <li>Setup \u2192 System Overview \u2192 API Usage</li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#dont","title":"DON'T \u274c","text":"<ol> <li>\u274c Commit <code>.env</code> or <code>server.key</code> to git</li> <li>\u274c Share Consumer Secret publicly</li> <li>\u274c Use OAuth password flow in production</li> <li>\u274c Use same credentials for dev and prod</li> <li>\u274c Give \"Full Access\" to users who don't need it</li> </ol>"},{"location":"SALESFORCE_SETUP_GUIDE/#quick-reference","title":"Quick Reference","text":""},{"location":"SALESFORCE_SETUP_GUIDE/#file-locations","title":"File Locations","text":"<pre><code>your-project/\n\u251c\u2500\u2500 .env                    # Configuration (NEVER commit!)\n\u251c\u2500\u2500 certs/\n\u2502   \u251c\u2500\u2500 server.key          # Private key (NEVER commit!)\n\u2502   \u2514\u2500\u2500 server.crt          # Certificate (upload to Salesforce)\n\u2514\u2500\u2500 your_script.py\n</code></pre>"},{"location":"SALESFORCE_SETUP_GUIDE/#environment-variables-jwt","title":"Environment Variables (JWT)","text":"<pre><code>SF_CLIENT_ID=3MVG9...       # From Salesforce Connected App\nSF_USERNAME=user@domain     # Your Salesforce username\nSF_PRIVATE_KEY_PATH=/abs/path/server.key  # ABSOLUTE path\nSF_LOGIN_URL=https://test.salesforce.com  # or login.salesforce.com\n</code></pre>"},{"location":"SALESFORCE_SETUP_GUIDE/#environment-variables-oauth","title":"Environment Variables (OAuth)","text":"<pre><code>SF_CLIENT_ID=3MVG9...       # Consumer Key\nSF_CLIENT_SECRET=12345...   # Consumer Secret\nSF_USERNAME=user@domain\nSF_PASSWORD=yourpassword\nSF_SECURITY_TOKEN=ABC123... # From email\nSF_LOGIN_URL=https://test.salesforce.com\n</code></pre>"},{"location":"SALESFORCE_SETUP_GUIDE/#next-steps","title":"Next Steps","text":"<p>After successful authentication:</p> <ol> <li>\u2705 Try the Quick Start Guide</li> <li>\u2705 Run the Examples</li> <li>\u2705 Read the README</li> <li>\u2705 Build your first pipeline</li> </ol> <p>Need help? - Check INSTALLATION.md for more details - Open an issue on GitHub - Read the Troubleshooting section above</p> <p>\u2728 You're all set! Happy coding!</p>"},{"location":"TESTING_GUIDE/","title":"Testing Quick Start Guide","text":"<p>This guide helps you verify that <code>salesforce-toolkit</code> is correctly installed and functional.</p>"},{"location":"TESTING_GUIDE/#docker-method-recommended","title":"\ud83d\udc33 Docker Method (Recommended)","text":"<p>If you are using Docker, verification is extremely simple.</p> <p>1. Run Tests: <pre><code>docker-compose build\ndocker-compose run tests\n</code></pre></p> <p>2. Verify CLI: <pre><code>docker-compose run toolkit --help\n</code></pre></p>"},{"location":"TESTING_GUIDE/#manual-python-method","title":"\ud83d\udc0d Manual Python Method","text":"<p>If you prefer to run locally without Docker, follow these steps:</p>"},{"location":"TESTING_GUIDE/#1-environment-setup","title":"1. Environment Setup","text":"<p>First, ensure all dependencies are installed. The toolkit requires Python 3.8+.</p> <pre><code># Install production dependencies\npip install -r requirements.txt\n\n# Install development dependencies (needed for testing)\npip install -e \".[dev]\"\n</code></pre>"},{"location":"TESTING_GUIDE/#2-verification-steps","title":"2. Verification Steps","text":""},{"location":"TESTING_GUIDE/#a-cli-sanity-check","title":"A. CLI Sanity Check","text":"<p>Verify that the Command Line Interface loads correctly. This confirms that all Python modules are importable.</p> <p><pre><code>python cli.py --help\n</code></pre> Expected Output: A help message listing available commands (<code>auth</code>, <code>query</code>, <code>create</code>, etc.).</p>"},{"location":"TESTING_GUIDE/#b-authentication-test-dry-run","title":"B. Authentication Test (Dry Run)","text":"<p>You can verify the authentication modules without connecting to Salesforce by checking if the classes instantiate.</p> <p>Create a file named <code>verify_install.py</code>:</p> <pre><code>import sys\nfrom salesforce_toolkit import JWTAuthenticator, SalesforceClient\n\nprint(\"Verifying imports and classes...\")\ntry:\n    # Check if classes are available\n    assert JWTAuthenticator\n    assert SalesforceClient\n    print(\"\u2705 Core modules imported successfully.\")\nexcept ImportError as e:\n    print(f\"\u274c Import failed: {e}\")\n    sys.exit(1)\nexcept Exception as e:\n    print(f\"\u274c Unexpected error: {e}\")\n    sys.exit(1)\n</code></pre> <p>Run it: <pre><code>python verify_install.py\n</code></pre></p>"},{"location":"TESTING_GUIDE/#3-running-tests","title":"3. Running Tests","text":"<p>Note: The <code>tests/</code> directory is currently empty. To fully verify functionality, unit tests needed to be added.</p> <p>Once tests are added, you can run them using <code>pytest</code>:</p> <pre><code>pytest\n</code></pre>"},{"location":"TESTING_GUIDE/#4-connection-test-requires-credentials","title":"4. Connection Test (Requires Credentials)","text":"<p>To test actual connectivity, you need a Salesforce instance.</p> <ol> <li>Create a <code>.env</code> file based on <code>config/.env.example</code>.</li> <li>run:    <pre><code>python cli.py auth --method jwt\n</code></pre> or <pre><code>python cli.py auth --method oauth\n</code></pre></li> </ol>"},{"location":"USER_GUIDE/","title":"Kinetic Core - Complete User Guide","text":"<p>Complete guide to using Kinetic Core for Salesforce integration.</p> <p>Part of the KineticMCP ecosystem - AI-powered Salesforce integration tools by Antonio Trento</p>"},{"location":"USER_GUIDE/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Getting Started</li> <li>Authentication</li> <li>Basic Operations</li> <li>Bulk Operations</li> <li>Field Mapping</li> <li>ETL Pipelines</li> <li>Best Practices</li> <li>Troubleshooting</li> </ol>"},{"location":"USER_GUIDE/#getting-started","title":"Getting Started","text":""},{"location":"USER_GUIDE/#installation","title":"Installation","text":"<pre><code>pip install kinetic-core\n</code></pre>"},{"location":"USER_GUIDE/#quick-start","title":"Quick Start","text":"<pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\n\n# 1. Authenticate\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\n\n# 2. Create client\nclient = SalesforceClient(session)\n\n# 3. Use it!\naccounts = client.query(\"SELECT Id, Name FROM Account LIMIT 5\")\nfor account in accounts:\n    print(f\"{account['Name']} - {account['Id']}\")\n</code></pre>"},{"location":"USER_GUIDE/#authentication","title":"Authentication","text":"<p>Kinetic Core supports two authentication methods:</p>"},{"location":"USER_GUIDE/#jwt-authentication-recommended","title":"JWT Authentication (Recommended)","text":"<p>Best for: Production environments, CI/CD pipelines, automated scripts</p> <p>Setup:</p> <ol> <li>Create a Connected App in Salesforce</li> <li>Upload your certificate</li> <li>Configure environment variables</li> </ol> <p>Environment Variables: <pre><code># Required\nSALESFORCE_CLIENT_ID=your_consumer_key\nSALESFORCE_USERNAME=your_username\nSALESFORCE_PRIVATE_KEY_PATH=/path/to/server.key\n\n# Optional\nSALESFORCE_LOGIN_URL=https://login.salesforce.com  # or test.salesforce.com for sandbox\n</code></pre></p> <p>Usage: <pre><code>from kinetic_core import JWTAuthenticator\n\n# Load from environment\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\n\n# Or configure manually\nauth = JWTAuthenticator(\n    client_id=\"your_consumer_key\",\n    username=\"your_username\",\n    private_key_path=\"/path/to/server.key\",\n    login_url=\"https://login.salesforce.com\"\n)\nsession = auth.authenticate()\n</code></pre></p>"},{"location":"USER_GUIDE/#oauth-20-password-flow","title":"OAuth 2.0 Password Flow","text":"<p>Best for: Development, testing, quick prototypes</p> <p>Environment Variables: <pre><code>SALESFORCE_CLIENT_ID=your_consumer_key\nSALESFORCE_CLIENT_SECRET=your_consumer_secret\nSALESFORCE_USERNAME=your_username\nSALESFORCE_PASSWORD=your_password\nSALESFORCE_SECURITY_TOKEN=your_security_token\n</code></pre></p> <p>Usage: <pre><code>from kinetic_core import OAuthAuthenticator\n\n# Load from environment\nauth = OAuthAuthenticator.from_env()\nsession = auth.authenticate()\n</code></pre></p> <p>See Also: Complete Authentication Reference</p>"},{"location":"USER_GUIDE/#basic-operations","title":"Basic Operations","text":""},{"location":"USER_GUIDE/#crud-operations","title":"CRUD Operations","text":""},{"location":"USER_GUIDE/#create-records","title":"Create Records","text":"<pre><code>from kinetic_core import SalesforceClient\n\n# Create single record\naccount_id = client.create(\"Account\", {\n    \"Name\": \"ACME Corporation\",\n    \"Industry\": \"Technology\",\n    \"AnnualRevenue\": 5000000,\n    \"BillingCity\": \"San Francisco\"\n})\n\nprint(f\"Created Account: {account_id}\")\n</code></pre>"},{"location":"USER_GUIDE/#read-records","title":"Read Records","text":"<pre><code># Get by ID\naccount = client.get(\"Account\", \"001xxx000001AAA\")\nprint(account['Name'])\n\n# Query with SOQL\naccounts = client.query(\n    \"SELECT Id, Name, Industry FROM Account WHERE Industry = 'Technology'\"\n)\n\nfor account in accounts:\n    print(f\"{account['Name']} - {account['Industry']}\")\n</code></pre>"},{"location":"USER_GUIDE/#update-records","title":"Update Records","text":"<pre><code># Update single record\nclient.update(\"Account\", \"001xxx000001\", {\n    \"Phone\": \"555-1234\",\n    \"Industry\": \"Software\"\n})\n\nprint(\"Account updated!\")\n</code></pre>"},{"location":"USER_GUIDE/#delete-records","title":"Delete Records","text":"<pre><code># Delete single record\nclient.delete(\"Account\", \"001xxx000001\")\nprint(\"Account deleted!\")\n</code></pre>"},{"location":"USER_GUIDE/#upsert-records","title":"Upsert Records","text":"<pre><code># Insert or update based on external ID\nresult = client.upsert(\n    sobject=\"Account\",\n    external_id_field=\"External_Key__c\",\n    external_id_value=\"EXT-001\",\n    data={\n        \"Name\": \"ACME Corp\",\n        \"Industry\": \"Technology\"\n    }\n)\n\nif result['created']:\n    print(f\"Created new record: {result['id']}\")\nelse:\n    print(f\"Updated existing: {result['id']}\")\n</code></pre>"},{"location":"USER_GUIDE/#batch-operations","title":"Batch Operations","text":"<p>For 2-200 records, use Composite API:</p> <pre><code># Create multiple records\naccounts = [\n    {\"Name\": \"Account 1\", \"Industry\": \"Tech\"},\n    {\"Name\": \"Account 2\", \"Industry\": \"Finance\"},\n    {\"Name\": \"Account 3\", \"Industry\": \"Retail\"}\n]\n\nresult = client.create_bulk(\"Account\", accounts)\n\n# Check results\nfor item in result['compositeResponse']:\n    if item['httpStatusCode'] == 201:\n        print(f\"Created: {item['body']['id']}\")\n    else:\n        print(f\"Failed: {item['body'][0]['message']}\")\n</code></pre> <p>See Also: Complete CRUD Reference</p>"},{"location":"USER_GUIDE/#bulk-operations","title":"Bulk Operations","text":"<p>For high-volume operations (&gt; 2,000 records), use Bulk API v2.</p>"},{"location":"USER_GUIDE/#bulk-insert","title":"Bulk Insert","text":"<pre><code># Prepare large dataset\naccounts = [\n    {\"Name\": f\"Account {i}\", \"Industry\": \"Technology\"}\n    for i in range(10000)\n]\n\n# Bulk insert\nresult = client.bulk.insert(\"Account\", accounts)\n\nprint(f\"Success: {result.success_count}\")\nprint(f\"Failed: {result.failed_count}\")\n\n# Get created IDs\nfor record in result.success_records:\n    print(f\"Created: {record['sf__Id']}\")\n</code></pre>"},{"location":"USER_GUIDE/#bulk-update","title":"Bulk Update","text":"<pre><code># Prepare updates (must include Id)\nupdates = [\n    {\"Id\": \"001xxx000001\", \"Industry\": \"Software\"},\n    {\"Id\": \"001xxx000002\", \"Industry\": \"Hardware\"}\n]\n\nresult = client.bulk.update(\"Account\", updates)\n\nif result.failed_count &gt; 0:\n    for error in result.errors:\n        print(f\"Error: {error.message}\")\n</code></pre>"},{"location":"USER_GUIDE/#bulk-upsert","title":"Bulk Upsert","text":"<pre><code># Use external ID to prevent duplicates\nrecords = [\n    {\"External_Key__c\": \"EXT001\", \"Name\": \"Company 1\"},\n    {\"External_Key__c\": \"EXT002\", \"Name\": \"Company 2\"}\n]\n\nresult = client.bulk.upsert(\n    \"Account\",\n    records,\n    external_id_field=\"External_Key__c\"\n)\n\nprint(f\"Inserted/Updated: {result.success_count}\")\n</code></pre>"},{"location":"USER_GUIDE/#bulk-query","title":"Bulk Query","text":"<pre><code># Query large dataset\nquery = \"\"\"\n    SELECT Id, Name, Industry, AnnualRevenue\n    FROM Account\n    WHERE CreatedDate = THIS_YEAR\n\"\"\"\n\nresult = client.bulk.query(query)\n\nprint(f\"Retrieved {result.record_count} records\")\n\n# Process results\nfor account in result.records:\n    print(f\"{account['Name']} - {account['Industry']}\")\n</code></pre>"},{"location":"USER_GUIDE/#progress-tracking","title":"Progress Tracking","text":"<pre><code>def show_progress(job):\n    print(f\"State: {job.state}\")\n    print(f\"Processed: {job.number_records_processed}\")\n\nresult = client.bulk.insert(\n    \"Account\",\n    large_dataset,\n    on_progress=show_progress\n)\n</code></pre> <p>See Also: - Bulk API v2 Reference - Bulk Quick Start - Bulk Examples</p>"},{"location":"USER_GUIDE/#field-mapping","title":"Field Mapping","text":"<p>Transform data between different schemas with <code>FieldMapper</code>.</p>"},{"location":"USER_GUIDE/#basic-mapping","title":"Basic Mapping","text":"<pre><code>from kinetic_core import FieldMapper\n\n# Simple field renaming\nmapper = FieldMapper({\n    \"customer_name\": \"Name\",\n    \"customer_email\": \"Email\",\n    \"customer_phone\": \"Phone\"\n})\n\nsource = {\n    \"customer_name\": \"ACME Corp\",\n    \"customer_email\": \"info@acme.com\",\n    \"customer_phone\": \"555-1234\"\n}\n\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Name\": \"ACME Corp\",\n#   \"Email\": \"info@acme.com\",\n#   \"Phone\": \"555-1234\"\n# }\n</code></pre>"},{"location":"USER_GUIDE/#with-transformations","title":"With Transformations","text":"<pre><code># Apply custom transformations\nmapper = FieldMapper({\n    \"name\": \"Name\",\n    \"email\": (\"Email\", lambda x: x.lower()),\n    \"revenue\": (\"AnnualRevenue\", lambda x: float(x.replace(\"$\", \"\").replace(\",\", \"\"))),\n    \"employees\": (\"NumberOfEmployees\", int)\n})\n\nsource = {\n    \"name\": \"ACME Corp\",\n    \"email\": \"INFO@ACME.COM\",\n    \"revenue\": \"$5,000,000\",\n    \"employees\": \"250\"\n}\n\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Name\": \"ACME Corp\",\n#   \"Email\": \"info@acme.com\",\n#   \"AnnualRevenue\": 5000000.0,\n#   \"NumberOfEmployees\": 250\n# }\n</code></pre>"},{"location":"USER_GUIDE/#with-default-values","title":"With Default Values","text":"<pre><code># Provide defaults for missing fields\nmapper = FieldMapper({\n    \"name\": \"Name\",\n    \"email\": \"Email\",\n    \"status\": (\"Status__c\", None, \"Active\"),\n    \"created_date\": (\"CreatedDate\", None, \"2025-01-02\")\n})\n\nsource = {\"name\": \"ACME Corp\", \"email\": \"info@acme.com\"}\n\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Name\": \"ACME Corp\",\n#   \"Email\": \"info@acme.com\",\n#   \"Status__c\": \"Active\",         # Used default\n#   \"CreatedDate\": \"2025-01-02\"    # Used default\n# }\n</code></pre>"},{"location":"USER_GUIDE/#nested-fields","title":"Nested Fields","text":"<pre><code># Access nested data with dot notation\nsource = {\n    \"company\": {\n        \"name\": \"ACME Corp\",\n        \"contact\": {\n            \"email\": \"info@acme.com\",\n            \"phone\": \"555-1234\"\n        }\n    }\n}\n\nmapper = FieldMapper({\n    \"company.name\": \"Name\",\n    \"company.contact.email\": \"Email\",\n    \"company.contact.phone\": \"Phone\"\n})\n\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Name\": \"ACME Corp\",\n#   \"Email\": \"info@acme.com\",\n#   \"Phone\": \"555-1234\"\n# }\n</code></pre>"},{"location":"USER_GUIDE/#batch-transformation","title":"Batch Transformation","text":"<pre><code># Transform multiple records\nrecords = [\n    {\"name\": \"Alice\", \"age\": 30},\n    {\"name\": \"Bob\", \"age\": 25},\n    {\"name\": \"Charlie\", \"age\": 35}\n]\n\nmapper = FieldMapper({\n    \"name\": \"Name\",\n    \"age\": \"Age__c\"\n})\n\nresults = mapper.transform_batch(records)\n\nfor result in results:\n    print(result)\n# {\"Name\": \"Alice\", \"Age__c\": 30}\n# {\"Name\": \"Bob\", \"Age__c\": 25}\n# {\"Name\": \"Charlie\", \"Age__c\": 35}\n</code></pre> <p>See Also: Complete Field Mapping Reference</p>"},{"location":"USER_GUIDE/#etl-pipelines","title":"ETL Pipelines","text":"<p>Orchestrate complete data synchronization workflows with <code>SyncPipeline</code>.</p>"},{"location":"USER_GUIDE/#basic-pipeline","title":"Basic Pipeline","text":"<pre><code>from kinetic_core import FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\n# Setup mapping\nmapper = FieldMapper({\n    \"customer_name\": \"Name\",\n    \"customer_email\": \"Email\",\n    \"customer_phone\": \"Phone\"\n})\n\n# Create pipeline\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT\n)\n\n# Prepare data\nsource_data = [\n    {\"customer_name\": \"ACME\", \"customer_email\": \"info@acme.com\"},\n    {\"customer_name\": \"Globex\", \"customer_email\": \"contact@globex.com\"}\n]\n\n# Execute sync\nresult = pipeline.sync(source_data)\n\nprint(f\"Success: {result.success_count}/{result.total_records}\")\nprint(f\"Failed: {result.error_count}\")\n</code></pre>"},{"location":"USER_GUIDE/#sync-modes","title":"Sync Modes","text":""},{"location":"USER_GUIDE/#insert-mode","title":"INSERT Mode","text":"<pre><code># Create new records\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT\n)\n\ndata = [{\"Name\": \"Company 1\"}, {\"Name\": \"Company 2\"}]\nresult = pipeline.sync(data)\n</code></pre>"},{"location":"USER_GUIDE/#update-mode","title":"UPDATE Mode","text":"<pre><code># Update existing records (requires Id)\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.UPDATE\n)\n\ndata = [\n    {\"Id\": \"001xxx000001\", \"Phone\": \"555-1111\"},\n    {\"Id\": \"001xxx000002\", \"Phone\": \"555-2222\"}\n]\n\nresult = pipeline.sync(data)\n</code></pre>"},{"location":"USER_GUIDE/#upsert-mode","title":"UPSERT Mode","text":"<pre><code># Insert or update based on external ID\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.UPSERT,\n    external_id_field=\"External_Key__c\"\n)\n\ndata = [\n    {\"External_Key__c\": \"EXT001\", \"Name\": \"ACME\"},\n    {\"External_Key__c\": \"EXT002\", \"Name\": \"Globex\"}\n]\n\nresult = pipeline.sync(data)\n</code></pre>"},{"location":"USER_GUIDE/#progress-callbacks","title":"Progress Callbacks","text":"<pre><code>def on_batch(batch_num, total_batches, result):\n    print(f\"Batch {batch_num}/{total_batches} complete\")\n    print(f\"  Success: {result.success_count}\")\n    print(f\"  Errors: {result.error_count}\")\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT,\n    callbacks={\"on_batch_complete\": on_batch}\n)\n\nresult = pipeline.sync(large_dataset)\n</code></pre>"},{"location":"USER_GUIDE/#configuration-driven-pipeline","title":"Configuration-Driven Pipeline","text":"<pre><code># Define configuration\nconfig = {\n    \"sobject\": \"Account\",\n    \"mode\": \"upsert\",\n    \"external_id_field\": \"External_Key__c\",\n    \"batch_size\": 100,\n    \"mapping\": {\n        \"ext_id\": \"External_Key__c\",\n        \"company\": \"Name\",\n        \"email\": (\"Email\", lambda x: x.lower())\n    }\n}\n\n# Create from config\npipeline = SyncPipeline.from_config(config, client)\n\n# Use as normal\nresult = pipeline.sync(data)\n</code></pre> <p>See Also: Complete Pipelines Reference</p>"},{"location":"USER_GUIDE/#best-practices","title":"Best Practices","text":""},{"location":"USER_GUIDE/#1-choose-the-right-api","title":"1. Choose the Right API","text":"Records Recommended Method 1 <code>client.create()</code> 2-200 <code>client.create_bulk()</code> 200-2,000 Loop with batches &gt; 2,000 <code>client.bulk.insert()</code> <pre><code># Good: Use Bulk API for large datasets\nif len(records) &gt; 2000:\n    result = client.bulk.insert(\"Account\", records)\nelse:\n    result = client.create_bulk(\"Account\", records)\n</code></pre>"},{"location":"USER_GUIDE/#2-use-external-ids","title":"2. Use External IDs","text":"<pre><code># Good: Prevents duplicates\nresult = client.bulk.upsert(\n    \"Account\",\n    records,\n    external_id_field=\"External_Key__c\"\n)\n\n# Bad: May create duplicates\nresult = client.bulk.insert(\"Account\", records)\n</code></pre>"},{"location":"USER_GUIDE/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<pre><code>result = client.bulk.insert(\"Account\", records)\n\nif result.failed_count &gt; 0:\n    print(f\"\u26a0\ufe0f  {result.failed_count} records failed\")\n\n    # Log errors\n    with open(\"errors.log\", \"w\") as f:\n        for error in result.errors:\n            f.write(f\"{error.message}\\n\")\n\n    # Retry failed records\n    failed_records = result.failed_records\n    # ... implement retry logic\n</code></pre>"},{"location":"USER_GUIDE/#4-validate-data","title":"4. Validate Data","text":"<pre><code>def validate_account(data):\n    \"\"\"Validate before creating\"\"\"\n    required = ['Name']\n    for field in required:\n        if field not in data or not data[field]:\n            raise ValueError(f\"Missing required field: {field}\")\n\n    if 'AnnualRevenue' in data:\n        if not isinstance(data['AnnualRevenue'], (int, float)):\n            raise ValueError(\"AnnualRevenue must be numeric\")\n\n# Validate before insert\nfor record in records:\n    validate_account(record)\n\nresult = client.bulk.insert(\"Account\", records)\n</code></pre>"},{"location":"USER_GUIDE/#5-use-field-mapping","title":"5. Use Field Mapping","text":"<pre><code># Good: Centralized transformation logic\nmapper = FieldMapper({\n    \"cust_name\": \"Name\",\n    \"cust_email\": (\"Email\", lambda x: x.lower())\n})\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper\n)\n\n# Bad: Manual transformation\ntransformed = [\n    {\"Name\": rec[\"cust_name\"], \"Email\": rec[\"cust_email\"].lower()}\n    for rec in records\n]\n</code></pre>"},{"location":"USER_GUIDE/#6-monitor-performance","title":"6. Monitor Performance","text":"<pre><code>result = pipeline.sync(data)\n\n# Check metrics\nprint(f\"Duration: {result.metadata['elapsed_seconds']}s\")\nprint(f\"Throughput: {result.metadata['records_per_second']} rec/sec\")\n\n# Adjust if needed\nif result.metadata['records_per_second'] &lt; 50:\n    print(\"Consider using larger batch_size or Bulk API\")\n</code></pre>"},{"location":"USER_GUIDE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"USER_GUIDE/#authentication-errors","title":"Authentication Errors","text":"<p>Problem: <code>AuthenticationError: Invalid credentials</code></p> <p>Solutions: 1. Check environment variables are set correctly 2. Verify certificate path for JWT 3. Ensure security token is appended for OAuth 4. Check login URL (login.salesforce.com vs test.salesforce.com)</p> <pre><code># Debug authentication\nimport os\nprint(\"Client ID:\", os.getenv(\"SALESFORCE_CLIENT_ID\"))\nprint(\"Username:\", os.getenv(\"SALESFORCE_USERNAME\"))\nprint(\"Key exists:\", os.path.exists(os.getenv(\"SALESFORCE_PRIVATE_KEY_PATH\")))\n</code></pre>"},{"location":"USER_GUIDE/#query-errors","title":"Query Errors","text":"<p>Problem: <code>SalesforceAPIError: INVALID_FIELD</code></p> <p>Solution: Verify field API names</p> <pre><code># Check object metadata\nmetadata = client.describe(\"Account\")\n\n# List all fields\nfor field in metadata['fields']:\n    print(f\"{field['name']} ({field['type']})\")\n</code></pre>"},{"location":"USER_GUIDE/#bulk-api-timeouts","title":"Bulk API Timeouts","text":"<p>Problem: <code>TimeoutError: Job did not complete</code></p> <p>Solution: Increase timeout</p> <pre><code># Increase timeout for large datasets\nresult = client.bulk.query(\n    \"SELECT * FROM Account\",\n    timeout_minutes=30  # Default is 10\n)\n</code></pre>"},{"location":"USER_GUIDE/#rate-limit-errors","title":"Rate Limit Errors","text":"<p>Problem: <code>REQUEST_LIMIT_EXCEEDED</code></p> <p>Solutions: 1. Use Bulk API instead of standard API 2. Reduce batch sizes 3. Implement exponential backoff 4. Check org API limits</p> <pre><code># Check API usage (requires custom implementation)\n# Salesforce Limits API: /services/data/vXX.0/limits\n</code></pre>"},{"location":"USER_GUIDE/#data-validation-errors","title":"Data Validation Errors","text":"<p>Problem: <code>REQUIRED_FIELD_MISSING</code> or <code>INVALID_TYPE_FOR_FIELD</code></p> <p>Solution: Validate data before sync</p> <pre><code># Validate against Salesforce schema\nmetadata = client.describe(\"Account\")\n\nrequired_fields = [\n    field['name'] for field in metadata['fields']\n    if not field['nillable'] and field['createable']\n]\n\n# Check records\nfor record in records:\n    for field in required_fields:\n        if field not in record:\n            print(f\"Missing required field: {field}\")\n</code></pre>"},{"location":"USER_GUIDE/#real-world-examples","title":"Real-World Examples","text":""},{"location":"USER_GUIDE/#example-1-csv-import","title":"Example 1: CSV Import","text":"<pre><code>import csv\nfrom kinetic_core import SalesforceClient, FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\n# Read CSV\nwith open(\"customers.csv\", \"r\") as f:\n    reader = csv.DictReader(f)\n    csv_data = list(reader)\n\n# Setup mapping\nmapper = FieldMapper({\n    \"Company Name\": \"Name\",\n    \"Email\": (\"Email\", lambda x: x.lower()),\n    \"Phone\": \"Phone\",\n    \"Industry\": \"Industry\"\n})\n\n# Create pipeline\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT\n)\n\n# Import\nresult = pipeline.sync(csv_data)\n\nprint(f\"Imported {result.success_count} records\")\n</code></pre>"},{"location":"USER_GUIDE/#example-2-database-sync","title":"Example 2: Database Sync","text":"<pre><code>import psycopg2\nfrom kinetic_core import SalesforceClient, FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\n# Fetch from database\nconn = psycopg2.connect(\"dbname=mydb user=user\")\ncursor = conn.cursor()\ncursor.execute(\"SELECT id, name, email FROM customers\")\n\n# Convert to dict\ncolumns = [desc[0] for desc in cursor.description]\ndb_data = [dict(zip(columns, row)) for row in cursor.fetchall()]\n\n# Setup sync\nmapper = FieldMapper({\n    \"id\": \"External_Id__c\",\n    \"name\": \"Name\",\n    \"email\": (\"Email\", lambda x: x.lower())\n})\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.UPSERT,\n    external_id_field=\"External_Id__c\"\n)\n\n# Sync\nresult = pipeline.sync(db_data)\n\nprint(f\"Synced {result.success_count} records\")\nconn.close()\n</code></pre>"},{"location":"USER_GUIDE/#example-3-api-integration","title":"Example 3: API Integration","text":"<pre><code>import requests\nfrom kinetic_core import SalesforceClient, FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\n# Fetch from API\nresponse = requests.get(\"https://api.example.com/customers\")\napi_data = response.json()\n\n# Setup mapping for nested API response\nmapper = FieldMapper({\n    \"company.name\": \"Name\",\n    \"company.industry\": \"Industry\",\n    \"contact.email\": \"Email\",\n    \"contact.phone\": \"Phone\"\n})\n\n# Sync to Salesforce\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT\n)\n\nresult = pipeline.sync(api_data)\n\nprint(f\"Imported {result.success_count} accounts from API\")\n</code></pre>"},{"location":"USER_GUIDE/#additional-resources","title":"Additional Resources","text":""},{"location":"USER_GUIDE/#documentation","title":"Documentation","text":"<ul> <li>Authentication Guide</li> <li>CRUD Operations Reference</li> <li>Bulk API v2 Reference</li> <li>Field Mapping Guide</li> <li>Pipelines Reference</li> <li>Bulk Quick Start</li> <li>Bulk Examples</li> </ul>"},{"location":"USER_GUIDE/#external-resources","title":"External Resources","text":"<ul> <li>Salesforce REST API Documentation</li> <li>SOQL Reference</li> <li>Salesforce Bulk API v2</li> </ul>"},{"location":"USER_GUIDE/#community","title":"Community","text":"<ul> <li>GitHub Repository</li> <li>KineticMCP Website</li> <li>Report Issues</li> </ul>"},{"location":"USER_GUIDE/#about","title":"About","text":"<p>Kinetic Core is the foundational library powering the KineticMCP ecosystem.</p> <ul> <li>Author: Antonio Trento</li> <li>Website: KineticMCP.com</li> <li>License: MIT</li> <li>Version: 2.0.0</li> </ul> <p>Part of the KineticMCP ecosystem - AI-powered Salesforce integration tools.</p>"},{"location":"api/AUTHENTICATION/","title":"Authentication - Complete Reference","text":"<p>Complete guide to Salesforce authentication in Kinetic Core.</p>"},{"location":"api/AUTHENTICATION/#overview","title":"Overview","text":"<p>Kinetic Core supports two authentication methods: 1. JWT Bearer Flow (Recommended for production) 2. OAuth 2.0 Password Flow (For development/testing)</p> <p>Both methods provide a <code>SalesforceSession</code> object used by the <code>SalesforceClient</code>.</p>"},{"location":"api/AUTHENTICATION/#jwt-bearer-flow-recommended","title":"JWT Bearer Flow (Recommended)","text":""},{"location":"api/AUTHENTICATION/#why-jwt","title":"Why JWT?","text":"<p>\u2705 More Secure: No password storage required \u2705 Production-Ready: Recommended by Salesforce \u2705 No User Interaction: Fully automated \u2705 Longer Sessions: 2-hour token validity \u2705 Best for: Servers, batch jobs, integrations</p>"},{"location":"api/AUTHENTICATION/#prerequisites","title":"Prerequisites","text":"<ol> <li>Salesforce Connected App with:</li> <li>OAuth settings enabled</li> <li>JWT Bearer Flow enabled</li> <li>Certificate uploaded</li> <li> <p>Appropriate scopes granted</p> </li> <li> <p>Digital Certificate:</p> </li> <li>Private key (.key file)</li> <li> <p>Certificate (.crt file) uploaded to Salesforce</p> </li> <li> <p>User with API Access:</p> </li> <li>API Enabled permission</li> <li>Assigned to Connected App</li> </ol>"},{"location":"api/AUTHENTICATION/#quick-setup","title":"Quick Setup","text":""},{"location":"api/AUTHENTICATION/#1-generate-certificate","title":"1. Generate Certificate","text":"<pre><code># Generate private key\nopenssl genrsa -out server.key 2048\n\n# Generate certificate\nopenssl req -new -x509 -key server.key -out server.crt -days 365\n\n# Optional: Generate PKCS12 for backup\nopenssl pkcs12 -export -in server.crt -inkey server.key -out server.p12\n</code></pre>"},{"location":"api/AUTHENTICATION/#2-configure-connected-app","title":"2. Configure Connected App","text":"<ol> <li>Setup \u2192 App Manager \u2192 New Connected App</li> <li>Enable OAuth Settings</li> <li>Enable \"Use Digital Signatures\"</li> <li>Upload <code>server.crt</code></li> <li>Add scopes: <code>api</code>, <code>refresh_token</code>, <code>offline_access</code></li> <li>Save and note the Consumer Key (Client ID)</li> </ol>"},{"location":"api/AUTHENTICATION/#3-environment-variables","title":"3. Environment Variables","text":"<p>Create <code>.env</code> file:</p> <pre><code>SF_CLIENT_ID=3MVG9...your_consumer_key\nSF_USERNAME=integration@company.com.sandbox\nSF_PRIVATE_KEY_PATH=/path/to/server.key\nSF_LOGIN_URL=https://test.salesforce.com  # or https://login.salesforce.com\n</code></pre>"},{"location":"api/AUTHENTICATION/#usage","title":"Usage","text":""},{"location":"api/AUTHENTICATION/#from-environment-variables-recommended","title":"From Environment Variables (Recommended)","text":"<pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\n\n# Load from .env\nauth = JWTAuthenticator.from_env()\n\n# Authenticate\nsession = auth.authenticate()\n\n# Create client\nclient = SalesforceClient(session)\n</code></pre>"},{"location":"api/AUTHENTICATION/#manual-configuration","title":"Manual Configuration","text":"<pre><code>from kinetic_core import JWTAuthenticator\n\nauth = JWTAuthenticator(\n    client_id=\"3MVG9...\",\n    username=\"user@example.com\",\n    private_key_path=\"/path/to/server.key\",\n    login_url=\"https://test.salesforce.com\"\n)\n\nsession = auth.authenticate()\n</code></pre>"},{"location":"api/AUTHENTICATION/#using-private-key-string","title":"Using Private Key String","text":"<pre><code>private_key_content = \"\"\"\n-----BEGIN RSA PRIVATE KEY-----\nMIIEpAIBAAKCAQEA...\n-----END RSA PRIVATE KEY-----\n\"\"\"\n\nauth = JWTAuthenticator(\n    client_id=\"3MVG9...\",\n    username=\"user@example.com\",\n    private_key=private_key_content,  # Use key content instead of path\n    login_url=\"https://test.salesforce.com\"\n)\n\nsession = auth.authenticate()\n</code></pre>"},{"location":"api/AUTHENTICATION/#api-reference","title":"API Reference","text":""},{"location":"api/AUTHENTICATION/#jwtauthenticator-class","title":"JWTAuthenticator Class","text":"<pre><code>class JWTAuthenticator:\n    \"\"\"JWT Bearer Flow authenticator\"\"\"\n\n    def __init__(\n        self,\n        client_id: str,\n        username: str,\n        private_key: Optional[str] = None,\n        private_key_path: Optional[str] = None,\n        login_url: str = \"https://login.salesforce.com\"\n    )\n</code></pre> <p>Parameters: - <code>client_id</code> (str): Connected App Consumer Key - <code>username</code> (str): Salesforce username - <code>private_key</code> (str, optional): Private key content as string - <code>private_key_path</code> (str, optional): Path to private key file - <code>login_url</code> (str): Salesforce login URL (production or sandbox)</p> <p>Note: Must provide either <code>private_key</code> OR <code>private_key_path</code></p>"},{"location":"api/AUTHENTICATION/#methods","title":"Methods","text":""},{"location":"api/AUTHENTICATION/#from_env","title":"from_env()","text":"<p>Create authenticator from environment variables.</p> <pre><code>@classmethod\ndef from_env(cls) -&gt; JWTAuthenticator\n</code></pre> <p>Environment Variables Required: - <code>SF_CLIENT_ID</code>: Consumer Key - <code>SF_USERNAME</code>: Salesforce username - <code>SF_PRIVATE_KEY_PATH</code>: Path to private key - <code>SF_LOGIN_URL</code>: Login URL (optional, defaults to production)</p> <p>Returns: <code>JWTAuthenticator</code> instance</p> <p>Example: <pre><code>auth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\n</code></pre></p>"},{"location":"api/AUTHENTICATION/#authenticate","title":"authenticate()","text":"<p>Perform JWT authentication and get session.</p> <pre><code>def authenticate(self) -&gt; SalesforceSession\n</code></pre> <p>Returns: <code>SalesforceSession</code> with: - <code>access_token</code>: OAuth token - <code>instance_url</code>: Salesforce instance URL - <code>id</code>: User identity URL - <code>issued_at</code>: Token issue timestamp</p> <p>Raises: - <code>AuthenticationError</code>: If authentication fails - <code>FileNotFoundError</code>: If private key file not found - <code>ValueError</code>: If JWT creation fails</p> <p>Example: <pre><code>try:\n    session = auth.authenticate()\n    print(f\"Authenticated: {session.instance_url}\")\nexcept Exception as e:\n    print(f\"Authentication failed: {e}\")\n</code></pre></p>"},{"location":"api/AUTHENTICATION/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api/AUTHENTICATION/#common-issues","title":"Common Issues","text":"<p>Issue: <code>invalid_grant: user hasn't approved this consumer</code> - Solution: Pre-approve the Connected App for the user's profile</p> <p>Issue: <code>invalid_grant: IP restricted or invalid login hours</code> - Solution: Check IP restrictions and login hours in user profile</p> <p>Issue: <code>FileNotFoundError: Private key not found</code> - Solution: Verify <code>SF_PRIVATE_KEY_PATH</code> is correct and file exists</p> <p>Issue: <code>jwt expired</code> - Solution: JWT tokens expire in 3 minutes. This is normal during generation, not usage.</p>"},{"location":"api/AUTHENTICATION/#debug-mode","title":"Debug Mode","text":"<pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()  # Will print debug info\n</code></pre>"},{"location":"api/AUTHENTICATION/#oauth-20-password-flow","title":"OAuth 2.0 Password Flow","text":""},{"location":"api/AUTHENTICATION/#why-oauth-password-flow","title":"Why OAuth Password Flow?","text":"<p>\u2705 Easy Setup: No certificates required \u2705 Quick Testing: Fast for development \u2705 User-Based: Uses user credentials \u26a0\ufe0f Less Secure: Stores password \u274c Not Recommended: For production use</p>"},{"location":"api/AUTHENTICATION/#prerequisites_1","title":"Prerequisites","text":"<ol> <li>Salesforce Connected App with:</li> <li>OAuth settings enabled</li> <li>Password flow enabled</li> <li> <p>Appropriate scopes</p> </li> <li> <p>User Credentials:</p> </li> <li>Username</li> <li>Password</li> <li> <p>Security Token (if IP not whitelisted)</p> </li> <li> <p>Consumer Key &amp; Secret:</p> </li> <li>From Connected App</li> </ol>"},{"location":"api/AUTHENTICATION/#setup","title":"Setup","text":""},{"location":"api/AUTHENTICATION/#1-configure-connected-app","title":"1. Configure Connected App","text":"<ol> <li>Setup \u2192 App Manager \u2192 New Connected App</li> <li>Enable OAuth Settings</li> <li>Add callback URL (can be dummy)</li> <li>Add scopes: <code>api</code>, <code>refresh_token</code></li> <li>Save and note:</li> <li>Consumer Key (Client ID)</li> <li>Consumer Secret (Click \"Manage Consumer Details\")</li> </ol>"},{"location":"api/AUTHENTICATION/#2-get-security-token","title":"2. Get Security Token","text":"<ol> <li>Setup \u2192 Reset My Security Token</li> <li>Check email for token</li> <li>Token = password + security token concatenated</li> </ol>"},{"location":"api/AUTHENTICATION/#3-environment-variables_1","title":"3. Environment Variables","text":"<pre><code>SF_CLIENT_ID=3MVG9...your_consumer_key\nSF_CLIENT_SECRET=1234567890ABCDEF...\nSF_USERNAME=user@example.com\nSF_PASSWORD=YourPassword\nSF_SECURITY_TOKEN=ABC123XYZ789\nSF_LOGIN_URL=https://login.salesforce.com\n</code></pre>"},{"location":"api/AUTHENTICATION/#usage_1","title":"Usage","text":""},{"location":"api/AUTHENTICATION/#from-environment-variables","title":"From Environment Variables","text":"<pre><code>from kinetic_core import OAuthAuthenticator, SalesforceClient\n\n# Load from .env\nauth = OAuthAuthenticator.from_env()\n\n# Authenticate\nsession = auth.authenticate()\n\n# Create client\nclient = SalesforceClient(session)\n</code></pre>"},{"location":"api/AUTHENTICATION/#manual-configuration_1","title":"Manual Configuration","text":"<pre><code>from kinetic_core import OAuthAuthenticator\n\nauth = OAuthAuthenticator(\n    client_id=\"3MVG9...\",\n    client_secret=\"1234567890ABCDEF\",\n    username=\"user@example.com\",\n    password=\"YourPassword\",\n    security_token=\"ABC123\",\n    login_url=\"https://login.salesforce.com\"\n)\n\nsession = auth.authenticate()\n</code></pre>"},{"location":"api/AUTHENTICATION/#api-reference_1","title":"API Reference","text":""},{"location":"api/AUTHENTICATION/#oauthauthenticator-class","title":"OAuthAuthenticator Class","text":"<pre><code>class OAuthAuthenticator:\n    \"\"\"OAuth 2.0 Password Flow authenticator\"\"\"\n\n    def __init__(\n        self,\n        client_id: str,\n        client_secret: str,\n        username: str,\n        password: str,\n        security_token: str = \"\",\n        login_url: str = \"https://login.salesforce.com\"\n    )\n</code></pre> <p>Parameters: - <code>client_id</code> (str): Consumer Key - <code>client_secret</code> (str): Consumer Secret - <code>username</code> (str): Salesforce username - <code>password</code> (str): User password - <code>security_token</code> (str): Security token (if required) - <code>login_url</code> (str): Login URL</p>"},{"location":"api/AUTHENTICATION/#methods_1","title":"Methods","text":""},{"location":"api/AUTHENTICATION/#from_env_1","title":"from_env()","text":"<pre><code>@classmethod\ndef from_env(cls) -&gt; OAuthAuthenticator\n</code></pre> <p>Environment Variables: - <code>SF_CLIENT_ID</code> - <code>SF_CLIENT_SECRET</code> - <code>SF_USERNAME</code> - <code>SF_PASSWORD</code> - <code>SF_SECURITY_TOKEN</code> (optional) - <code>SF_LOGIN_URL</code> (optional)</p>"},{"location":"api/AUTHENTICATION/#authenticate_1","title":"authenticate()","text":"<pre><code>def authenticate(self) -&gt; SalesforceSession\n</code></pre> <p>Returns: <code>SalesforceSession</code></p> <p>Raises: <code>AuthenticationError</code> if fails</p>"},{"location":"api/AUTHENTICATION/#salesforcesession","title":"SalesforceSession","text":"<p>The authenticated session object.</p>"},{"location":"api/AUTHENTICATION/#properties","title":"Properties","text":"<pre><code>@dataclass\nclass SalesforceSession:\n    access_token: str      # OAuth access token\n    instance_url: str      # Salesforce instance URL\n    id: str               # Identity URL\n    issued_at: str        # Token issue timestamp\n    signature: str = \"\"   # HMAC signature (optional)\n</code></pre>"},{"location":"api/AUTHENTICATION/#usage_2","title":"Usage","text":"<pre><code># Access session properties\nprint(f\"Instance: {session.instance_url}\")\nprint(f\"Token: {session.access_token[:20]}...\")\n\n# Pass to client\nclient = SalesforceClient(session)\n</code></pre>"},{"location":"api/AUTHENTICATION/#best-practices","title":"Best Practices","text":""},{"location":"api/AUTHENTICATION/#production-deployments","title":"Production Deployments","text":"<ol> <li>Use JWT Bearer Flow</li> <li>More secure</li> <li>No password storage</li> <li> <p>Better for automation</p> </li> <li> <p>Store Secrets Securely</p> </li> <li>Use environment variables</li> <li>Never commit <code>.env</code> to git</li> <li> <p>Use secret managers (AWS Secrets, Azure Key Vault)</p> </li> <li> <p>Rotate Certificates</p> </li> <li>Plan for certificate expiration</li> <li>Have rollover strategy</li> <li>Test rotation process</li> </ol>"},{"location":"api/AUTHENTICATION/#development","title":"Development","text":"<ol> <li>Use OAuth for Quick Testing</li> <li>Easier initial setup</li> <li> <p>Good for local development</p> </li> <li> <p>Switch to JWT Before Production</p> </li> <li>Test thoroughly</li> <li>Update CI/CD pipelines</li> </ol>"},{"location":"api/AUTHENTICATION/#security","title":"Security","text":"<ol> <li> <p>Protect Private Keys <pre><code>chmod 600 server.key  # Read/write for owner only\n</code></pre></p> </li> <li> <p>Use IP Restrictions</p> </li> <li>Whitelist known IPs in Connected App</li> <li> <p>Reduces attack surface</p> </li> <li> <p>Limit Scopes</p> </li> <li>Only grant necessary OAuth scopes</li> <li> <p>Review periodically</p> </li> <li> <p>Monitor Access</p> </li> <li>Check login history</li> <li>Set up security alerts</li> </ol>"},{"location":"api/AUTHENTICATION/#environment-variables-reference","title":"Environment Variables Reference","text":""},{"location":"api/AUTHENTICATION/#required-for-jwt","title":"Required for JWT","text":"<pre><code>SF_CLIENT_ID=3MVG9...           # Connected App Consumer Key\nSF_USERNAME=user@example.com    # Salesforce username\nSF_PRIVATE_KEY_PATH=/path/key   # Path to private key\nSF_LOGIN_URL=https://test.salesforce.com  # Login URL\n</code></pre>"},{"location":"api/AUTHENTICATION/#required-for-oauth","title":"Required for OAuth","text":"<pre><code>SF_CLIENT_ID=3MVG9...           # Consumer Key\nSF_CLIENT_SECRET=ABC123...      # Consumer Secret\nSF_USERNAME=user@example.com    # Username\nSF_PASSWORD=MyPassword          # Password\nSF_SECURITY_TOKEN=XYZ789        # Security token\nSF_LOGIN_URL=https://login.salesforce.com\n</code></pre>"},{"location":"api/AUTHENTICATION/#optional","title":"Optional","text":"<pre><code>SF_API_VERSION=v62.0            # API version (default: v62.0)\nLOG_LEVEL=INFO                  # Logging level\nLOG_DIR=./logs                  # Log directory\n</code></pre>"},{"location":"api/AUTHENTICATION/#examples","title":"Examples","text":""},{"location":"api/AUTHENTICATION/#example-1-jwt-with-docker","title":"Example 1: JWT with Docker","text":"<pre><code>FROM python:3.11-slim\n\nWORKDIR /app\n\n# Copy private key\nCOPY server.key /app/certs/server.key\nRUN chmod 600 /app/certs/server.key\n\n# Install package\nRUN pip install kinetic-core\n\n# Set environment\nENV SF_CLIENT_ID=3MVG9...\nENV SF_USERNAME=integration@company.com\nENV SF_PRIVATE_KEY_PATH=/app/certs/server.key\nENV SF_LOGIN_URL=https://test.salesforce.com\n\nCMD [\"python\", \"sync_job.py\"]\n</code></pre>"},{"location":"api/AUTHENTICATION/#example-2-multi-environment-setup","title":"Example 2: Multi-Environment Setup","text":"<pre><code>import os\nfrom kinetic_core import JWTAuthenticator\n\n# Load config based on environment\nenv = os.getenv('ENVIRONMENT', 'dev')\n\nconfigs = {\n    'dev': {\n        'client_id': os.getenv('DEV_SF_CLIENT_ID'),\n        'username': os.getenv('DEV_SF_USERNAME'),\n        'private_key_path': '/certs/dev-key.pem',\n        'login_url': 'https://test.salesforce.com'\n    },\n    'prod': {\n        'client_id': os.getenv('PROD_SF_CLIENT_ID'),\n        'username': os.getenv('PROD_SF_USERNAME'),\n        'private_key_path': '/certs/prod-key.pem',\n        'login_url': 'https://login.salesforce.com'\n    }\n}\n\nconfig = configs[env]\nauth = JWTAuthenticator(**config)\nsession = auth.authenticate()\n</code></pre>"},{"location":"api/AUTHENTICATION/#example-3-token-refresh","title":"Example 3: Token Refresh","text":"<pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\n\nauth = JWTAuthenticator.from_env()\n\ndef get_client():\n    \"\"\"Get authenticated client with fresh session\"\"\"\n    session = auth.authenticate()\n    return SalesforceClient(session)\n\n# Use in long-running process\nwhile True:\n    client = get_client()  # Fresh session\n    # Do work...\n    time.sleep(3600)  # Re-authenticate every hour\n</code></pre>"},{"location":"api/AUTHENTICATION/#related-documentation","title":"Related Documentation","text":"<ul> <li>Salesforce Setup Guide - Configure Connected App</li> <li>User Guide - Using authenticated client</li> <li>Testing Guide - Test authentication</li> </ul>"},{"location":"api/AUTHENTICATION/#external-resources","title":"External Resources","text":"<ul> <li>Salesforce JWT Bearer Flow</li> <li>OAuth 2.0 Password Flow</li> <li>Connected Apps</li> </ul>"},{"location":"api/BULK_API_V2/","title":"Bulk API v2 - Complete API Reference","text":""},{"location":"api/BULK_API_V2/#overview","title":"Overview","text":"<p>The Bulk API v2 allows you to process millions of Salesforce records asynchronously with high performance and reliability.</p> <p>New in Kinetic Core v2.0.0 - Full native implementation of Salesforce Bulk API v2.</p>"},{"location":"api/BULK_API_V2/#features","title":"Features","text":"<ul> <li>\u2705 High-volume operations: Process up to 150 million records per job</li> <li>\u2705 Asynchronous processing: Non-blocking job execution</li> <li>\u2705 Smart polling: Exponential backoff for efficient API usage</li> <li>\u2705 Comprehensive error reporting: Per-record failure details</li> <li>\u2705 Progress tracking: Real-time job status updates</li> <li>\u2705 Type safety: Full type hints throughout</li> </ul>"},{"location":"api/BULK_API_V2/#supported-operations","title":"Supported Operations","text":"Operation Description Requirements <code>insert()</code> Create new records - <code>update()</code> Update existing records Requires <code>Id</code> field <code>upsert()</code> Insert or update Requires external ID field <code>delete()</code> Soft delete (to recycle bin) Requires <code>Id</code> field <code>hard_delete()</code> Permanent deletion Requires <code>Id</code> field + permission <code>query()</code> Export large datasets SOQL query"},{"location":"api/BULK_API_V2/#quick-start","title":"Quick Start","text":"<pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\n\n# Authenticate\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\n# Access Bulk API v2 via .bulk property\nbulk_client = client.bulk\n</code></pre>"},{"location":"api/BULK_API_V2/#api-reference","title":"API Reference","text":""},{"location":"api/BULK_API_V2/#bulkv2client","title":"BulkV2Client","text":"<p>Main client for Bulk API v2 operations.</p> <p>Access: <code>client.bulk</code></p> <p>Base URL: <code>{instance_url}/services/data/v60.0/jobs/ingest</code></p>"},{"location":"api/BULK_API_V2/#insert","title":"insert()","text":"<p>Bulk insert records into Salesforce.</p> <p>Signature: <pre><code>def insert(\n    sobject: str,\n    records: List[Dict[str, Any]],\n    wait: bool = True,\n    timeout_minutes: Optional[float] = 10,\n    on_progress: Optional[Callable[[BulkJob], None]] = None\n) -&gt; BulkResult\n</code></pre></p> <p>Parameters: - <code>sobject</code> (str): Salesforce object API name (e.g., \"Account\", \"Contact\") - <code>records</code> (List[Dict]): Records to insert - <code>wait</code> (bool): Wait for job completion (default: True) - <code>timeout_minutes</code> (float): Max wait time in minutes (default: 10) - <code>on_progress</code> (callable): Progress callback function (optional)</p> <p>Returns: <code>BulkResult</code> with success/failure details</p> <p>Example: <pre><code>records = [\n    {\"Name\": \"Acme Corp\", \"Industry\": \"Technology\"},\n    {\"Name\": \"Global Inc\", \"Industry\": \"Finance\"}\n]\n\nresult = client.bulk.insert(\"Account\", records)\nprint(f\"Success: {result.success_count}\")\nprint(f\"Failed: {result.failed_count}\")\n</code></pre></p>"},{"location":"api/BULK_API_V2/#update","title":"update()","text":"<p>Bulk update existing records.</p> <p>Signature: <pre><code>def update(\n    sobject: str,\n    records: List[Dict[str, Any]],\n    wait: bool = True,\n    timeout_minutes: Optional[float] = 10,\n    on_progress: Optional[Callable[[BulkJob], None]] = None\n) -&gt; BulkResult\n</code></pre></p> <p>Parameters: Same as <code>insert()</code></p> <p>Requirements: All records must include the <code>Id</code> field</p> <p>Example: <pre><code>records = [\n    {\"Id\": \"001xxx000001\", \"Industry\": \"Software\"},\n    {\"Id\": \"001xxx000002\", \"Industry\": \"Hardware\"}\n]\n\nresult = client.bulk.update(\"Account\", records)\n</code></pre></p> <p>Validation: Raises <code>ValueError</code> if any record is missing <code>Id</code> field</p>"},{"location":"api/BULK_API_V2/#upsert","title":"upsert()","text":"<p>Insert or update records using an external ID field.</p> <p>Signature: <pre><code>def upsert(\n    sobject: str,\n    records: List[Dict[str, Any]],\n    external_id_field: str,\n    wait: bool = True,\n    timeout_minutes: Optional[float] = 10,\n    on_progress: Optional[Callable[[BulkJob], None]] = None\n) -&gt; BulkResult\n</code></pre></p> <p>Parameters: - <code>external_id_field</code> (str): External ID field name (e.g., \"External_Key__c\") - Other parameters same as <code>insert()</code></p> <p>Requirements: All records must include the external ID field</p> <p>Example: <pre><code>records = [\n    {\"External_Key__c\": \"EXT001\", \"Name\": \"Acme Corp\"},\n    {\"External_Key__c\": \"EXT002\", \"Name\": \"Global Inc\"}\n]\n\nresult = client.bulk.upsert(\"Account\", records, \"External_Key__c\")\n</code></pre></p>"},{"location":"api/BULK_API_V2/#delete","title":"delete()","text":"<p>Bulk delete records (soft delete to recycle bin).</p> <p>Signature: <pre><code>def delete(\n    sobject: str,\n    ids: List[str],\n    wait: bool = True,\n    timeout_minutes: Optional[float] = 10,\n    on_progress: Optional[Callable[[BulkJob], None]] = None\n) -&gt; BulkResult\n</code></pre></p> <p>Parameters: - <code>ids</code> (List[str]): Record IDs to delete - Other parameters same as <code>insert()</code></p> <p>Example: <pre><code>ids = [\"001xxx000001\", \"001xxx000002\", \"001xxx000003\"]\nresult = client.bulk.delete(\"Account\", ids)\n</code></pre></p>"},{"location":"api/BULK_API_V2/#hard_delete","title":"hard_delete()","text":"<p>Permanently delete records, bypassing recycle bin.</p> <p>Signature: <pre><code>def hard_delete(\n    sobject: str,\n    ids: List[str],\n    wait: bool = True,\n    timeout_minutes: Optional[float] = 10,\n    on_progress: Optional[Callable[[BulkJob], None]] = None\n) -&gt; BulkResult\n</code></pre></p> <p>Requirements: - User must have \"Bulk API Hard Delete\" permission - Records are permanently deleted (cannot be recovered)</p> <p>Example: <pre><code>ids = [\"001xxx000001\"]\nresult = client.bulk.hard_delete(\"Account\", ids)\n</code></pre></p>"},{"location":"api/BULK_API_V2/#query","title":"query()","text":"<p>Export large datasets using SOQL queries.</p> <p>Signature: <pre><code>def query(\n    soql: str,\n    timeout_minutes: Optional[float] = 30,\n    on_progress: Optional[Callable[[BulkJob], None]] = None\n) -&gt; BulkQueryResult\n</code></pre></p> <p>Parameters: - <code>soql</code> (str): SOQL query string - <code>timeout_minutes</code> (float): Max wait time (default: 30 minutes) - <code>on_progress</code> (callable): Progress callback (optional)</p> <p>Returns: <code>BulkQueryResult</code> with records and job metadata</p> <p>Example: <pre><code>query = \"\"\"\n    SELECT Id, Name, Industry, AnnualRevenue\n    FROM Account\n    WHERE CreatedDate = LAST_YEAR\n    LIMIT 1000000\n\"\"\"\n\nresult = client.bulk.query(query)\nprint(f\"Retrieved {result.record_count} records\")\n\nfor record in result.records:\n    print(record['Name'])\n</code></pre></p>"},{"location":"api/BULK_API_V2/#data-models","title":"Data Models","text":""},{"location":"api/BULK_API_V2/#bulkjob","title":"BulkJob","text":"<p>Job metadata and status information.</p> <p>Properties: - <code>id</code> (str): Salesforce job ID - <code>operation</code> (str): Operation type (insert, update, etc.) - <code>object</code> (str): Salesforce object name - <code>state</code> (str): Job state (Open, UploadComplete, InProgress, JobComplete, Failed, Aborted) - <code>created_date</code> (datetime): Job creation timestamp - <code>system_modstamp</code> (datetime): Last modification timestamp - <code>number_records_processed</code> (int): Total records processed - <code>number_records_failed</code> (int): Number of failed records</p> <p>Methods: - <code>is_complete() -&gt; bool</code>: Check if job is finished - <code>is_successful() -&gt; bool</code>: Check if job completed successfully</p> <p>Job State Flow: <pre><code>Open \u2192 UploadComplete \u2192 InProgress \u2192 JobComplete/Failed/Aborted\n</code></pre></p>"},{"location":"api/BULK_API_V2/#bulkresult","title":"BulkResult","text":"<p>Result of insert/update/upsert/delete operations.</p> <p>Properties: - <code>job</code> (BulkJob): Job metadata - <code>success_records</code> (List[Dict]): Successfully processed records - <code>failed_records</code> (List[Dict]): Failed records - <code>errors</code> (List[BulkError]): Detailed error information - <code>success_count</code> (int): Number of successful records - <code>failed_count</code> (int): Number of failed records - <code>total_records</code> (int): Total records processed</p> <p>Example: <pre><code>result = client.bulk.insert(\"Account\", records)\n\nif result.failed_count &gt; 0:\n    print(f\"Errors occurred:\")\n    for error in result.errors:\n        print(f\"  - {error.message}\")\n</code></pre></p>"},{"location":"api/BULK_API_V2/#bulkqueryresult","title":"BulkQueryResult","text":"<p>Result of query operations.</p> <p>Properties: - <code>job</code> (BulkJob): Job metadata - <code>records</code> (List[Dict]): Query results - <code>record_count</code> (int): Number of records retrieved - <code>locator</code> (str): Always None for Bulk API v2</p> <p>Example: <pre><code>result = client.bulk.query(\"SELECT Id, Name FROM Account\")\n\nfor record in result.records:\n    account_id = record['Id']\n    account_name = record['Name']\n</code></pre></p>"},{"location":"api/BULK_API_V2/#bulkerror","title":"BulkError","text":"<p>Detailed error information for failed records.</p> <p>Properties: - <code>fields</code> (List[str]): Field names that caused the error - <code>message</code> (str): Error message - <code>status_code</code> (str): Salesforce error code</p> <p>Example: <pre><code>for error in result.errors:\n    print(f\"Error: {error.message}\")\n    print(f\"Code: {error.status_code}\")\n    print(f\"Fields: {', '.join(error.fields)}\")\n</code></pre></p>"},{"location":"api/BULK_API_V2/#progress-tracking","title":"Progress Tracking","text":"<p>Monitor job progress with callbacks:</p> <pre><code>def progress_callback(job: BulkJob):\n    print(f\"Job {job.id}: {job.state}\")\n    print(f\"  Processed: {job.number_records_processed}\")\n\nresult = client.bulk.insert(\n    \"Account\",\n    records,\n    on_progress=progress_callback\n)\n</code></pre>"},{"location":"api/BULK_API_V2/#error-handling","title":"Error Handling","text":""},{"location":"api/BULK_API_V2/#validation-errors","title":"Validation Errors","text":"<pre><code>try:\n    # Missing Id field\n    records = [{\"Name\": \"Test\"}]\n    client.bulk.update(\"Account\", records)\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n</code></pre>"},{"location":"api/BULK_API_V2/#job-failures","title":"Job Failures","text":"<pre><code>result = client.bulk.insert(\"Account\", records)\n\nif result.job.state == \"Failed\":\n    print(\"Job failed!\")\n    for error in result.errors:\n        print(f\"  - {error.message}\")\n</code></pre>"},{"location":"api/BULK_API_V2/#timeouts","title":"Timeouts","text":"<pre><code>try:\n    result = client.bulk.query(\n        \"SELECT * FROM Account\",\n        timeout_minutes=5\n    )\nexcept TimeoutError as e:\n    print(f\"Query timed out: {e}\")\n</code></pre>"},{"location":"api/BULK_API_V2/#performance-guidelines","title":"Performance Guidelines","text":""},{"location":"api/BULK_API_V2/#recommended-batch-sizes","title":"Recommended Batch Sizes","text":"Records Recommended Operation &lt; 2,000 Standard API (client.create, client.update) 2,000 - 10,000,000 Bulk API v2 (client.bulk) &gt; 10,000,000 Bulk API v2 with batching"},{"location":"api/BULK_API_V2/#optimal-settings","title":"Optimal Settings","text":"<pre><code># For large datasets (&gt; 100k records)\nresult = client.bulk.insert(\n    \"Account\",\n    records,\n    wait=True,\n    timeout_minutes=30  # Increase timeout\n)\n\n# For quick operations (&lt; 10k records)\nresult = client.bulk.insert(\n    \"Account\",\n    records,\n    wait=True,\n    timeout_minutes=5\n)\n</code></pre>"},{"location":"api/BULK_API_V2/#polling-strategy","title":"Polling Strategy","text":"<p>The Bulk API client uses exponential backoff: - Initial delay: 2 seconds - Max delay: 30 seconds - Backoff factor: 1.5x</p> <p>This minimizes API calls while ensuring responsive status updates.</p>"},{"location":"api/BULK_API_V2/#limitations","title":"Limitations","text":"Limit Value Max records per job 150 million Max file size 100 MB (CSV) Max concurrent jobs 5,000 per org Job retention 7 days Query timeout 10 minutes <p>Note: Salesforce-imposed limits, not library limitations.</p>"},{"location":"api/BULK_API_V2/#best-practices","title":"Best Practices","text":""},{"location":"api/BULK_API_V2/#1-use-bulk-api-for-large-datasets","title":"1. Use Bulk API for Large Datasets","text":"<pre><code># \u274c Inefficient for 10k records\nfor record in records:\n    client.create(\"Account\", record)\n\n# \u2705 Efficient\nresult = client.bulk.insert(\"Account\", records)\n</code></pre>"},{"location":"api/BULK_API_V2/#2-handle-partial-failures","title":"2. Handle Partial Failures","text":"<pre><code>result = client.bulk.insert(\"Account\", records)\n\nif result.failed_count &gt; 0:\n    # Retry failed records\n    failed_data = result.failed_records\n    # ... implement retry logic\n</code></pre>"},{"location":"api/BULK_API_V2/#3-use-external-ids-for-upsert","title":"3. Use External IDs for Upsert","text":"<pre><code># Prevents duplicates\nresult = client.bulk.upsert(\n    \"Account\",\n    records,\n    external_id_field=\"External_Key__c\"\n)\n</code></pre>"},{"location":"api/BULK_API_V2/#4-monitor-progress-for-large-jobs","title":"4. Monitor Progress for Large Jobs","text":"<pre><code>def log_progress(job):\n    percent = (job.number_records_processed / total_records) * 100\n    print(f\"Progress: {percent:.1f}%\")\n\nresult = client.bulk.insert(\n    \"Account\",\n    large_dataset,\n    on_progress=log_progress\n)\n</code></pre>"},{"location":"api/BULK_API_V2/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api/BULK_API_V2/#common-issues","title":"Common Issues","text":"<p>Issue: Job fails immediately - Cause: Invalid field names or missing required fields - Solution: Verify field API names match Salesforce schema</p> <p>Issue: Timeout errors - Cause: Job takes longer than specified timeout - Solution: Increase <code>timeout_minutes</code> parameter</p> <p>Issue: Empty success_records - Cause: All records failed validation - Solution: Check <code>result.errors</code> for details</p>"},{"location":"api/BULK_API_V2/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable detailed logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\nresult = client.bulk.insert(\"Account\", records)\n</code></pre>"},{"location":"api/BULK_API_V2/#migration-from-bulk-api-v1","title":"Migration from Bulk API v1","text":"<p>If migrating from the old Bulk API v1:</p> v1 Concept v2 Equivalent Batch Job (single batch) ResultList BulkResult.success_records Error list BulkResult.errors Locators Not needed (automatic) <p>Key Differences: - v2 uses single-batch jobs (simpler) - No manual batch management - Better error reporting - Faster processing</p>"},{"location":"api/BULK_API_V2/#related-documentation","title":"Related Documentation","text":"<ul> <li>Bulk API v2 Quick Start</li> <li>Migration Guide</li> <li>Examples</li> <li>Salesforce Official Docs</li> </ul>"},{"location":"api/CRUD_OPERATIONS/","title":"CRUD Operations - Complete Reference","text":"<p>Complete guide to Create, Read, Update, and Delete operations in Kinetic Core.</p>"},{"location":"api/CRUD_OPERATIONS/#overview","title":"Overview","text":"<p>The <code>SalesforceClient</code> provides comprehensive CRUD operations for any Salesforce object (standard or custom).</p> <p>Key Features: - \u2705 Works with any Salesforce object - \u2705 Type-safe with full type hints - \u2705 Automatic error handling - \u2705 Query pagination - \u2705 Bulk create via Composite API - \u2705 Flexible upsert operations</p>"},{"location":"api/CRUD_OPERATIONS/#quick-reference","title":"Quick Reference","text":"Operation Method Use Case Create <code>create()</code> Insert single record Read <code>get()</code> Retrieve by ID Update <code>update()</code> Update existing record Delete <code>delete()</code> Remove record Upsert <code>upsert()</code> Insert or update Query <code>query()</code> SOQL queries Query All <code>query_all()</code> Include deleted/archived Describe <code>describe()</code> Get object metadata"},{"location":"api/CRUD_OPERATIONS/#create-operations","title":"Create Operations","text":""},{"location":"api/CRUD_OPERATIONS/#create","title":"create()","text":"<p>Create a single Salesforce record.</p> <p>Signature: <pre><code>def create(\n    self,\n    sobject: str,\n    data: Dict[str, Any]\n) -&gt; str\n</code></pre></p> <p>Parameters: - <code>sobject</code> (str): Salesforce object API name - <code>data</code> (dict): Field name-value pairs</p> <p>Returns: Record ID (str)</p> <p>Raises: <code>SalesforceAPIError</code> if creation fails</p> <p>Example: <pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\n\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\n# Create Account\naccount_id = client.create(\"Account\", {\n    \"Name\": \"Acme Corporation\",\n    \"Industry\": \"Technology\",\n    \"AnnualRevenue\": 5000000,\n    \"BillingCity\": \"San Francisco\"\n})\n\nprint(f\"Created Account: {account_id}\")  # 001xxx000001AAA\n</code></pre></p> <p>Custom Objects: <pre><code># Custom object (note __c suffix)\ncustom_id = client.create(\"Custom_Object__c\", {\n    \"Name\": \"Record 1\",\n    \"Custom_Field__c\": \"Value\"\n})\n</code></pre></p>"},{"location":"api/CRUD_OPERATIONS/#create_bulk","title":"create_bulk()","text":"<p>Create multiple records using Composite API.</p> <p>Signature: <pre><code>def create_bulk(\n    self,\n    sobject: str,\n    records: List[Dict[str, Any]],\n    all_or_none: bool = False\n) -&gt; Dict[str, Any]\n</code></pre></p> <p>Parameters: - <code>sobject</code> (str): Object name - <code>records</code> (list): List of record dictionaries - <code>all_or_none</code> (bool): Rollback all if any fails</p> <p>Returns: Dictionary with results</p> <p>Limit: 200 records per call (Salesforce Composite API limit)</p> <p>Example: <pre><code># Create multiple accounts\naccounts = [\n    {\"Name\": \"Account 1\", \"Industry\": \"Tech\"},\n    {\"Name\": \"Account 2\", \"Industry\": \"Finance\"},\n    {\"Name\": \"Account 3\", \"Industry\": \"Retail\"}\n]\n\nresult = client.create_bulk(\"Account\", accounts)\n\n# Check results\nfor item in result['compositeResponse']:\n    if item['httpStatusCode'] == 201:\n        print(f\"Created: {item['body']['id']}\")\n    else:\n        print(f\"Failed: {item['body'][0]['message']}\")\n</code></pre></p> <p>For &gt; 200 records: Use Bulk API v2</p>"},{"location":"api/CRUD_OPERATIONS/#read-operations","title":"Read Operations","text":""},{"location":"api/CRUD_OPERATIONS/#get","title":"get()","text":"<p>Retrieve a record by ID.</p> <p>Signature: <pre><code>def get(\n    self,\n    sobject: str,\n    record_id: str,\n    fields: Optional[List[str]] = None\n) -&gt; Dict[str, Any]\n</code></pre></p> <p>Parameters: - <code>sobject</code> (str): Object name - <code>record_id</code> (str): Salesforce record ID - <code>fields</code> (list, optional): Specific fields to retrieve</p> <p>Returns: Dictionary with record data</p> <p>Example: <pre><code># Get all fields\naccount = client.get(\"Account\", \"001xxx000001AAA\")\nprint(account['Name'])\nprint(account['Industry'])\n\n# Get specific fields only\naccount = client.get(\n    \"Account\",\n    \"001xxx000001AAA\",\n    fields=[\"Name\", \"Industry\", \"AnnualRevenue\"]\n)\n</code></pre></p>"},{"location":"api/CRUD_OPERATIONS/#query","title":"query()","text":"<p>Execute SOQL query.</p> <p>Signature: <pre><code>def query(\n    self,\n    soql: str\n) -&gt; List[Dict[str, Any]]\n</code></pre></p> <p>Parameters: - <code>soql</code> (str): SOQL query string</p> <p>Returns: List of records</p> <p>Features: - \u2705 Automatic pagination (handles &gt; 2000 results) - \u2705 Returns all records - \u2705 Follows <code>nextRecordsUrl</code> automatically</p> <p>Example: <pre><code># Simple query\naccounts = client.query(\n    \"SELECT Id, Name, Industry FROM Account WHERE Industry = 'Technology'\"\n)\n\nfor account in accounts:\n    print(f\"{account['Name']} - {account['Industry']}\")\n\n# Query with relationships\ncontacts = client.query(\"\"\"\n    SELECT Id, FirstName, LastName, Account.Name\n    FROM Contact\n    WHERE Account.Industry = 'Technology'\n    LIMIT 100\n\"\"\")\n\nfor contact in contacts:\n    print(f\"{contact['FirstName']} - {contact['Account']['Name']}\")\n\n# Aggregate queries\nresult = client.query(\"\"\"\n    SELECT Industry, COUNT(Id) total\n    FROM Account\n    GROUP BY Industry\n\"\"\")\n\nfor row in result:\n    print(f\"{row['Industry']}: {row['total']}\")\n</code></pre></p> <p>SOQL Tips: <pre><code># Date literals\nquery = \"SELECT Id FROM Account WHERE CreatedDate = TODAY\"\nquery = \"SELECT Id FROM Account WHERE CreatedDate = LAST_WEEK\"\nquery = \"SELECT Id FROM Account WHERE CreatedDate &gt;= 2025-01-01\"\n\n# IN clause\nquery = \"SELECT Id FROM Account WHERE Industry IN ('Tech', 'Finance')\"\n\n# ORDER BY\nquery = \"SELECT Id, Name FROM Account ORDER BY Name ASC\"\n\n# LIMIT\nquery = \"SELECT Id FROM Account LIMIT 1000\"\n</code></pre></p>"},{"location":"api/CRUD_OPERATIONS/#query_all","title":"query_all()","text":"<p>Query including deleted and archived records.</p> <p>Signature: <pre><code>def query_all(\n    self,\n    soql: str\n) -&gt; List[Dict[str, Any]]\n</code></pre></p> <p>Use Cases: - Retrieve soft-deleted records - Access archived data - Audit trails</p> <p>Example: <pre><code># Include deleted records\nall_accounts = client.query_all(\n    \"SELECT Id, Name, IsDeleted FROM Account\"\n)\n\ndeleted = [a for a in all_accounts if a.get('IsDeleted')]\nprint(f\"Found {len(deleted)} deleted accounts\")\n</code></pre></p>"},{"location":"api/CRUD_OPERATIONS/#update-operations","title":"Update Operations","text":""},{"location":"api/CRUD_OPERATIONS/#update","title":"update()","text":"<p>Update an existing record.</p> <p>Signature: <pre><code>def update(\n    self,\n    sobject: str,\n    record_id: str,\n    data: Dict[str, Any]\n) -&gt; bool\n</code></pre></p> <p>Parameters: - <code>sobject</code> (str): Object name - <code>record_id</code> (str): Record ID to update - <code>data</code> (dict): Fields to update</p> <p>Returns: <code>True</code> if successful</p> <p>Example: <pre><code># Update single field\nclient.update(\"Account\", \"001xxx000001\", {\n    \"Phone\": \"555-1234\"\n})\n\n# Update multiple fields\nclient.update(\"Account\", \"001xxx000001\", {\n    \"Phone\": \"555-1234\",\n    \"Industry\": \"Software\",\n    \"AnnualRevenue\": 10000000\n})\n\n# Update custom fields\nclient.update(\"Custom_Object__c\", record_id, {\n    \"Status__c\": \"Completed\",\n    \"Completion_Date__c\": \"2025-01-02\"\n})\n</code></pre></p> <p>Null Values: <pre><code># Set field to null (clear value)\nclient.update(\"Account\", record_id, {\n    \"Fax\": None,  # Clears the field\n    \"Description\": None\n})\n</code></pre></p>"},{"location":"api/CRUD_OPERATIONS/#delete-operations","title":"Delete Operations","text":""},{"location":"api/CRUD_OPERATIONS/#delete","title":"delete()","text":"<p>Delete a record (soft delete to recycle bin).</p> <p>Signature: <pre><code>def delete(\n    self,\n    sobject: str,\n    record_id: str\n) -&gt; bool\n</code></pre></p> <p>Parameters: - <code>sobject</code> (str): Object name - <code>record_id</code> (str): Record ID</p> <p>Returns: <code>True</code> if successful</p> <p>Example: <pre><code># Delete single record\nclient.delete(\"Account\", \"001xxx000001\")\n\n# Delete multiple (loop)\nids_to_delete = [\"001xxx001\", \"001xxx002\", \"001xxx003\"]\nfor record_id in ids_to_delete:\n    client.delete(\"Account\", record_id)\n</code></pre></p> <p>Note: For &gt; 100 deletes, use Bulk API v2</p>"},{"location":"api/CRUD_OPERATIONS/#upsert-operations","title":"Upsert Operations","text":""},{"location":"api/CRUD_OPERATIONS/#upsert","title":"upsert()","text":"<p>Insert new record or update existing based on external ID.</p> <p>Signature: <pre><code>def upsert(\n    self,\n    sobject: str,\n    external_id_field: str,\n    external_id_value: str,\n    data: Dict[str, Any]\n) -&gt; Dict[str, Any]\n</code></pre></p> <p>Parameters: - <code>sobject</code> (str): Object name - <code>external_id_field</code> (str): External ID field name - <code>external_id_value</code> (str): External ID value - <code>data</code> (dict): Record data</p> <p>Returns: Dictionary with result details</p> <p>Use Cases: - Prevent duplicates - Sync from external systems - Idempotent operations</p> <p>Example: <pre><code># Upsert with custom external ID field\nresult = client.upsert(\n    sobject=\"Account\",\n    external_id_field=\"External_Key__c\",\n    external_id_value=\"EXT-001\",\n    data={\n        \"Name\": \"Acme Corp\",\n        \"Industry\": \"Technology\"\n    }\n)\n\nif result['created']:\n    print(f\"Created new record: {result['id']}\")\nelse:\n    print(f\"Updated existing: {result['id']}\")\n\n# Upsert Contact with Email as external ID\nresult = client.upsert(\n    sobject=\"Contact\",\n    external_id_field=\"Email\",\n    external_id_value=\"john@example.com\",\n    data={\n        \"FirstName\": \"John\",\n        \"LastName\": \"Doe\",\n        \"Title\": \"Manager\"\n    }\n)\n</code></pre></p> <p>External ID Fields: <pre><code># Must be configured in Salesforce:\n# Setup \u2192 Object Manager \u2192 Custom Field \u2192 \"External ID\" checkbox\n</code></pre></p>"},{"location":"api/CRUD_OPERATIONS/#describe-operations","title":"Describe Operations","text":""},{"location":"api/CRUD_OPERATIONS/#describe","title":"describe()","text":"<p>Get metadata for a Salesforce object.</p> <p>Signature: <pre><code>def describe(\n    self,\n    sobject: str\n) -&gt; Dict[str, Any]\n</code></pre></p> <p>Parameters: - <code>sobject</code> (str): Object name</p> <p>Returns: Complete object metadata</p> <p>Example: <pre><code># Get Account metadata\nmetadata = client.describe(\"Account\")\n\n# Object properties\nprint(f\"Label: {metadata['label']}\")\nprint(f\"Createable: {metadata['createable']}\")\nprint(f\"Updateable: {metadata['updateable']}\")\nprint(f\"Deletable: {metadata['deletable']}\")\n\n# Fields\nfor field in metadata['fields']:\n    print(f\"Field: {field['name']} ({field['type']})\")\n    print(f\"  Required: {not field['nillable']}\")\n    print(f\"  Unique: {field.get('unique', False)}\")\n\n# Record types\nfor record_type in metadata.get('recordTypeInfos', []):\n    print(f\"RecordType: {record_type['name']}\")\n</code></pre></p> <p>Use Cases: - Dynamic field mapping - Validation - UI generation - Documentation</p>"},{"location":"api/CRUD_OPERATIONS/#advanced-examples","title":"Advanced Examples","text":""},{"location":"api/CRUD_OPERATIONS/#example-1-create-with-relationships","title":"Example 1: Create with Relationships","text":"<pre><code># Create Contact with Account\naccount_id = client.create(\"Account\", {\n    \"Name\": \"Parent Company\"\n})\n\ncontact_id = client.create(\"Contact\", {\n    \"FirstName\": \"John\",\n    \"LastName\": \"Doe\",\n    \"AccountId\": account_id,  # Lookup relationship\n    \"Email\": \"john@example.com\"\n})\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#example-2-query-with-parent-child","title":"Example 2: Query with Parent-Child","text":"<pre><code># Parent to Child (Contacts from Account)\nresult = client.query(\"\"\"\n    SELECT Id, Name,\n           (SELECT Id, FirstName, LastName FROM Contacts)\n    FROM Account\n    WHERE Industry = 'Technology'\n\"\"\")\n\nfor account in result:\n    print(f\"Account: {account['Name']}\")\n    if account['Contacts']:\n        for contact in account['Contacts']['records']:\n            print(f\"  - {contact['FirstName']} {contact['LastName']}\")\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#example-3-batch-create-with-error-handling","title":"Example 3: Batch Create with Error Handling","text":"<pre><code>def safe_create_bulk(client, sobject, records):\n    \"\"\"Create with error handling\"\"\"\n    batch_size = 200  # Composite API limit\n\n    all_results = []\n\n    for i in range(0, len(records), batch_size):\n        batch = records[i:i + batch_size]\n\n        try:\n            result = client.create_bulk(sobject, batch)\n\n            # Process results\n            for item in result['compositeResponse']:\n                if item['httpStatusCode'] == 201:\n                    all_results.append({\n                        'success': True,\n                        'id': item['body']['id']\n                    })\n                else:\n                    all_results.append({\n                        'success': False,\n                        'error': item['body'][0]['message']\n                    })\n\n        except Exception as e:\n            print(f\"Batch failed: {e}\")\n            # Add failures\n            all_results.extend([\n                {'success': False, 'error': str(e)}\n                for _ in batch\n            ])\n\n    return all_results\n\n# Usage\nrecords = [{\"Name\": f\"Account {i}\"} for i in range(500)]\nresults = safe_create_bulk(client, \"Account\", records)\n\nsuccesses = sum(1 for r in results if r['success'])\nprint(f\"Created {successes}/{len(records)} records\")\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#example-4-conditional-update","title":"Example 4: Conditional Update","text":"<pre><code># Update only if condition met\naccounts = client.query(\n    \"SELECT Id, AnnualRevenue FROM Account WHERE Industry = 'Technology'\"\n)\n\nfor account in accounts:\n    if account.get('AnnualRevenue', 0) &gt; 1000000:\n        client.update(\"Account\", account['Id'], {\n            \"Rating\": \"Hot\",\n            \"Priority__c\": \"High\"\n        })\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#example-5-pagination-with-large-result-sets","title":"Example 5: Pagination with Large Result Sets","text":"<pre><code># Query handles pagination automatically\n# Even for &gt; 10,000 results\naccounts = client.query(\n    \"SELECT Id, Name FROM Account\"  # No LIMIT = all records\n)\n\nprint(f\"Retrieved {len(accounts)} total records\")\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#best-practices","title":"Best Practices","text":""},{"location":"api/CRUD_OPERATIONS/#1-field-validation","title":"1. Field Validation","text":"<pre><code># Validate before create/update\ndef validate_account(data):\n    required = ['Name']\n    for field in required:\n        if field not in data or not data[field]:\n            raise ValueError(f\"Missing required field: {field}\")\n\n    # Validate data types\n    if 'AnnualRevenue' in data and not isinstance(data['AnnualRevenue'], (int, float)):\n        raise ValueError(\"AnnualRevenue must be numeric\")\n\ndata = {\"Name\": \"Acme\", \"AnnualRevenue\": 5000000}\nvalidate_account(data)\nclient.create(\"Account\", data)\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#2-use-external-ids-for-upsert","title":"2. Use External IDs for Upsert","text":"<pre><code># Good: Prevents duplicates\nclient.upsert(\n    \"Account\",\n    \"External_Key__c\",\n    \"EXT-001\",\n    {\"Name\": \"Acme\"}\n)\n\n# Bad: May create duplicates\nclient.create(\"Account\", {\"Name\": \"Acme\"})\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#3-batch-operations","title":"3. Batch Operations","text":"<pre><code># Good: Batch creates\nclient.create_bulk(\"Account\", records)\n\n# Bad: Loop with single creates (slow)\nfor record in records:\n    client.create(\"Account\", record)\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#4-query-efficiently","title":"4. Query Efficiently","text":"<pre><code># Good: Select only needed fields\naccounts = client.query(\n    \"SELECT Id, Name FROM Account\"\n)\n\n# Bad: SELECT * equivalent (slower)\naccounts = client.query(\n    \"SELECT FIELDS(ALL) FROM Account\"\n)\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#5-error-handling","title":"5. Error Handling","text":"<pre><code>from kinetic_core.exceptions import SalesforceAPIError\n\ntry:\n    client.create(\"Account\", data)\nexcept SalesforceAPIError as e:\n    print(f\"Error: {e.error_code}\")\n    print(f\"Message: {e.message}\")\n    # Handle specific errors\n    if e.error_code == \"REQUIRED_FIELD_MISSING\":\n        # Handle missing field\n        pass\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#performance-tips","title":"Performance Tips","text":"Records Recommended Method 1 <code>create()</code> 2-200 <code>create_bulk()</code> 200-2000 Loop with <code>create_bulk()</code> in batches &gt; 2000 Bulk API v2"},{"location":"api/CRUD_OPERATIONS/#optimization-strategies","title":"Optimization Strategies","text":"<ol> <li>Use Bulk API v2 for Large Datasets</li> <li>Select Only Necessary Fields</li> <li>Use WHERE Clauses</li> <li>Leverage Indexes (External ID fields)</li> <li>Avoid N+1 Queries (use relationship queries)</li> </ol>"},{"location":"api/CRUD_OPERATIONS/#limitations","title":"Limitations","text":""},{"location":"api/CRUD_OPERATIONS/#api-limits","title":"API Limits","text":"Operation Limit Single Record 1 per call Composite API 200 per call SOQL Query 2000 records (auto-paginated) Query Total 50,000 rows Daily API Calls Org-dependent"},{"location":"api/CRUD_OPERATIONS/#field-limits","title":"Field Limits","text":"<ul> <li>String: 255 characters (standard), 131,072 (long text)</li> <li>Number: 18 digits</li> <li>Currency: 18 digits with 2 decimal places</li> </ul>"},{"location":"api/CRUD_OPERATIONS/#best-practice-monitor-api-usage","title":"Best Practice: Monitor API Usage","text":"<pre><code># Check API limits (requires additional API call)\n# Available via Salesforce Limits API\n</code></pre>"},{"location":"api/CRUD_OPERATIONS/#related-documentation","title":"Related Documentation","text":"<ul> <li>Bulk API v2 - High-volume operations</li> <li>Field Mapping - Data transformation</li> <li>Authentication - Setup client</li> </ul>"},{"location":"api/CRUD_OPERATIONS/#external-resources","title":"External Resources","text":"<ul> <li>Salesforce REST API</li> <li>SOQL Reference</li> <li>Composite API</li> </ul>"},{"location":"api/FIELD_MAPPING/","title":"Field Mapping - Complete Reference","text":"<p>Transform data between different schemas with flexible field mapping and value transformations.</p>"},{"location":"api/FIELD_MAPPING/#overview","title":"Overview","text":"<p>The <code>FieldMapper</code> provides powerful data transformation capabilities for converting data between external systems and Salesforce schemas.</p> <p>Key Features: - \u2705 Simple field renaming - \u2705 Value transformations with custom functions - \u2705 Default values for missing fields - \u2705 Nested field access (dot notation) - \u2705 Conditional mapping logic - \u2705 Batch processing support - \u2705 Built-in transformation functions - \u2705 YAML configuration support</p>"},{"location":"api/FIELD_MAPPING/#quick-reference","title":"Quick Reference","text":"Feature Example Simple Rename <code>{\"source\": \"Target\"}</code> With Transform <code>{\"source\": (\"Target\", lambda x: x.upper())}</code> With Default <code>{\"source\": (\"Target\", None, \"default\")}</code> Nested Access <code>{\"user.email\": \"Email\"}</code> Conditional <code>ConditionalFieldMapper</code>"},{"location":"api/FIELD_MAPPING/#fieldmapper-class","title":"FieldMapper Class","text":""},{"location":"api/FIELD_MAPPING/#initialization","title":"Initialization","text":"<p>Signature: <pre><code>def __init__(self, mapping: Dict[str, Any])\n</code></pre></p> <p>Parameters: - <code>mapping</code> (dict): Mapping configuration with multiple formats</p> <p>Mapping Formats:</p> <ol> <li> <p>Simple String Mapping: <pre><code>mapping = {\n    \"source_field\": \"target_field\"\n}\n</code></pre></p> </li> <li> <p>With Transformation Function: <pre><code>mapping = {\n    \"source_field\": (\"target_field\", transform_function)\n}\n</code></pre></p> </li> <li> <p>With Default Value: <pre><code>mapping = {\n    \"source_field\": (\"target_field\", None, \"default_value\")\n}\n</code></pre></p> </li> <li> <p>Full Format (transformation + default): <pre><code>mapping = {\n    \"source_field\": (\"target_field\", transform_function, \"default_value\")\n}\n</code></pre></p> </li> </ol> <p>Example: <pre><code>from kinetic_core import FieldMapper\n\nmapper = FieldMapper({\n    # Simple rename\n    \"customer_name\": \"Name\",\n\n    # With transformation\n    \"email\": (\"Email\", lambda x: x.lower()),\n\n    # With default value\n    \"status\": (\"Status__c\", None, \"Active\"),\n\n    # Full format\n    \"created_at\": (\n        \"CreatedDate\",\n        lambda x: x.strftime(\"%Y-%m-%d\") if x else None,\n        \"2025-01-02\"\n    )\n})\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#core-methods","title":"Core Methods","text":""},{"location":"api/FIELD_MAPPING/#transform","title":"transform()","text":"<p>Transform a single record from source to target schema.</p> <p>Signature: <pre><code>def transform(\n    source: Dict[str, Any],\n    skip_none: bool = True,\n    strict: bool = False\n) -&gt; Dict[str, Any]\n</code></pre></p> <p>Parameters: - <code>source</code> (dict): Source data dictionary - <code>skip_none</code> (bool): Skip fields with None values (default: True) - <code>strict</code> (bool): Raise error if source field missing (default: False)</p> <p>Returns: Transformed dictionary in target schema</p> <p>Raises: - <code>KeyError</code>: If strict=True and source field is missing - <code>Exception</code>: If transformation function fails</p> <p>Example: <pre><code>source = {\n    \"first_name\": \"John\",\n    \"last_name\": \"Doe\",\n    \"email\": \"JOHN.DOE@EXAMPLE.COM\"\n}\n\nmapping = {\n    \"first_name\": \"FirstName\",\n    \"last_name\": \"LastName\",\n    \"email\": (\"Email\", lambda x: x.lower())\n}\n\nmapper = FieldMapper(mapping)\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"FirstName\": \"John\",\n#   \"LastName\": \"Doe\",\n#   \"Email\": \"john.doe@example.com\"\n# }\n</code></pre></p> <p>Strict Mode: <pre><code># Raises KeyError if field missing\nresult = mapper.transform(source, strict=True)\n</code></pre></p> <p>Include None Values: <pre><code># Include fields even if None\nresult = mapper.transform(source, skip_none=False)\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#transform_batch","title":"transform_batch()","text":"<p>Transform a list of records.</p> <p>Signature: <pre><code>def transform_batch(\n    source_list: List[Dict[str, Any]],\n    skip_none: bool = True,\n    strict: bool = False\n) -&gt; List[Dict[str, Any]]\n</code></pre></p> <p>Parameters: Same as <code>transform()</code> but accepts a list</p> <p>Returns: List of transformed dictionaries</p> <p>Example: <pre><code>source_list = [\n    {\"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\"},\n    {\"name\": \"Bob\", \"age\": 25, \"city\": \"LA\"},\n    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"SF\"}\n]\n\nmapping = {\n    \"name\": \"Name\",\n    \"age\": \"Age__c\",\n    \"city\": \"BillingCity\"\n}\n\nmapper = FieldMapper(mapping)\nresults = mapper.transform_batch(source_list)\n\nfor record in results:\n    print(record)\n# {\"Name\": \"Alice\", \"Age__c\": 30, \"BillingCity\": \"NYC\"}\n# {\"Name\": \"Bob\", \"Age__c\": 25, \"BillingCity\": \"LA\"}\n# {\"Name\": \"Charlie\", \"Age__c\": 35, \"BillingCity\": \"SF\"}\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#advanced-features","title":"Advanced Features","text":""},{"location":"api/FIELD_MAPPING/#nested-field-access","title":"Nested Field Access","text":"<p>Access nested fields using dot notation.</p> <p>Example: <pre><code>source = {\n    \"user\": {\n        \"profile\": {\n            \"email\": \"john@example.com\",\n            \"name\": \"John Doe\"\n        },\n        \"address\": {\n            \"city\": \"New York\",\n            \"zip\": \"10001\"\n        }\n    }\n}\n\nmapping = {\n    \"user.profile.email\": \"Email\",\n    \"user.profile.name\": \"Name\",\n    \"user.address.city\": \"BillingCity\",\n    \"user.address.zip\": \"BillingPostalCode\"\n}\n\nmapper = FieldMapper(mapping)\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Email\": \"john@example.com\",\n#   \"Name\": \"John Doe\",\n#   \"BillingCity\": \"New York\",\n#   \"BillingPostalCode\": \"10001\"\n# }\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#transformation-functions","title":"Transformation Functions","text":"<p>Custom transformation functions for value processing.</p> <p>Common Transformations:</p> <pre><code># String transformations\nmapping = {\n    \"email\": (\"Email\", lambda x: x.lower()),\n    \"name\": (\"Name\", lambda x: x.strip().title()),\n    \"phone\": (\"Phone\", lambda x: x.replace(\"-\", \"\"))\n}\n\n# Type conversions\nmapping = {\n    \"revenue\": (\"AnnualRevenue\", lambda x: float(x)),\n    \"employee_count\": (\"NumberOfEmployees\", lambda x: int(x)),\n    \"is_active\": (\"IsActive__c\", lambda x: bool(x))\n}\n\n# Date/time formatting\nfrom datetime import datetime\n\nmapping = {\n    \"created_at\": (\n        \"CreatedDate\",\n        lambda x: x.strftime(\"%Y-%m-%d\") if isinstance(x, datetime) else x\n    ),\n    \"updated_at\": (\n        \"LastModifiedDate\",\n        lambda x: x.isoformat() if isinstance(x, datetime) else x\n    )\n}\n\n# Complex transformations\ndef format_address(addr):\n    \"\"\"Format address object to single string\"\"\"\n    if not addr:\n        return None\n    return f\"{addr['street']}, {addr['city']}, {addr['state']} {addr['zip']}\"\n\nmapping = {\n    \"address\": (\"BillingAddress\", format_address)\n}\n</code></pre> <p>Safe Transformations: <pre><code># Handle None values gracefully\ndef safe_upper(value):\n    \"\"\"Convert to uppercase, handle None\"\"\"\n    return value.upper() if value is not None else None\n\nmapping = {\n    \"industry\": (\"Industry\", safe_upper)\n}\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#default-values","title":"Default Values","text":"<p>Provide fallback values for missing fields.</p> <p>Example: <pre><code>mapping = {\n    # Static default\n    \"status\": (\"Status__c\", None, \"Active\"),\n\n    # Dynamic default\n    \"created_date\": (\n        \"CreatedDate\",\n        None,\n        datetime.now().strftime(\"%Y-%m-%d\")\n    ),\n\n    # Transformation with default\n    \"revenue\": (\n        \"AnnualRevenue\",\n        lambda x: float(x) if x else 0,\n        0  # Default if missing\n    )\n}\n\n# Source without 'status' field\nsource = {\"name\": \"ACME Corp\"}\n\nmapper = FieldMapper(mapping)\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Status__c\": \"Active\",  # Used default\n#   \"CreatedDate\": \"2025-01-02\"\n# }\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#built-in-transformations","title":"Built-in Transformations","text":"<p>Pre-defined transformation functions accessible by name.</p> <p>Available Transforms:</p> Name Function Example <code>lowercase</code> Convert to lowercase \"HELLO\" \u2192 \"hello\" <code>uppercase</code> Convert to uppercase \"hello\" \u2192 \"HELLO\" <code>strip</code> Remove whitespace \" text \" \u2192 \"text\" <code>int</code> Convert to integer \"123\" \u2192 123 <code>float</code> Convert to float \"12.5\" \u2192 12.5 <code>bool</code> Convert to boolean \"true\" \u2192 True <code>date_iso</code> Format date as ISO datetime \u2192 \"2025-01-02\" <code>datetime_iso</code> Format datetime as ISO datetime \u2192 \"2025-01-02T10:30:00\" <p>Usage with YAML: <pre><code># config.yaml\nmapping:\n  email:\n    target: Email\n    transform: lowercase\n\n  name:\n    target: Name\n    transform: uppercase\n\n  revenue:\n    target: AnnualRevenue\n    transform: float\n    default: 0\n</code></pre></p> <pre><code>mapper = FieldMapper.from_yaml(\"config.yaml\")\n</code></pre>"},{"location":"api/FIELD_MAPPING/#conditionalfieldmapper","title":"ConditionalFieldMapper","text":"<p>Extended mapper with conditional field logic.</p> <p>Signature: <pre><code>class ConditionalFieldMapper(FieldMapper):\n    def __init__(\n        self,\n        mapping: Dict[str, Any],\n        conditions: Dict[str, Callable] = None\n    )\n</code></pre></p> <p>Parameters: - <code>mapping</code> (dict): Standard field mapping - <code>conditions</code> (dict): Conditional field functions</p> <p>Example: <pre><code>from kinetic_core.mapping import ConditionalFieldMapper\n\nmapper = ConditionalFieldMapper(\n    mapping={\n        \"name\": \"Name\",\n        \"revenue\": \"AnnualRevenue\"\n    },\n    conditions={\n        # Add 'Industry' based on revenue\n        \"Industry\": lambda data: (\n            \"Enterprise\" if data.get(\"revenue\", 0) &gt; 10000000\n            else \"SMB\"\n        ),\n\n        # Add 'Rating' based on multiple fields\n        \"Rating\": lambda data: (\n            \"Hot\" if data.get(\"revenue\", 0) &gt; 5000000 and data.get(\"employees\", 0) &gt; 100\n            else \"Warm\" if data.get(\"revenue\", 0) &gt; 1000000\n            else \"Cold\"\n        ),\n\n        # Add 'Type' based on name\n        \"Type\": lambda data: (\n            \"Partner\" if \"partner\" in data.get(\"name\", \"\").lower()\n            else \"Customer\"\n        )\n    }\n)\n\nsource = {\n    \"name\": \"ACME Partner Corp\",\n    \"revenue\": 15000000,\n    \"employees\": 250\n}\n\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Name\": \"ACME Partner Corp\",\n#   \"AnnualRevenue\": 15000000,\n#   \"Industry\": \"Enterprise\",    # From condition\n#   \"Rating\": \"Hot\",              # From condition\n#   \"Type\": \"Partner\"             # From condition\n# }\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#yaml-configuration","title":"YAML Configuration","text":"<p>Load mapping configuration from YAML files.</p>"},{"location":"api/FIELD_MAPPING/#from_yaml","title":"from_yaml()","text":"<p>Signature: <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: str) -&gt; FieldMapper\n</code></pre></p> <p>Parameters: - <code>yaml_path</code> (str): Path to YAML configuration file</p> <p>Returns: Configured FieldMapper instance</p> <p>YAML Format:</p> <pre><code># mapping_config.yaml\nmapping:\n  # Simple mapping\n  customer_name: Name\n  customer_email: Email\n\n  # With transformation\n  industry_type:\n    target: Industry\n    transform: uppercase\n\n  # With default\n  status:\n    target: Status__c\n    default: Active\n\n  # With both\n  annual_revenue:\n    target: AnnualRevenue\n    transform: float\n    default: 0\n\n  # Nested fields\n  address.city:\n    target: BillingCity\n\n  address.postal_code:\n    target: BillingPostalCode\n</code></pre> <p>Usage: <pre><code>from kinetic_core import FieldMapper\n\n# Load from YAML\nmapper = FieldMapper.from_yaml(\"mapping_config.yaml\")\n\n# Use as normal\nsource = {\n    \"customer_name\": \"ACME Corp\",\n    \"customer_email\": \"info@acme.com\",\n    \"industry_type\": \"technology\",\n    \"annual_revenue\": \"5000000\",\n    \"address\": {\n        \"city\": \"San Francisco\",\n        \"postal_code\": \"94105\"\n    }\n}\n\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Name\": \"ACME Corp\",\n#   \"Email\": \"info@acme.com\",\n#   \"Industry\": \"TECHNOLOGY\",\n#   \"Status__c\": \"Active\",\n#   \"AnnualRevenue\": 5000000.0,\n#   \"BillingCity\": \"San Francisco\",\n#   \"BillingPostalCode\": \"94105\"\n# }\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#real-world-examples","title":"Real-World Examples","text":""},{"location":"api/FIELD_MAPPING/#example-1-csv-to-salesforce","title":"Example 1: CSV to Salesforce","text":"<pre><code>import csv\nfrom kinetic_core import FieldMapper, SalesforceClient\n\n# Define mapping\nmapper = FieldMapper({\n    \"Company Name\": \"Name\",\n    \"Email Address\": (\"Email\", lambda x: x.lower()),\n    \"Phone Number\": (\"Phone\", lambda x: x.replace(\"-\", \"\")),\n    \"Industry Type\": \"Industry\",\n    \"Annual Revenue\": (\"AnnualRevenue\", lambda x: float(x.replace(\"$\", \"\").replace(\",\", \"\"))),\n    \"Employee Count\": (\"NumberOfEmployees\", int),\n    \"Status\": (\"Status__c\", None, \"Active\")\n})\n\n# Read CSV\nwith open(\"companies.csv\", \"r\") as f:\n    reader = csv.DictReader(f)\n    csv_records = list(reader)\n\n# Transform\nsf_records = mapper.transform_batch(csv_records)\n\n# Insert to Salesforce\nclient = SalesforceClient(session)\nresult = client.bulk.insert(\"Account\", sf_records)\n\nprint(f\"Imported {result.success_count} records\")\n</code></pre>"},{"location":"api/FIELD_MAPPING/#example-2-external-api-to-salesforce","title":"Example 2: External API to Salesforce","text":"<pre><code>import requests\nfrom kinetic_core import FieldMapper, SalesforceClient\n\n# Fetch from external API\nresponse = requests.get(\"https://api.example.com/customers\")\ncustomers = response.json()\n\n# Define mapping for nested API response\nmapper = FieldMapper({\n    \"company.name\": \"Name\",\n    \"company.industry\": (\"Industry\", lambda x: x.upper()),\n    \"contact.email\": \"Email\",\n    \"contact.phone\": \"Phone\",\n    \"metadata.created_at\": (\n        \"CreatedDate\",\n        lambda x: datetime.fromisoformat(x).strftime(\"%Y-%m-%d\")\n    ),\n    \"billing.address.city\": \"BillingCity\",\n    \"billing.address.state\": \"BillingState\",\n    \"billing.address.zip\": \"BillingPostalCode\"\n})\n\n# Transform\nsf_records = mapper.transform_batch(customers)\n\n# Upsert to Salesforce\nclient = SalesforceClient(session)\nresult = client.bulk.upsert(\"Account\", sf_records, \"Email\")\n\nprint(f\"Synced {result.success_count} accounts\")\n</code></pre>"},{"location":"api/FIELD_MAPPING/#example-3-conditional-business-logic","title":"Example 3: Conditional Business Logic","text":"<pre><code>from kinetic_core.mapping import ConditionalFieldMapper\n\n# Complex business rules\nmapper = ConditionalFieldMapper(\n    mapping={\n        \"name\": \"Name\",\n        \"email\": (\"Email\", lambda x: x.lower()),\n        \"revenue\": \"AnnualRevenue\",\n        \"employees\": \"NumberOfEmployees\"\n    },\n    conditions={\n        # Tier based on revenue\n        \"Tier__c\": lambda data: (\n            \"Platinum\" if data.get(\"revenue\", 0) &gt; 50000000\n            else \"Gold\" if data.get(\"revenue\", 0) &gt; 10000000\n            else \"Silver\" if data.get(\"revenue\", 0) &gt; 1000000\n            else \"Bronze\"\n        ),\n\n        # Priority scoring\n        \"Priority__c\": lambda data: (\n            \"High\" if (\n                data.get(\"revenue\", 0) &gt; 10000000 or\n                data.get(\"employees\", 0) &gt; 500\n            ) else \"Medium\" if data.get(\"revenue\", 0) &gt; 1000000\n            else \"Low\"\n        ),\n\n        # Account source\n        \"AccountSource\": lambda data: (\n            \"Partner\" if \"partner\" in data.get(\"name\", \"\").lower()\n            else \"Direct\"\n        ),\n\n        # Region based on phone\n        \"Region__c\": lambda data: (\n            \"North America\" if data.get(\"phone\", \"\").startswith(\"+1\")\n            else \"Europe\" if data.get(\"phone\", \"\").startswith(\"+44\")\n            else \"Other\"\n        )\n    }\n)\n\nsource = {\n    \"name\": \"Global Partner Solutions\",\n    \"email\": \"INFO@GPS.COM\",\n    \"revenue\": 25000000,\n    \"employees\": 750,\n    \"phone\": \"+1-555-0100\"\n}\n\nresult = mapper.transform(source)\n\nprint(result)\n# {\n#   \"Name\": \"Global Partner Solutions\",\n#   \"Email\": \"info@gps.com\",\n#   \"AnnualRevenue\": 25000000,\n#   \"NumberOfEmployees\": 750,\n#   \"Tier__c\": \"Gold\",\n#   \"Priority__c\": \"High\",\n#   \"AccountSource\": \"Partner\",\n#   \"Region__c\": \"North America\"\n# }\n</code></pre>"},{"location":"api/FIELD_MAPPING/#example-4-data-validation","title":"Example 4: Data Validation","text":"<pre><code>from kinetic_core import FieldMapper\n\n# Validation functions\ndef validate_email(email):\n    \"\"\"Validate and normalize email\"\"\"\n    if not email or \"@\" not in email:\n        raise ValueError(f\"Invalid email: {email}\")\n    return email.lower().strip()\n\ndef validate_phone(phone):\n    \"\"\"Validate and format phone\"\"\"\n    digits = \"\".join(filter(str.isdigit, phone))\n    if len(digits) &lt; 10:\n        raise ValueError(f\"Invalid phone: {phone}\")\n    return f\"+1-{digits[-10:-7]}-{digits[-7:-4]}-{digits[-4:]}\"\n\ndef validate_revenue(revenue):\n    \"\"\"Validate revenue is positive\"\"\"\n    value = float(revenue)\n    if value &lt; 0:\n        raise ValueError(f\"Revenue cannot be negative: {value}\")\n    return value\n\n# Mapping with validation\nmapper = FieldMapper({\n    \"name\": \"Name\",\n    \"email\": (\"Email\", validate_email),\n    \"phone\": (\"Phone\", validate_phone),\n    \"revenue\": (\"AnnualRevenue\", validate_revenue)\n})\n\n# Transform with strict validation\ntry:\n    result = mapper.transform(source, strict=True)\nexcept ValueError as e:\n    print(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"api/FIELD_MAPPING/#integration-with-pipelines","title":"Integration with Pipelines","text":"<p>Use FieldMapper with SyncPipeline for complete ETL workflows.</p> <p>Example: <pre><code>from kinetic_core import FieldMapper, SyncPipeline, SyncMode\n\n# Define mapping\nmapper = FieldMapper({\n    \"external_id\": \"External_Id__c\",\n    \"company_name\": \"Name\",\n    \"industry\": (\"Industry\", lambda x: x.upper()),\n    \"revenue\": (\"AnnualRevenue\", float)\n})\n\n# Transform data\nexternal_data = fetch_from_external_api()\nsalesforce_data = mapper.transform_batch(external_data)\n\n# Sync to Salesforce\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.UPSERT,\n    external_id_field=\"External_Id__c\"\n)\n\nresult = pipeline.sync(salesforce_data)\nprint(f\"Synced {result.success_count} records\")\n</code></pre></p>"},{"location":"api/FIELD_MAPPING/#best-practices","title":"Best Practices","text":""},{"location":"api/FIELD_MAPPING/#1-use-type-safe-transformations","title":"1. Use Type-Safe Transformations","text":"<pre><code># Good: Handle None values\ndef safe_float(value):\n    try:\n        return float(value) if value is not None else None\n    except (ValueError, TypeError):\n        return None\n\nmapping = {\"revenue\": (\"AnnualRevenue\", safe_float)}\n\n# Bad: May raise exceptions\nmapping = {\"revenue\": (\"AnnualRevenue\", float)}\n</code></pre>"},{"location":"api/FIELD_MAPPING/#2-validate-data","title":"2. Validate Data","text":"<pre><code># Good: Validate during transformation\ndef validate_email(email):\n    if not email or \"@\" not in email:\n        raise ValueError(f\"Invalid email: {email}\")\n    return email.lower()\n\n# Bad: No validation\nmapping = {\"email\": (\"Email\", lambda x: x.lower())}\n</code></pre>"},{"location":"api/FIELD_MAPPING/#3-use-default-values","title":"3. Use Default Values","text":"<pre><code># Good: Provide defaults\nmapping = {\n    \"status\": (\"Status__c\", None, \"Active\"),\n    \"created_date\": (\"CreatedDate\", None, datetime.now().strftime(\"%Y-%m-%d\"))\n}\n\n# Bad: Missing fields cause errors in strict mode\nmapping = {\n    \"status\": \"Status__c\",\n    \"created_date\": \"CreatedDate\"\n}\n</code></pre>"},{"location":"api/FIELD_MAPPING/#4-keep-transformations-simple","title":"4. Keep Transformations Simple","text":"<pre><code># Good: Simple, focused functions\ndef format_phone(phone):\n    \"\"\"Remove non-digits and format\"\"\"\n    return \"\".join(filter(str.isdigit, phone))\n\n# Bad: Complex logic in lambda\nmapping = {\n    \"phone\": (\n        \"Phone\",\n        lambda x: f\"+1-{x[0:3]}-{x[3:6]}-{x[6:]}\" if len(x.replace(\"-\", \"\")) &gt;= 10 else x\n    )\n}\n</code></pre>"},{"location":"api/FIELD_MAPPING/#5-use-yaml-for-configuration","title":"5. Use YAML for Configuration","text":"<pre><code># Good: External configuration\nmapper = FieldMapper.from_yaml(\"config/account_mapping.yaml\")\n\n# Bad: Hardcoded mapping\nmapper = FieldMapper({...})  # Long mapping dict in code\n</code></pre>"},{"location":"api/FIELD_MAPPING/#error-handling","title":"Error Handling","text":""},{"location":"api/FIELD_MAPPING/#handle-missing-fields","title":"Handle Missing Fields","text":"<pre><code># Graceful handling\ntry:\n    result = mapper.transform(source, strict=False)\nexcept Exception as e:\n    logger.error(f\"Transform failed: {e}\")\n\n# Strict mode (raises errors)\ntry:\n    result = mapper.transform(source, strict=True)\nexcept KeyError as e:\n    logger.error(f\"Missing required field: {e}\")\n</code></pre>"},{"location":"api/FIELD_MAPPING/#handle-transformation-failures","title":"Handle Transformation Failures","text":"<pre><code># Batch with error logging\nresults = []\nfor i, source in enumerate(source_list):\n    try:\n        result = mapper.transform(source)\n        results.append(result)\n    except Exception as e:\n        logger.error(f\"Record #{i} failed: {e}\")\n        # Continue processing other records\n        continue\n</code></pre>"},{"location":"api/FIELD_MAPPING/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/FIELD_MAPPING/#batch-processing","title":"Batch Processing","text":"<pre><code># Good: Use transform_batch for large datasets\nresults = mapper.transform_batch(large_dataset)\n\n# Bad: Loop with transform (slower)\nresults = [mapper.transform(rec) for rec in large_dataset]\n</code></pre>"},{"location":"api/FIELD_MAPPING/#caching-transformations","title":"Caching Transformations","text":"<pre><code>from functools import lru_cache\n\n# Cache expensive lookups\n@lru_cache(maxsize=1000)\ndef lookup_industry_code(name):\n    \"\"\"Look up industry code (cached)\"\"\"\n    return industry_lookup.get(name, \"Other\")\n\nmapping = {\n    \"industry_name\": (\"Industry\", lookup_industry_code)\n}\n</code></pre>"},{"location":"api/FIELD_MAPPING/#related-documentation","title":"Related Documentation","text":"<ul> <li>CRUD Operations - Data operations</li> <li>Pipelines - ETL workflows</li> <li>Bulk API v2 - High-volume processing</li> </ul>"},{"location":"api/FIELD_MAPPING/#external-resources","title":"External Resources","text":"<ul> <li>Python typing module</li> <li>Salesforce Field Types</li> <li>Data Transformation Patterns</li> </ul>"},{"location":"api/PIPELINES/","title":"Pipelines - Complete Reference","text":"<p>Orchestrate data synchronization between external sources and Salesforce with flexible, configuration-driven ETL pipelines.</p>"},{"location":"api/PIPELINES/#overview","title":"Overview","text":"<p>The <code>SyncPipeline</code> provides a complete framework for Extract-Transform-Load (ETL) operations, enabling you to:</p> <ul> <li>Extract data from any source (databases, APIs, CSV files, etc.)</li> <li>Transform data using FieldMapper</li> <li>Load data to Salesforce with comprehensive error handling</li> <li>Track progress with callbacks and detailed logging</li> </ul> <p>Key Features: - \u2705 Multiple sync modes (INSERT, UPDATE, UPSERT, DELETE) - \u2705 Batch processing for efficiency - \u2705 Integrated field mapping - \u2705 Progress callbacks and event hooks - \u2705 Comprehensive error tracking - \u2705 Configuration-driven setup - \u2705 Flexible and extensible architecture</p>"},{"location":"api/PIPELINES/#quick-reference","title":"Quick Reference","text":"Component Description <code>SyncPipeline</code> Main pipeline class <code>SyncMode</code> Sync operation modes <code>SyncResult</code> Operation results and metrics <code>SyncStatus</code> Pipeline execution status"},{"location":"api/PIPELINES/#syncmode-enum","title":"SyncMode Enum","text":"<p>Defines the type of synchronization operation.</p> <p>Values:</p> Mode Description Requirements <code>INSERT</code> Create new records - <code>UPDATE</code> Update existing records Requires <code>Id</code> field <code>UPSERT</code> Insert or update Requires external ID field <code>DELETE</code> Delete records Requires <code>Id</code> field <p>Example: <pre><code>from kinetic_core.pipeline import SyncMode\n\n# Use different modes\nmode_insert = SyncMode.INSERT\nmode_update = SyncMode.UPDATE\nmode_upsert = SyncMode.UPSERT\nmode_delete = SyncMode.DELETE\n</code></pre></p>"},{"location":"api/PIPELINES/#syncstatus-enum","title":"SyncStatus Enum","text":"<p>Tracks the status of pipeline execution.</p> <p>Values:</p> Status Description <code>PENDING</code> Not yet started <code>IN_PROGRESS</code> Currently running <code>SUCCESS</code> All records processed successfully <code>FAILED</code> All records failed <code>PARTIAL</code> Some succeeded, some failed"},{"location":"api/PIPELINES/#syncresult-class","title":"SyncResult Class","text":"<p>Contains results and metrics from a synchronization operation.</p> <p>Properties: - <code>status</code> (SyncStatus): Overall sync status - <code>total_records</code> (int): Total records processed - <code>success_count</code> (int): Number of successful operations - <code>error_count</code> (int): Number of failed operations - <code>errors</code> (List[Dict]): Detailed error information - <code>salesforce_ids</code> (List[str]): Created/updated Salesforce IDs - <code>metadata</code> (Dict): Additional metadata (timing, throughput)</p> <p>Methods: - <code>success_rate</code> (property): Calculate success percentage - <code>add_success(salesforce_id)</code>: Record a successful operation - <code>add_error(record_data, error)</code>: Record a failed operation</p> <p>Example: <pre><code>result = pipeline.sync(data)\n\nprint(f\"Status: {result.status.value}\")\nprint(f\"Total: {result.total_records}\")\nprint(f\"Success: {result.success_count}\")\nprint(f\"Errors: {result.error_count}\")\nprint(f\"Success Rate: {result.success_rate:.1f}%\")\n\n# Access created IDs\nfor sf_id in result.salesforce_ids:\n    print(f\"Created: {sf_id}\")\n\n# Check errors\nif result.error_count &gt; 0:\n    for error in result.errors:\n        print(f\"Failed record: {error['record']}\")\n        print(f\"Error: {error['error']}\")\n\n# Metadata\nprint(f\"Elapsed: {result.metadata['elapsed_seconds']}s\")\nprint(f\"Throughput: {result.metadata['records_per_second']} rec/sec\")\n</code></pre></p>"},{"location":"api/PIPELINES/#syncpipeline-class","title":"SyncPipeline Class","text":"<p>Main pipeline class for orchestrating data synchronization.</p>"},{"location":"api/PIPELINES/#initialization","title":"Initialization","text":"<p>Signature: <pre><code>def __init__(\n    self,\n    client: SalesforceClient,\n    sobject: str,\n    mapper: Optional[FieldMapper] = None,\n    mode: SyncMode = SyncMode.INSERT,\n    external_id_field: Optional[str] = None,\n    batch_size: int = 200,\n    stop_on_error: bool = False,\n    callbacks: Optional[Dict[str, Callable]] = None\n)\n</code></pre></p> <p>Parameters: - <code>client</code> (SalesforceClient): Authenticated Salesforce client - <code>sobject</code> (str): Salesforce object API name - <code>mapper</code> (FieldMapper, optional): Field mapping for data transformation - <code>mode</code> (SyncMode): Sync operation mode (default: INSERT) - <code>external_id_field</code> (str, optional): External ID field name (required for UPSERT) - <code>batch_size</code> (int): Records per batch (default: 200) - <code>stop_on_error</code> (bool): Stop on first error (default: False) - <code>callbacks</code> (dict, optional): Event callback functions</p> <p>Example: <pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient, FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\n# Setup client\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\n# Setup mapper\nmapper = FieldMapper({\n    \"customer_name\": \"Name\",\n    \"customer_email\": \"Email\",\n    \"customer_phone\": \"Phone\"\n})\n\n# Create pipeline\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT,\n    batch_size=100\n)\n</code></pre></p>"},{"location":"api/PIPELINES/#core-methods","title":"Core Methods","text":""},{"location":"api/PIPELINES/#sync","title":"sync()","text":"<p>Execute the synchronization pipeline.</p> <p>Signature: <pre><code>def sync(self, source_data: List[Dict[str, Any]]) -&gt; SyncResult\n</code></pre></p> <p>Parameters: - <code>source_data</code> (List[Dict]): List of source data dictionaries</p> <p>Returns: <code>SyncResult</code> with operation results</p> <p>Example: <pre><code># Prepare source data\nsource_data = [\n    {\"customer_name\": \"ACME Corp\", \"customer_email\": \"info@acme.com\"},\n    {\"customer_name\": \"Globex Inc\", \"customer_email\": \"contact@globex.com\"},\n    {\"customer_name\": \"Initech\", \"customer_email\": \"admin@initech.com\"}\n]\n\n# Execute sync\nresult = pipeline.sync(source_data)\n\n# Check results\nif result.status == SyncStatus.SUCCESS:\n    print(f\"\u2713 All {result.success_count} records synced successfully!\")\nelif result.status == SyncStatus.PARTIAL:\n    print(f\"\u26a0 Partial success: {result.success_count}/{result.total_records}\")\n    print(f\"Errors: {result.error_count}\")\nelse:\n    print(f\"\u2717 Sync failed: {result.error_count} errors\")\n\n# Display errors\nfor error in result.errors:\n    print(f\"  - {error['error']}\")\n</code></pre></p>"},{"location":"api/PIPELINES/#from_config","title":"from_config()","text":"<p>Create pipeline from configuration dictionary.</p> <p>Signature: <pre><code>@classmethod\ndef from_config(\n    cls,\n    config: Dict[str, Any],\n    client: SalesforceClient\n) -&gt; SyncPipeline\n</code></pre></p> <p>Parameters: - <code>config</code> (dict): Configuration with keys:   - <code>sobject</code> (str, required): Salesforce object name   - <code>mode</code> (str): Sync mode (default: \"insert\")   - <code>external_id_field</code> (str): External ID field for upsert   - <code>batch_size</code> (int): Batch size (default: 200)   - <code>stop_on_error</code> (bool): Stop on error flag (default: False)   - <code>mapping</code> (dict): Field mapping configuration - <code>client</code> (SalesforceClient): Salesforce client</p> <p>Returns: Configured <code>SyncPipeline</code> instance</p> <p>Example: <pre><code>config = {\n    \"sobject\": \"Account\",\n    \"mode\": \"upsert\",\n    \"external_id_field\": \"External_Key__c\",\n    \"batch_size\": 100,\n    \"stop_on_error\": False,\n    \"mapping\": {\n        \"ext_id\": \"External_Key__c\",\n        \"company\": \"Name\",\n        \"email\": (\"Email\", lambda x: x.lower()),\n        \"industry\": \"Industry\"\n    }\n}\n\npipeline = SyncPipeline.from_config(config, client)\n\n# Use pipeline\nresult = pipeline.sync(source_data)\n</code></pre></p>"},{"location":"api/PIPELINES/#sync-modes-in-detail","title":"Sync Modes in Detail","text":""},{"location":"api/PIPELINES/#insert-mode","title":"INSERT Mode","text":"<p>Create new records in Salesforce.</p> <p>Requirements: None</p> <p>Example: <pre><code>pipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT\n)\n\ndata = [\n    {\"Name\": \"New Company 1\"},\n    {\"Name\": \"New Company 2\"}\n]\n\nresult = pipeline.sync(data)\nprint(f\"Created {result.success_count} accounts\")\n</code></pre></p>"},{"location":"api/PIPELINES/#update-mode","title":"UPDATE Mode","text":"<p>Update existing records.</p> <p>Requirements: All records must include <code>Id</code> field</p> <p>Example: <pre><code>pipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.UPDATE\n)\n\ndata = [\n    {\"Id\": \"001xxx000001\", \"Phone\": \"555-1111\"},\n    {\"Id\": \"001xxx000002\", \"Phone\": \"555-2222\"}\n]\n\nresult = pipeline.sync(data)\nprint(f\"Updated {result.success_count} accounts\")\n</code></pre></p> <p>With Field Mapping: <pre><code>mapper = FieldMapper({\n    \"account_id\": \"Id\",\n    \"new_phone\": \"Phone\",\n    \"new_industry\": \"Industry\"\n})\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.UPDATE\n)\n\ndata = [\n    {\"account_id\": \"001xxx000001\", \"new_phone\": \"555-1111\", \"new_industry\": \"Tech\"}\n]\n\nresult = pipeline.sync(data)\n</code></pre></p>"},{"location":"api/PIPELINES/#upsert-mode","title":"UPSERT Mode","text":"<p>Insert new records or update existing based on external ID.</p> <p>Requirements: - <code>external_id_field</code> parameter must be set - All records must include the external ID field</p> <p>Example: <pre><code>pipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.UPSERT,\n    external_id_field=\"External_Key__c\"\n)\n\ndata = [\n    {\"External_Key__c\": \"EXT001\", \"Name\": \"ACME Corp\"},\n    {\"External_Key__c\": \"EXT002\", \"Name\": \"Globex Inc\"}\n]\n\nresult = pipeline.sync(data)\nprint(f\"Upserted {result.success_count} accounts\")\n</code></pre></p> <p>Prevents Duplicates: <pre><code># First run: Creates 2 records\nresult1 = pipeline.sync(data)\nprint(f\"Created: {result1.success_count}\")  # 2\n\n# Second run: Updates same 2 records (no duplicates)\ndata[0][\"Name\"] = \"ACME Corporation\"  # Changed name\nresult2 = pipeline.sync(data)\nprint(f\"Updated: {result2.success_count}\")  # 2 (same records)\n</code></pre></p>"},{"location":"api/PIPELINES/#delete-mode","title":"DELETE Mode","text":"<p>Delete records from Salesforce (moves to recycle bin).</p> <p>Requirements: All records must include <code>Id</code> field</p> <p>Example: <pre><code>pipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.DELETE\n)\n\ndata = [\n    {\"Id\": \"001xxx000001\"},\n    {\"Id\": \"001xxx000002\"}\n]\n\nresult = pipeline.sync(data)\nprint(f\"Deleted {result.success_count} accounts\")\n</code></pre></p>"},{"location":"api/PIPELINES/#callbacks-and-event-hooks","title":"Callbacks and Event Hooks","text":"<p>Monitor pipeline execution with custom callbacks.</p> <p>Available Callbacks:</p> Callback When Called Parameters <code>on_record_start</code> Before processing each record <code>(record)</code> <code>on_record_success</code> After successful processing <code>(record, salesforce_id)</code> <code>on_record_error</code> After failed processing <code>(record, error)</code> <code>on_batch_complete</code> After each batch <code>(batch_num, total_batches, result)</code> <p>Example: <pre><code>def on_start(record):\n    print(f\"Processing: {record.get('Name', 'Unknown')}\")\n\ndef on_success(record, sf_id):\n    print(f\"\u2713 Created {sf_id} for {record.get('Name')}\")\n\ndef on_error(record, error):\n    print(f\"\u2717 Failed: {record.get('Name')} - {error}\")\n\ndef on_batch(batch_num, total_batches, result):\n    print(f\"Batch {batch_num}/{total_batches} complete\")\n    print(f\"  Success: {result.success_count}, Errors: {result.error_count}\")\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT,\n    callbacks={\n        \"on_record_start\": on_start,\n        \"on_record_success\": on_success,\n        \"on_record_error\": on_error,\n        \"on_batch_complete\": on_batch\n    }\n)\n\nresult = pipeline.sync(data)\n</code></pre></p> <p>Progress Bar Example: <pre><code>from tqdm import tqdm\n\nprogress = None\n\ndef on_batch(batch_num, total_batches, result):\n    global progress\n    if progress is None:\n        progress = tqdm(total=result.total_records, desc=\"Syncing\")\n    progress.update(result.success_count + result.error_count - progress.n)\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT,\n    callbacks={\"on_batch_complete\": on_batch}\n)\n\nresult = pipeline.sync(large_dataset)\nprogress.close()\n</code></pre></p>"},{"location":"api/PIPELINES/#error-handling","title":"Error Handling","text":""},{"location":"api/PIPELINES/#stop-on-error","title":"Stop on Error","text":"<p>Default Behavior (<code>stop_on_error=False</code>): - Pipeline continues processing even if errors occur - All errors are collected in <code>SyncResult.errors</code> - Status becomes <code>PARTIAL</code> if some succeed</p> <pre><code>pipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT,\n    stop_on_error=False  # Default\n)\n\nresult = pipeline.sync(data)\n\n# Check partial failures\nif result.status == SyncStatus.PARTIAL:\n    print(f\"Processed: {result.total_records}\")\n    print(f\"Success: {result.success_count}\")\n    print(f\"Failed: {result.error_count}\")\n\n    for error in result.errors:\n        print(f\"Error: {error['error']}\")\n</code></pre> <p>Stop on First Error (<code>stop_on_error=True</code>): - Pipeline stops immediately on first error - Remaining records are not processed - Useful for data integrity scenarios</p> <pre><code>pipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT,\n    stop_on_error=True\n)\n\ntry:\n    result = pipeline.sync(data)\nexcept Exception as e:\n    print(f\"Pipeline stopped due to error: {e}\")\n</code></pre>"},{"location":"api/PIPELINES/#real-world-examples","title":"Real-World Examples","text":""},{"location":"api/PIPELINES/#example-1-csv-import","title":"Example 1: CSV Import","text":"<pre><code>import csv\nfrom kinetic_core import SalesforceClient, FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\n# Read CSV\nwith open(\"accounts.csv\", \"r\") as f:\n    reader = csv.DictReader(f)\n    csv_data = list(reader)\n\n# Setup mapping\nmapper = FieldMapper({\n    \"Company Name\": \"Name\",\n    \"Email Address\": (\"Email\", lambda x: x.lower()),\n    \"Phone Number\": \"Phone\",\n    \"Industry Type\": \"Industry\",\n    \"Annual Revenue\": (\"AnnualRevenue\", float)\n})\n\n# Create pipeline\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.INSERT,\n    batch_size=200\n)\n\n# Import\nresult = pipeline.sync(csv_data)\n\nprint(f\"Import complete:\")\nprint(f\"  Success: {result.success_count}\")\nprint(f\"  Failed: {result.error_count}\")\nprint(f\"  Duration: {result.metadata['elapsed_seconds']}s\")\n</code></pre>"},{"location":"api/PIPELINES/#example-2-database-to-salesforce-sync","title":"Example 2: Database to Salesforce Sync","text":"<pre><code>import psycopg2\nfrom kinetic_core import SalesforceClient, FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\n# Fetch from PostgreSQL\nconn = psycopg2.connect(\"dbname=mydb user=user password=pass\")\ncursor = conn.cursor()\ncursor.execute(\"SELECT id, name, email, phone FROM customers WHERE synced = false\")\n\n# Convert to dict\ncolumns = [desc[0] for desc in cursor.description]\ndb_data = [dict(zip(columns, row)) for row in cursor.fetchall()]\n\n# Setup sync\nmapper = FieldMapper({\n    \"id\": \"External_Customer_Id__c\",\n    \"name\": \"Name\",\n    \"email\": (\"Email\", lambda x: x.lower()),\n    \"phone\": \"Phone\"\n})\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mapper=mapper,\n    mode=SyncMode.UPSERT,\n    external_id_field=\"External_Customer_Id__c\"\n)\n\n# Sync\nresult = pipeline.sync(db_data)\n\n# Update database\nif result.success_count &gt; 0:\n    success_ids = [r['id'] for r in db_data[:result.success_count]]\n    cursor.execute(\n        \"UPDATE customers SET synced = true WHERE id = ANY(%s)\",\n        (success_ids,)\n    )\n    conn.commit()\n\nconn.close()\n\nprint(f\"Synced {result.success_count} customers from database\")\n</code></pre>"},{"location":"api/PIPELINES/#example-3-api-to-salesforce-with-retry","title":"Example 3: API to Salesforce with Retry","text":"<pre><code>import requests\nfrom kinetic_core import SalesforceClient, FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode, SyncStatus\n\n# Fetch from external API\nresponse = requests.get(\"https://api.example.com/contacts\")\napi_data = response.json()\n\n# Setup pipeline\nmapper = FieldMapper({\n    \"external_id\": \"External_Id__c\",\n    \"first_name\": \"FirstName\",\n    \"last_name\": \"LastName\",\n    \"email\": (\"Email\", lambda x: x.lower()),\n    \"company_name\": \"Account.Name\"  # Nested\n})\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Contact\",\n    mapper=mapper,\n    mode=SyncMode.UPSERT,\n    external_id_field=\"External_Id__c\",\n    stop_on_error=False\n)\n\n# Sync with retry\nmax_retries = 3\nretry_count = 0\nfailed_records = api_data\n\nwhile retry_count &lt; max_retries and failed_records:\n    print(f\"Attempt {retry_count + 1}: Processing {len(failed_records)} records\")\n\n    result = pipeline.sync(failed_records)\n\n    print(f\"  Success: {result.success_count}, Failed: {result.error_count}\")\n\n    if result.status == SyncStatus.SUCCESS:\n        break\n\n    # Prepare failed records for retry\n    if result.error_count &gt; 0:\n        failed_indices = [i for i, error in enumerate(result.errors)]\n        failed_records = [result.errors[i]['record'] for i in failed_indices]\n        retry_count += 1\n    else:\n        break\n\nprint(f\"Final result: {result.success_count} synced, {result.error_count} failed\")\n</code></pre>"},{"location":"api/PIPELINES/#example-4-scheduled-data-sync","title":"Example 4: Scheduled Data Sync","text":"<pre><code>import schedule\nimport time\nfrom kinetic_core import SalesforceClient, FieldMapper\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\ndef sync_daily_leads():\n    \"\"\"Sync new leads from external system\"\"\"\n\n    # Fetch today's leads\n    leads = fetch_leads_from_crm()\n\n    # Setup pipeline\n    mapper = FieldMapper({\n        \"lead_id\": \"External_Lead_Id__c\",\n        \"first_name\": \"FirstName\",\n        \"last_name\": \"LastName\",\n        \"company\": \"Company\",\n        \"email\": (\"Email\", lambda x: x.lower()),\n        \"phone\": \"Phone\",\n        \"status\": (\"Status\", None, \"New\")\n    })\n\n    pipeline = SyncPipeline(\n        client=client,\n        sobject=\"Lead\",\n        mapper=mapper,\n        mode=SyncMode.UPSERT,\n        external_id_field=\"External_Lead_Id__c\"\n    )\n\n    # Sync\n    result = pipeline.sync(leads)\n\n    # Log results\n    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Daily sync complete:\")\n    print(f\"  Leads processed: {result.total_records}\")\n    print(f\"  Success: {result.success_count}\")\n    print(f\"  Errors: {result.error_count}\")\n\n    # Send notification if errors\n    if result.error_count &gt; 0:\n        send_error_notification(result.errors)\n\n# Schedule daily sync at 2 AM\nschedule.every().day.at(\"02:00\").do(sync_daily_leads)\n\nprint(\"Scheduler started. Waiting for jobs...\")\nwhile True:\n    schedule.run_pending()\n    time.sleep(60)\n</code></pre>"},{"location":"api/PIPELINES/#example-5-bulk-update-with-progress-tracking","title":"Example 5: Bulk Update with Progress Tracking","text":"<pre><code>from kinetic_core import SalesforceClient\nfrom kinetic_core.pipeline import SyncPipeline, SyncMode\n\n# Query accounts to update\naccounts = client.query(\n    \"SELECT Id, AnnualRevenue FROM Account WHERE Industry = 'Technology'\"\n)\n\n# Prepare updates\nupdates = []\nfor account in accounts:\n    revenue = account.get('AnnualRevenue', 0)\n    tier = \"Platinum\" if revenue &gt; 10000000 else \"Gold\" if revenue &gt; 1000000 else \"Silver\"\n\n    updates.append({\n        \"Id\": account['Id'],\n        \"Customer_Tier__c\": tier\n    })\n\n# Progress tracking\ndef on_batch(batch_num, total_batches, result):\n    percent = (batch_num / total_batches) * 100\n    print(f\"Progress: {percent:.1f}% ({batch_num}/{total_batches} batches)\")\n    print(f\"  Processed: {result.success_count + result.error_count}/{result.total_records}\")\n\n# Update pipeline\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.UPDATE,\n    batch_size=200,\n    callbacks={\"on_batch_complete\": on_batch}\n)\n\n# Execute update\nresult = pipeline.sync(updates)\n\nprint(f\"\\n\u2713 Update complete!\")\nprint(f\"  Total: {result.total_records}\")\nprint(f\"  Updated: {result.success_count}\")\nprint(f\"  Failed: {result.error_count}\")\nprint(f\"  Duration: {result.metadata['elapsed_seconds']:.2f}s\")\n</code></pre>"},{"location":"api/PIPELINES/#best-practices","title":"Best Practices","text":""},{"location":"api/PIPELINES/#1-use-appropriate-batch-sizes","title":"1. Use Appropriate Batch Sizes","text":"<pre><code># Good: Batch size based on data volume\nif len(data) &lt; 1000:\n    batch_size = 200  # Standard API limit\nelif len(data) &lt; 10000:\n    batch_size = 500\nelse:\n    batch_size = 1000  # Or use Bulk API\n\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT,\n    batch_size=batch_size\n)\n</code></pre>"},{"location":"api/PIPELINES/#2-always-use-external-ids-for-upsert","title":"2. Always Use External IDs for Upsert","text":"<pre><code># Good: Prevents duplicates\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.UPSERT,\n    external_id_field=\"External_Key__c\"\n)\n\n# Bad: INSERT mode may create duplicates\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT\n)\n</code></pre>"},{"location":"api/PIPELINES/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<pre><code># Good: Collect errors for review\npipeline = SyncPipeline(\n    client=client,\n    sobject=\"Account\",\n    mode=SyncMode.INSERT,\n    stop_on_error=False\n)\n\nresult = pipeline.sync(data)\n\nif result.error_count &gt; 0:\n    # Log errors for investigation\n    with open(\"sync_errors.log\", \"w\") as f:\n        for error in result.errors:\n            f.write(f\"{error}\\n\")\n</code></pre>"},{"location":"api/PIPELINES/#4-use-field-mapping","title":"4. Use Field Mapping","text":"<pre><code># Good: Clean separation of concerns\nmapper = FieldMapper({...})\npipeline = SyncPipeline(client=client, sobject=\"Account\", mapper=mapper)\n\n# Bad: Pre-transform data manually\ntransformed_data = [transform(rec) for rec in data]\npipeline = SyncPipeline(client=client, sobject=\"Account\")\n</code></pre>"},{"location":"api/PIPELINES/#5-monitor-performance","title":"5. Monitor Performance","text":"<pre><code>result = pipeline.sync(data)\n\n# Check performance metrics\nprint(f\"Throughput: {result.metadata['records_per_second']} rec/sec\")\nprint(f\"Duration: {result.metadata['elapsed_seconds']}s\")\n\n# Adjust batch size if needed\nif result.metadata['records_per_second'] &lt; 50:\n    print(\"Performance low, consider increasing batch_size or using Bulk API\")\n</code></pre>"},{"location":"api/PIPELINES/#related-documentation","title":"Related Documentation","text":"<ul> <li>Field Mapping - Data transformation</li> <li>CRUD Operations - Standard operations</li> <li>Bulk API v2 - High-volume processing</li> </ul>"},{"location":"api/PIPELINES/#external-resources","title":"External Resources","text":"<ul> <li>ETL Best Practices</li> <li>Salesforce Data Loader</li> <li>Python Design Patterns</li> </ul>"},{"location":"examples/BULK_EXAMPLES/","title":"Bulk API v2 - Practical Examples","text":"<p>Real-world examples for common Bulk API use cases.</p>"},{"location":"examples/BULK_EXAMPLES/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Data Migration</li> <li>CSV Import</li> <li>Scheduled Batch Jobs</li> <li>Data Synchronization</li> <li>Large-Scale Updates</li> <li>Error Recovery</li> </ol>"},{"location":"examples/BULK_EXAMPLES/#data-migration","title":"Data Migration","text":"<p>Migrate large datasets from external systems to Salesforce.</p>"},{"location":"examples/BULK_EXAMPLES/#complete-migration-script","title":"Complete Migration Script","text":"<pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\nimport pandas as pd\n\ndef migrate_accounts_from_csv(csv_file: str):\n    \"\"\"Migrate accounts from CSV to Salesforce\"\"\"\n\n    # Load data\n    df = pd.read_csv(csv_file)\n\n    # Transform to Salesforce format\n    records = df.to_dict('records')\n\n    # Authenticate\n    auth = JWTAuthenticator.from_env()\n    session = auth.authenticate()\n    client = SalesforceClient(session)\n\n    # Bulk insert with progress tracking\n    total = len(records)\n\n    def show_progress(job):\n        processed = job.number_records_processed\n        percent = (processed / total) * 100 if total &gt; 0 else 0\n        print(f\"Migration progress: {processed}/{total} ({percent:.1f}%)\")\n\n    result = client.bulk.insert(\n        \"Account\",\n        records,\n        wait=True,\n        timeout_minutes=30,\n        on_progress=show_progress\n    )\n\n    # Report results\n    print(f\"\\n\u2713 Migration completed!\")\n    print(f\"  Successful: {result.success_count}\")\n    print(f\"  Failed: {result.failed_count}\")\n\n    # Save results\n    if result.success_count &gt; 0:\n        pd.DataFrame(result.success_records).to_csv('migrated_accounts.csv', index=False)\n\n    if result.failed_count &gt; 0:\n        pd.DataFrame(result.failed_records).to_csv('failed_accounts.csv', index=False)\n        print(f\"\\nErrors:\")\n        for error in result.errors[:10]:\n            print(f\"  - {error.message}\")\n\n    return result\n\n# Run migration\nif __name__ == \"__main__\":\n    result = migrate_accounts_from_csv(\"accounts_to_migrate.csv\")\n</code></pre>"},{"location":"examples/BULK_EXAMPLES/#csv-import","title":"CSV Import","text":"<p>Import data from CSV files with validation.</p> <pre><code>import csv\nfrom typing import List, Dict\nfrom kinetic_core import SalesforceClient\n\nclass BulkCSVImporter:\n    \"\"\"Import CSV files using Bulk API v2\"\"\"\n\n    def __init__(self, client: SalesforceClient):\n        self.client = client\n\n    def import_csv(\n        self,\n        csv_path: str,\n        sobject: str,\n        field_mapping: Dict[str, str] = None,\n        batch_size: int = 10000\n    ):\n        \"\"\"\n        Import CSV file to Salesforce.\n\n        Args:\n            csv_path: Path to CSV file\n            sobject: Salesforce object name\n            field_mapping: Map CSV headers to SF fields (optional)\n            batch_size: Records per batch\n        \"\"\"\n        records = self._read_csv(csv_path, field_mapping)\n\n        # Process in batches\n        results = []\n        for i in range(0, len(records), batch_size):\n            batch = records[i:i + batch_size]\n\n            print(f\"Processing batch {i//batch_size + 1}...\")\n            result = self.client.bulk.insert(sobject, batch)\n\n            results.append(result)\n            print(f\"  Success: {result.success_count}, Failed: {result.failed_count}\")\n\n        return results\n\n    def _read_csv(self, csv_path: str, field_mapping: Dict = None) -&gt; List[Dict]:\n        \"\"\"Read and transform CSV\"\"\"\n        records = []\n\n        with open(csv_path, 'r', encoding='utf-8') as f:\n            reader = csv.DictReader(f)\n\n            for row in reader:\n                if field_mapping:\n                    # Apply field mapping\n                    record = {\n                        sf_field: row[csv_field]\n                        for csv_field, sf_field in field_mapping.items()\n                        if csv_field in row\n                    }\n                else:\n                    record = dict(row)\n\n                records.append(record)\n\n        return records\n\n# Usage\nfrom kinetic_core import JWTAuthenticator\n\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\nimporter = BulkCSVImporter(client)\n\n# Import with field mapping\nfield_mapping = {\n    'company_name': 'Name',\n    'industry_type': 'Industry',\n    'annual_revenue': 'AnnualRevenue'\n}\n\nresults = importer.import_csv(\n    'data.csv',\n    'Account',\n    field_mapping=field_mapping,\n    batch_size=5000\n)\n</code></pre>"},{"location":"examples/BULK_EXAMPLES/#scheduled-batch-jobs","title":"Scheduled Batch Jobs","text":"<p>Automate regular data operations.</p> <pre><code>from kinetic_core import SalesforceClient\nfrom datetime import datetime, timedelta\nimport schedule\nimport time\n\nclass ScheduledBulkJob:\n    \"\"\"Run bulk operations on a schedule\"\"\"\n\n    def __init__(self, client: SalesforceClient):\n        self.client = client\n\n    def cleanup_old_records(self, days_old: int = 90):\n        \"\"\"Delete records older than specified days\"\"\"\n\n        # Query old records\n        cutoff_date = (datetime.now() - timedelta(days=days_old)).strftime('%Y-%m-%d')\n\n        query = f\"\"\"\n            SELECT Id\n            FROM Account\n            WHERE CreatedDate &lt; {cutoff_date}\n            AND Status__c = 'Inactive'\n        \"\"\"\n\n        result = self.client.bulk.query(query)\n\n        if result.record_count &gt; 0:\n            ids = [r['Id'] for r in result.records]\n\n            print(f\"Deleting {len(ids)} old records...\")\n            delete_result = self.client.bulk.delete(\"Account\", ids)\n\n            print(f\"Deleted: {delete_result.success_count}\")\n\n            # Log to custom object\n            self._log_cleanup(delete_result)\n\n    def _log_cleanup(self, result):\n        \"\"\"Log cleanup operation\"\"\"\n        log_record = {\n            \"Operation__c\": \"Cleanup\",\n            \"Records_Processed__c\": result.success_count,\n            \"Run_Date__c\": datetime.now().strftime('%Y-%m-%d'),\n            \"Job_Id__c\": result.job.id\n        }\n\n        self.client.create(\"Bulk_Job_Log__c\", log_record)\n\n    def sync_external_system(self):\n        \"\"\"Sync data from external system\"\"\"\n\n        # Fetch from external API\n        external_data = self._fetch_external_data()\n\n        # Upsert to Salesforce\n        result = self.client.bulk.upsert(\n            \"Account\",\n            external_data,\n            external_id_field=\"External_Id__c\"\n        )\n\n        print(f\"Synced: {result.success_count} records\")\n\n    def _fetch_external_data(self):\n        \"\"\"Fetch data from external system (mock)\"\"\"\n        # Replace with actual API call\n        return [\n            {\"External_Id__c\": \"EXT001\", \"Name\": \"External Account 1\"},\n            {\"External_Id__c\": \"EXT002\", \"Name\": \"External Account 2\"}\n        ]\n\n# Setup scheduled jobs\nfrom kinetic_core import JWTAuthenticator\n\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\njob_runner = ScheduledBulkJob(client)\n\n# Schedule cleanup every day at 2 AM\nschedule.every().day.at(\"02:00\").do(job_runner.cleanup_old_records, days_old=90)\n\n# Schedule sync every 6 hours\nschedule.every(6).hours.do(job_runner.sync_external_system)\n\n# Run scheduler\nprint(\"Scheduler started...\")\nwhile True:\n    schedule.run_pending()\n    time.sleep(60)\n</code></pre>"},{"location":"examples/BULK_EXAMPLES/#data-synchronization","title":"Data Synchronization","text":"<p>Bi-directional sync between Salesforce and external systems.</p> <pre><code>from kinetic_core import SalesforceClient\nfrom datetime import datetime\n\nclass DataSync:\n    \"\"\"Synchronize data between Salesforce and external system\"\"\"\n\n    def __init__(self, client: SalesforceClient):\n        self.client = client\n\n    def sync_to_salesforce(self, external_records: list):\n        \"\"\"Sync external data to Salesforce\"\"\"\n\n        # Prepare for upsert\n        sf_records = [\n            {\n                \"External_Id__c\": rec['external_id'],\n                \"Name\": rec['name'],\n                \"Status__c\": rec['status'],\n                \"Last_Sync__c\": datetime.now().isoformat()\n            }\n            for rec in external_records\n        ]\n\n        result = self.client.bulk.upsert(\n            \"Account\",\n            sf_records,\n            external_id_field=\"External_Id__c\"\n        )\n\n        return result\n\n    def sync_from_salesforce(self, last_sync_date: str):\n        \"\"\"Sync Salesforce changes to external system\"\"\"\n\n        # Query changed records\n        query = f\"\"\"\n            SELECT Id, External_Id__c, Name, Status__c\n            FROM Account\n            WHERE LastModifiedDate &gt; {last_sync_date}\n            AND External_Id__c != null\n        \"\"\"\n\n        result = self.client.bulk.query(query)\n\n        # Transform for external system\n        external_updates = [\n            {\n                'external_id': rec['External_Id__c'],\n                'name': rec['Name'],\n                'status': rec['Status__c']\n            }\n            for rec in result.records\n        ]\n\n        # Send to external system\n        self._update_external_system(external_updates)\n\n        return len(external_updates)\n\n    def _update_external_system(self, records):\n        \"\"\"Update external system (mock)\"\"\"\n        print(f\"Updating {len(records)} records in external system\")\n        # Replace with actual API calls\n\n# Usage\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\nsync = DataSync(client)\n\n# Sync to Salesforce\nexternal_data = [\n    {'external_id': 'EXT001', 'name': 'Company A', 'status': 'Active'},\n    {'external_id': 'EXT002', 'name': 'Company B', 'status': 'Inactive'}\n]\n\nresult = sync.sync_to_salesforce(external_data)\nprint(f\"Synced to SF: {result.success_count}\")\n\n# Sync from Salesforce\nupdated = sync.sync_from_salesforce(\"2025-01-01T00:00:00Z\")\nprint(f\"Synced from SF: {updated}\")\n</code></pre>"},{"location":"examples/BULK_EXAMPLES/#large-scale-updates","title":"Large-Scale Updates","text":"<p>Update millions of records efficiently.</p> <pre><code>from kinetic_core import SalesforceClient\n\ndef mass_update_with_retry(\n    client: SalesforceClient,\n    sobject: str,\n    updates: list,\n    max_retries: int = 3\n):\n    \"\"\"\n    Update records with automatic retry for failures.\n\n    Args:\n        client: SalesforceClient instance\n        sobject: Object name\n        updates: Records to update\n        max_retries: Maximum retry attempts\n    \"\"\"\n\n    remaining = updates.copy()\n    attempt = 0\n\n    while remaining and attempt &lt; max_retries:\n        attempt += 1\n        print(f\"\\nAttempt {attempt}: Processing {len(remaining)} records...\")\n\n        result = client.bulk.update(sobject, remaining)\n\n        print(f\"  Success: {result.success_count}\")\n        print(f\"  Failed: {result.failed_count}\")\n\n        if result.failed_count == 0:\n            print(\"\u2713 All records updated successfully!\")\n            return result\n\n        # Prepare failed records for retry\n        remaining = []\n        for i, record in enumerate(result.failed_records):\n            error = result.errors[i] if i &lt; len(result.errors) else None\n\n            # Only retry if error is recoverable\n            if error and 'UNABLE_TO_LOCK_ROW' in error.status_code:\n                # Re-add original record for retry\n                original_record = updates[i]\n                remaining.append(original_record)\n            else:\n                print(f\"  Permanent failure: {error.message if error else 'Unknown'}\")\n\n        if remaining:\n            print(f\"  Will retry {len(remaining)} records...\")\n            time.sleep(5)  # Wait before retry\n\n    if remaining:\n        print(f\"\\n\u2717 {len(remaining)} records failed after {max_retries} attempts\")\n\n    return result\n\n# Usage\nfrom kinetic_core import JWTAuthenticator\n\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\n# Mass update with field formula\nquery_result = client.bulk.query(\n    \"SELECT Id, Annual Revenue FROM Account WHERE AnnualRevenue &gt; 1000000\"\n)\n\nupdates = [\n    {\n        \"Id\": rec[\"Id\"],\n        \"Tier__c\": \"Premium\" if rec[\"AnnualRevenue\"] &gt; 5000000 else \"Standard\"\n    }\n    for rec in query_result.records\n]\n\nresult = mass_update_with_retry(client, \"Account\", updates)\n</code></pre>"},{"location":"examples/BULK_EXAMPLES/#error-recovery","title":"Error Recovery","text":"<p>Handle and recover from bulk operation failures.</p> <pre><code>from kinetic_core import SalesforceClient\nimport json\nfrom datetime import datetime\n\nclass BulkErrorRecovery:\n    \"\"\"Recover from bulk operation failures\"\"\"\n\n    def __init__(self, client: SalesforceClient):\n        self.client = client\n\n    def safe_bulk_insert(self, sobject: str, records: list):\n        \"\"\"Insert with comprehensive error handling\"\"\"\n\n        result = self.client.bulk.insert(sobject, records)\n\n        if result.failed_count &gt; 0:\n            self._handle_failures(sobject, result, records)\n\n        return result\n\n    def _handle_failures(self, sobject, result, original_records):\n        \"\"\"Process and log failures\"\"\"\n\n        # Save failed records\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        error_file = f\"bulk_errors_{sobject}_{timestamp}.json\"\n\n        error_data = {\n            'job_id': result.job.id,\n            'sobject': sobject,\n            'timestamp': timestamp,\n            'total_failed': result.failed_count,\n            'errors': [\n                {\n                    'record': result.failed_records[i] if i &lt; len(result.failed_records) else {},\n                    'error_message': error.message,\n                    'error_code': error.status_code,\n                    'fields': error.fields\n                }\n                for i, error in enumerate(result.errors)\n            ]\n        }\n\n        with open(error_file, 'w') as f:\n            json.dump(error_data, f, indent=2)\n\n        print(f\"\u2717 Errors saved to: {error_file}\")\n\n        # Categorize errors\n        self._categorize_errors(result.errors)\n\n    def _categorize_errors(self, errors):\n        \"\"\"Categorize errors by type\"\"\"\n\n        categories = {}\n\n        for error in errors:\n            error_type = error.status_code\n            categories[error_type] = categories.get(error_type, 0) + 1\n\n        print(\"\\nError summary:\")\n        for error_type, count in sorted(categories.items()):\n            print(f\"  {error_type}: {count}\")\n\n    def retry_from_error_log(self, error_file: str):\n        \"\"\"Retry failed records from error log\"\"\"\n\n        with open(error_file, 'r') as f:\n            error_data = json.load(f)\n\n        sobject = error_data['sobject']\n        failed_records = [e['record'] for e in error_data['errors']]\n\n        print(f\"Retrying {len(failed_records)} failed records...\")\n\n        result = self.client.bulk.insert(sobject, failed_records)\n\n        print(f\"Retry result: {result.success_count} succeeded, {result.failed_count} failed\")\n\n        return result\n\n# Usage\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\nrecovery = BulkErrorRecovery(client)\n\n# Insert with error handling\nrecords = [\n    {\"Name\": \"Valid Account\"},\n    {\"InvalidField__c\": \"This will fail\"},  # Invalid field\n    {\"Name\": None}  # Missing required field\n]\n\nresult = recovery.safe_bulk_insert(\"Account\", records)\n\n# Later, retry from error log\n# recovery.retry_from_error_log(\"bulk_errors_Account_20250102_120000.json\")\n</code></pre>"},{"location":"examples/BULK_EXAMPLES/#performance-monitoring","title":"Performance Monitoring","text":"<p>Track and optimize bulk operation performance.</p> <pre><code>from kinetic_core import SalesforceClient\nimport time\n\nclass BulkPerformanceMonitor:\n    \"\"\"Monitor bulk operation performance\"\"\"\n\n    def __init__(self, client: SalesforceClient):\n        self.client = client\n\n    def benchmark_operation(self, sobject: str, records: list, operation: str = \"insert\"):\n        \"\"\"Benchmark a bulk operation\"\"\"\n\n        print(f\"\\n{'='*60}\")\n        print(f\"Benchmarking {operation} on {sobject}\")\n        print(f\"Records: {len(records):,}\")\n        print(f\"{'='*60}\\n\")\n\n        start_time = time.time()\n\n        # Execute operation\n        if operation == \"insert\":\n            result = self.client.bulk.insert(sobject, records)\n        elif operation == \"update\":\n            result = self.client.bulk.update(sobject, records)\n        else:\n            raise ValueError(f\"Unknown operation: {operation}\")\n\n        end_time = time.time()\n        duration = end_time - start_time\n\n        # Calculate metrics\n        records_per_second = len(records) / duration if duration &gt; 0 else 0\n\n        print(f\"\\nPerformance Metrics:\")\n        print(f\"  Total time: {duration:.2f} seconds\")\n        print(f\"  Records/second: {records_per_second:.0f}\")\n        print(f\"  Success rate: {(result.success_count/len(records)*100):.1f}%\")\n\n        return {\n            'duration': duration,\n            'records_per_second': records_per_second,\n            'success_rate': result.success_count / len(records)\n        }\n\n# Usage\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\nclient = SalesforceClient(session)\n\nmonitor = BulkPerformanceMonitor(client)\n\n# Generate test data\ntest_records = [\n    {\"Name\": f\"Test Account {i}\"}\n    for i in range(10000)\n]\n\nmetrics = monitor.benchmark_operation(\"Account\", test_records, \"insert\")\n</code></pre>"},{"location":"examples/BULK_EXAMPLES/#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udcd6 API Reference</li> <li>\ud83d\ude80 Quick Start Guide</li> <li>\ud83d\udd27 Troubleshooting</li> </ul>"},{"location":"examples/BULK_EXAMPLES/#need-more-examples","title":"Need More Examples?","text":"<p>Open an issue on GitHub with your use case!</p>"},{"location":"guides/BULK_QUICKSTART/","title":"Bulk API v2 - Quick Start Guide","text":"<p>Get started with Bulk API v2 in 5 minutes.</p>"},{"location":"guides/BULK_QUICKSTART/#installation","title":"Installation","text":"<pre><code>pip install kinetic-core&gt;=2.0.0\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#basic-setup","title":"Basic Setup","text":"<pre><code>from kinetic_core import JWTAuthenticator, SalesforceClient\n\n# Authenticate\nauth = JWTAuthenticator.from_env()\nsession = auth.authenticate()\n\n# Create client\nclient = SalesforceClient(session)\n\n# Access Bulk API\nbulk = client.bulk\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#5-common-use-cases","title":"5 Common Use Cases","text":""},{"location":"guides/BULK_QUICKSTART/#1-bulk-insert-create-records","title":"1. Bulk Insert (Create Records)","text":"<pre><code># Prepare data\naccounts = [\n    {\"Name\": \"Acme Corp\", \"Industry\": \"Technology\"},\n    {\"Name\": \"Global Inc\", \"Industry\": \"Finance\"},\n    {\"Name\": \"Tech Solutions\", \"Industry\": \"Software\"}\n]\n\n# Insert\nresult = client.bulk.insert(\"Account\", accounts)\n\n# Check results\nprint(f\"\u2713 Created: {result.success_count}\")\nprint(f\"\u2717 Failed: {result.failed_count}\")\n\n# Get created IDs\nfor record in result.success_records:\n    print(f\"Created: {record['sf__Id']}\")\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#2-bulk-update","title":"2. Bulk Update","text":"<pre><code># Prepare updates (must include Id)\nupdates = [\n    {\"Id\": \"001xxx000001\", \"Industry\": \"Software\"},\n    {\"Id\": \"001xxx000002\", \"AnnualRevenue\": 5000000}\n]\n\n# Update\nresult = client.bulk.update(\"Account\", updates)\n\nif result.failed_count &gt; 0:\n    for error in result.errors:\n        print(f\"Error: {error.message}\")\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#3-bulk-upsert-insert-or-update","title":"3. Bulk Upsert (Insert or Update)","text":"<pre><code># Use external ID to prevent duplicates\nrecords = [\n    {\"External_Key__c\": \"EXT001\", \"Name\": \"New or Existing 1\"},\n    {\"External_Key__c\": \"EXT002\", \"Name\": \"New or Existing 2\"}\n]\n\nresult = client.bulk.upsert(\n    \"Account\",\n    records,\n    external_id_field=\"External_Key__c\"\n)\n\nprint(f\"Inserted/Updated: {result.success_count}\")\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#4-bulk-delete","title":"4. Bulk Delete","text":"<pre><code># Get IDs to delete\nids_to_delete = [\"001xxx000001\", \"001xxx000002\"]\n\n# Delete (moves to recycle bin)\nresult = client.bulk.delete(\"Account\", ids_to_delete)\n\nprint(f\"Deleted: {result.success_count}\")\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#5-bulk-query-export-data","title":"5. Bulk Query (Export Data)","text":"<pre><code># Query large dataset\nquery = \"\"\"\n    SELECT Id, Name, Industry, CreatedDate\n    FROM Account\n    WHERE CreatedDate = THIS_YEAR\n\"\"\"\n\nresult = client.bulk.query(query)\n\nprint(f\"Retrieved {result.record_count} records\")\n\n# Process results\nfor account in result.records:\n    print(f\"{account['Name']} - {account['Industry']}\")\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#progress-tracking","title":"Progress Tracking","text":"<p>Monitor long-running jobs:</p> <pre><code>def show_progress(job):\n    print(f\"State: {job.state}\")\n    print(f\"Processed: {job.number_records_processed}\")\n\nresult = client.bulk.insert(\n    \"Account\",\n    large_dataset,\n    on_progress=show_progress\n)\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#error-handling","title":"Error Handling","text":"<pre><code>result = client.bulk.insert(\"Account\", records)\n\nif result.failed_count &gt; 0:\n    print(f\"\u26a0\ufe0f  {result.failed_count} records failed\")\n\n    for error in result.errors[:5]:  # Show first 5 errors\n        print(f\"  - {error.message}\")\n        print(f\"    Fields: {', '.join(error.fields)}\")\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#async-mode-non-blocking","title":"Async Mode (Non-blocking)","text":"<pre><code># Start job without waiting\nresult = client.bulk.insert(\n    \"Account\",\n    records,\n    wait=False  # Returns immediately\n)\n\nprint(f\"Job started: {result.job.id}\")\nprint(f\"State: {result.job.state}\")\n\n# Check status later\njob = client.bulk.get_job(result.job.id)\nprint(f\"Current state: {job.state}\")\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#performance-tips","title":"Performance Tips","text":""},{"location":"guides/BULK_QUICKSTART/#when-to-use-bulk-api","title":"When to Use Bulk API","text":"<ul> <li>\u2705 Use Bulk API for &gt; 2,000 records</li> <li>\u2705 Use Bulk API for heavy data migrations</li> <li>\u2705 Use Bulk API for scheduled batch jobs</li> <li>\u274c Don't use for &lt; 200 records (standard API is faster)</li> <li>\u274c Don't use for real-time operations</li> </ul>"},{"location":"guides/BULK_QUICKSTART/#optimize-your-batches","title":"Optimize Your Batches","text":"<pre><code># Good: Batch 10k-50k records per operation\nrecords = load_records(limit=25000)\nresult = client.bulk.insert(\"Account\", records)\n\n# Bad: Too many small operations\nfor batch in small_batches:\n    client.bulk.insert(\"Account\", batch)  # Inefficient\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/BULK_QUICKSTART/#pattern-1-retry-failed-records","title":"Pattern 1: Retry Failed Records","text":"<pre><code>result = client.bulk.insert(\"Account\", records)\n\nif result.failed_count &gt; 0:\n    # Extract failed records for retry\n    failed_data = [\n        records[i] for i, record in enumerate(result.failed_records)\n    ]\n\n    # Retry after fixing issues\n    retry_result = client.bulk.insert(\"Account\", failed_data)\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#pattern-2-export-and-transform","title":"Pattern 2: Export and Transform","text":"<pre><code># Export data\nresult = client.bulk.query(\"SELECT Id, Name FROM Account LIMIT 10000\")\n\n# Transform\ntransformed = [\n    {\"Id\": r[\"Id\"], \"Name\": r[\"Name\"].upper()}\n    for r in result.records\n]\n\n# Import back\nclient.bulk.update(\"Account\", transformed)\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#pattern-3-incremental-updates","title":"Pattern 3: Incremental Updates","text":"<pre><code># Get records created today\nquery = \"SELECT Id, Name FROM Account WHERE CreatedDate = TODAY\"\nresult = client.bulk.query(query)\n\n# Apply updates\nupdates = [\n    {\"Id\": r[\"Id\"], \"Status__c\": \"Processed\"}\n    for r in result.records\n]\n\nclient.bulk.update(\"Account\", updates)\n</code></pre>"},{"location":"guides/BULK_QUICKSTART/#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udcd6 Complete API Reference</li> <li>\ud83d\udcdd Migration Guide</li> <li>\ud83d\udca1 Advanced Examples</li> <li>\ud83d\udd27 Troubleshooting</li> </ul>"},{"location":"guides/BULK_QUICKSTART/#need-help","title":"Need Help?","text":"<ul> <li>GitHub Issues</li> <li>Stack Overflow</li> <li>KineticMCP Community</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/","title":"KINETICMCP UPGRADE IMPACT","text":"<p>python -m twine upload dist/*</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#kineticmcp-upgrade-impact-analysis-implementation-plan","title":"KineticMCP Upgrade Impact Analysis &amp; Implementation Plan","text":"<p>Data Analisi: 2025-12-28 Kinetic-Core: v1.1.0 \u2192 v2.0.0 (planned) KineticMCP: Current integration analysis Obiettivo: Implementazione completa Bulk API v2 + tutte le funzionalit\u00e0 Salesforce</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#executive-summary","title":"\ud83c\udfaf EXECUTIVE SUMMARY","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#situazione-attuale","title":"Situazione Attuale","text":"<p>KineticMCP \u00e8 un MCP server che espone 15 tools Salesforce tramite Claude Desktop, utilizzando kinetic-core v1.1.0 come libreria base.</p> <p>Problema identificato: - \u274c kinetic-core usa Composite API (max 200 record) - \u274c KineticMCP ha implementato Bulk API v2 manualmente in <code>bulk.py</code> (104 linee) - \u274c Implementazione duplicata e non ottimale - \u274c Mancanza di funzionalit\u00e0 Bulk avanzate</p> <p>Soluzione proposta: - \u2705 Implementare Bulk API v2 nativamente in kinetic-core - \u2705 Rimuovere implementazione duplicata da KineticMCP - \u2705 Espandere funzionalit\u00e0 Salesforce complete - \u2705 Migliorare performance 20-50x</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#analisi-workspace-completo","title":"\ud83d\udcca ANALISI WORKSPACE COMPLETO","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#struttura-progetti","title":"Struttura Progetti","text":"<pre><code>workspace/\n\u251c\u2500\u2500 kinetic-core/              # Libreria Python base\n\u2502   \u251c\u2500\u2500 kinetic_core/         # Core package\n\u2502   \u2502   \u251c\u2500\u2500 auth/             # JWT + OAuth \u2705\n\u2502   \u2502   \u251c\u2500\u2500 core/             # SalesforceClient \u2705\n\u2502   \u2502   \u251c\u2500\u2500 mapping/          # FieldMapper \u2705\n\u2502   \u2502   \u251c\u2500\u2500 pipeline/         # SyncPipeline \u2705\n\u2502   \u2502   \u2514\u2500\u2500 bulk/             # \u274c DA CREARE\n\u2502   \u251c\u2500\u2500 tests/                # Test suite completa \u2705\n\u2502   \u2514\u2500\u2500 setup.py              # PyPI package\n\u2502\n\u2514\u2500\u2500 kineticmcp/               # MCP Server\n    \u251c\u2500\u2500 src/mcp_salesforce_server/\n    \u2502   \u251c\u2500\u2500 server.py         # 15 MCP tools \u2705\n    \u2502   \u251c\u2500\u2500 salesforce_client.py  # Factory using kinetic-core \u2705\n    \u2502   \u251c\u2500\u2500 bulk.py           # \u26a0\ufe0f DA RIMUOVERE (duplicato)\n    \u2502   \u251c\u2500\u2500 validators.py     # Security \u2705\n    \u2502   \u2514\u2500\u2500 session_manager.py # Multi-session \u2705\n    \u2514\u2500\u2500 requirements.txt      # kinetic-core&gt;=1.1.0\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#dipendenze-attuali","title":"\ud83d\udd0d DIPENDENZE ATTUALI","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#kineticmcp-kinetic-core","title":"KineticMCP \u2192 Kinetic-Core","text":"<p>File: <code>kineticmcp/requirements.txt:1</code> <pre><code>kinetic-core&gt;=1.1.0\n</code></pre></p> <p>Imports in KineticMCP:</p> <ol> <li> <p>server.py:5 <pre><code>from kinetic_core import SyncPipeline, FieldMapper, SyncMode\n</code></pre></p> </li> <li> <p>salesforce_client.py:3 <pre><code>from kinetic_core import SalesforceClient, JWTAuthenticator, OAuthAuthenticator\n</code></pre></p> </li> <li> <p>bulk.py:6 <pre><code>from .salesforce_client import create_salesforce_client\n# Usa kinetic-core indirettamente per auth + session\n# MA implementa Bulk API v2 manualmente con requests\n</code></pre></p> </li> </ol>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#problema-implementazione-bulk-duplicata","title":"\ud83d\udea8 PROBLEMA: IMPLEMENTAZIONE BULK DUPLICATA","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#implementazione-attuale-in-kineticmcp-bulkpy","title":"Implementazione Attuale in KineticMCP (bulk.py)","text":"<pre><code># kineticmcp/src/mcp_salesforce_server/bulk.py (104 linee)\n\nclass BulkJobManager:\n    def __init__(self):\n        self.client = create_salesforce_client()  # Da kinetic-core\n        self.session = self.client.session\n\n    def create_upsert_job(self, sobject: str, external_id_field: str):\n        url = f\"{instance_url}/services/data/v60.0/jobs/ingest\"\n        body = {\n            \"object\": sobject,\n            \"operation\": \"upsert\",\n            \"externalIdFieldName\": external_id_field,\n            \"contentType\": \"CSV\"\n        }\n        resp = requests.post(url, headers=headers, json=body)  # \u26a0\ufe0f Manuale!\n        return resp.json()[\"id\"]\n\n    def upload_data(self, job_id: str, records: List[Dict]):\n        # Converte a CSV manualmente\n        # Upload con requests.put()  # \u26a0\ufe0f Manuale!\n\n    def close_job(self, job_id: str):\n        # requests.patch()  # \u26a0\ufe0f Manuale!\n\n    def get_job_status(self, job_id: str):\n        # requests.get()  # \u26a0\ufe0f Manuale!\n</code></pre> <p>Problemi: - \u274c Duplica logica che dovrebbe essere in kinetic-core - \u274c Hardcoded API version (v60.0) - \u274c Nessun error handling robusto - \u274c Nessun retry logic - \u274c Solo upsert supportato (no insert, update, delete, query) - \u274c Nessun polling automatico - \u274c Nessun parsing risultati CSV - \u274c Manca gestione errori per record singoli</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#impatti-dellupgrade-kinetic-core","title":"\ud83d\udca5 IMPATTI DELL'UPGRADE KINETIC-CORE","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#impact-analysis","title":"Impact Analysis","text":"Componente Impatto Azione Richiesta Priorit\u00e0 kinetic-core/core/client.py \u26a0\ufe0f MEDIO Aggiungere attributo <code>.bulk</code> \ud83d\udd34 Alta kinetic-core/bulk/ \u2705 NUOVO Creare modulo completo \ud83d\udd34 Alta kineticmcp/bulk.py \ud83d\uddd1\ufe0f RIMUOVERE Eliminare e usare kinetic-core \ud83d\udd34 Alta kineticmcp/server.py \u26a0\ufe0f MEDIO Aggiornare imports \ud83d\udfe1 Media kineticmcp/requirements.txt \u26a0\ufe0f BASSO Bump version kinetic-core&gt;=2.0.0 \ud83d\udfe2 Bassa Tests \u2705 NUOVO Aggiungere test Bulk in kinetic-core \ud83d\udd34 Alta"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#backward-compatibility","title":"Backward Compatibility","text":"<p>Breaking Changes: \u274c NESSUNO per API esistenti</p> <p>New Features: \u2705 Solo aggiunte, nessuna modifica API esistente</p> <pre><code># PRIMA (v1.1.0) - Continua a funzionare\nclient = SalesforceClient(session)\nresults = client.create_batch(\"Account\", records)  # Composite API \u2705\n\n# DOPO (v2.0.0) - Nuove funzionalit\u00e0\nclient = SalesforceClient(session)\nresults = client.create_batch(\"Account\", records)  # Composite API \u2705 (unchanged)\nresults = client.bulk.insert(\"Account\", records)   # Bulk API v2 \u2705 (NEW)\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#architettura-proposta","title":"\ud83c\udfd7\ufe0f ARCHITETTURA PROPOSTA","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#nuova-struttura-kinetic-core-v200","title":"Nuova Struttura kinetic-core v2.0.0","text":"<pre><code>kinetic_core/\n\u251c\u2500\u2500 auth/                      # \u2705 Esistente (no changes)\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 session.py            # \u2705 Esistente (no changes)\n\u2502   \u2514\u2500\u2500 client.py             # \u26a0\ufe0f MODIFICATO (aggiungere .bulk property)\n\u251c\u2500\u2500 bulk/                      # \u2b50 NUOVO MODULO\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 client.py             # BulkV2Client\n\u2502   \u251c\u2500\u2500 job.py                # BulkJob, BulkResult models\n\u2502   \u251c\u2500\u2500 serializer.py         # CSV/JSON serialization\n\u2502   \u251c\u2500\u2500 operations.py         # insert, update, upsert, delete, query\n\u2502   \u2514\u2500\u2500 poller.py             # Job status polling\n\u251c\u2500\u2500 mapping/                   # \u2705 Esistente (no changes)\n\u251c\u2500\u2500 pipeline/                  # \u2705 Esistente (no changes)\n\u251c\u2500\u2500 logging/                   # \u2705 Esistente (no changes)\n\u2514\u2500\u2500 utils/                     # \u2705 Esistente (no changes)\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#api-proposta","title":"API Proposta","text":"<pre><code># kinetic_core/core/client.py (modificato)\n\nclass SalesforceClient:\n    def __init__(self, session):\n        self.session = session\n        self._bulk_client = None  # Lazy init\n\n    @property\n    def bulk(self):\n        \"\"\"Access Bulk API v2 operations.\"\"\"\n        if not self._bulk_client:\n            from kinetic_core.bulk import BulkV2Client\n            self._bulk_client = BulkV2Client(self.session)\n        return self._bulk_client\n\n    # ... existing methods (unchanged)\n</code></pre> <pre><code># kinetic_core/bulk/client.py (nuovo)\n\nclass BulkV2Client:\n    \"\"\"Salesforce Bulk API v2 client.\"\"\"\n\n    def insert(self, sobject: str, records: List[Dict], **options) -&gt; BulkResult:\n        \"\"\"Bulk insert records.\"\"\"\n\n    def update(self, sobject: str, records: List[Dict], **options) -&gt; BulkResult:\n        \"\"\"Bulk update records.\"\"\"\n\n    def upsert(self, sobject: str, records: List[Dict],\n               external_id_field: str, **options) -&gt; BulkResult:\n        \"\"\"Bulk upsert records.\"\"\"\n\n    def delete(self, sobject: str, ids: List[str], **options) -&gt; BulkResult:\n        \"\"\"Bulk delete records.\"\"\"\n\n    def query(self, soql: str, **options) -&gt; BulkQueryResult:\n        \"\"\"Bulk query (export large datasets).\"\"\"\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#piano-di-implementazione-completo","title":"\ud83d\udccb PIANO DI IMPLEMENTAZIONE COMPLETO","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#fase-1-implementazione-bulk-api-v2-in-kinetic-core","title":"FASE 1: Implementazione Bulk API v2 in kinetic-core","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-11-creare-struttura-base-2h","title":"Step 1.1: Creare Struttura Base (2h)","text":"<pre><code># File da creare\nkinetic_core/bulk/__init__.py\nkinetic_core/bulk/client.py\nkinetic_core/bulk/job.py\nkinetic_core/bulk/serializer.py\nkinetic_core/bulk/operations.py\nkinetic_core/bulk/poller.py\n</code></pre> <p>Deliverables: - \u2705 Modulo bulk/ con struttura base - \u2705 Models: BulkJob, BulkResult, BulkQueryResult - \u2705 CSV Serializer per conversione records</p> <p>Codice tipo: <pre><code># kinetic_core/bulk/__init__.py\nfrom .client import BulkV2Client\nfrom .job import BulkJob, BulkResult, BulkQueryResult\nfrom .operations import BulkOperation\n\n__all__ = ['BulkV2Client', 'BulkJob', 'BulkResult', 'BulkQueryResult']\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-12-implementare-bulkv2client-core-4h","title":"Step 1.2: Implementare BulkV2Client Core (4h)","text":"<p>File: <code>kinetic_core/bulk/client.py</code></p> <p>Funzionalit\u00e0: 1. Create job (<code>POST /jobs/ingest</code>) 2. Upload CSV data (<code>PUT /jobs/ingest/{jobId}/batches</code>) 3. Close job (<code>PATCH /jobs/ingest/{jobId}</code>) 4. Poll status (<code>GET /jobs/ingest/{jobId}</code>) 5. Get results (<code>GET /jobs/ingest/{jobId}/successfulResults</code>) 6. Get failures (<code>GET /jobs/ingest/{jobId}/failedResults</code>)</p> <p>Features: - \u2705 Auto-retry con exponential backoff - \u2705 Timeout configurabile - \u2705 Polling automatico fino a completamento - \u2705 Parsing CSV risultati - \u2705 Mapping errori per record - \u2705 Progress callbacks</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-13-implementare-operations-3h","title":"Step 1.3: Implementare Operations (3h)","text":"<p>File: <code>kinetic_core/bulk/operations.py</code></p> <p>Implementare: - <code>insert()</code> - Bulk insert - <code>update()</code> - Bulk update (richiede Id) - <code>upsert()</code> - Bulk upsert (richiede external ID) - <code>delete()</code> - Bulk delete (richiede Id) - <code>hard_delete()</code> - Bulk hard delete (permanente) - <code>query()</code> - Bulk query (export grandi dataset)</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-14-aggiungere-property-al-client-1h","title":"Step 1.4: Aggiungere Property al Client (1h)","text":"<p>File: <code>kinetic_core/core/client.py</code></p> <pre><code>@property\ndef bulk(self):\n    \"\"\"Access Bulk API v2 operations.\"\"\"\n    if not self._bulk_client:\n        from kinetic_core.bulk import BulkV2Client\n        self._bulk_client = BulkV2Client(self.session)\n    return self._bulk_client\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-15-test-suite-per-bulk-api-3h","title":"Step 1.5: Test Suite per Bulk API (3h)","text":"<p>File: <code>tests/test_bulk_integration.py</code></p> <p>Test da creare: - \u2705 test_bulk_insert (100 record) - \u2705 test_bulk_update (100 record) - \u2705 test_bulk_upsert (100 record) - \u2705 test_bulk_delete (100 record) - \u2705 test_bulk_query (export 1000+ record) - \u2705 test_bulk_error_handling - \u2705 test_bulk_polling - \u2705 test_bulk_results_parsing - \u2705 test_bulk_csv_serialization</p> <p>Totale Step 1: ~13 ore</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#fase-2-aggiornamento-kineticmcp","title":"FASE 2: Aggiornamento KineticMCP","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-21-rimuovere-implementazione-duplicata-1h","title":"Step 2.1: Rimuovere Implementazione Duplicata (1h)","text":"<pre><code># File da eliminare\nrm kineticmcp/src/mcp_salesforce_server/bulk.py\n</code></pre> <p>Modifiche in server.py:</p> <pre><code># PRIMA\nfrom .bulk import start_bulk_upsert, check_bulk_status\n\n# DOPO\n# Nessun import bulk separato, usare client.bulk\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-22-aggiornare-tool-sf_bulk_upsert-2h","title":"Step 2.2: Aggiornare Tool sf_bulk_upsert (2h)","text":"<p>File: <code>kineticmcp/src/mcp_salesforce_server/server.py</code></p> <p>PRIMA: <pre><code>@mcp.tool()\ndef sf_bulk_upsert(ctx: Context, sobject: str, records: List[Dict],\n                   external_id_field: str):\n    from .bulk import start_bulk_upsert\n    job_id = start_bulk_upsert(sobject, records, external_id_field)\n    return {\"job_id\": job_id, \"status\": \"submitted\"}\n</code></pre></p> <p>DOPO: <pre><code>@mcp.tool()\ndef sf_bulk_upsert(ctx: Context, sobject: str, records: List[Dict],\n                   external_id_field: str, wait: bool = True):\n    \"\"\"Bulk upsert using kinetic-core native Bulk API v2.\"\"\"\n    client = get_client_for_session(ctx)\n\n    if wait:\n        # Sincrono: attendi completamento\n        result = client.bulk.upsert(sobject, records, external_id_field)\n        return {\n            \"success_count\": result.success_count,\n            \"failed_count\": result.failed_count,\n            \"total\": result.total_records,\n            \"errors\": result.errors[:10]  # Primi 10 errori\n        }\n    else:\n        # Asincrono: ritorna job_id\n        job_id = client.bulk.upsert_async(sobject, records, external_id_field)\n        return {\"job_id\": job_id, \"status\": \"submitted\"}\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-23-aggiungere-nuovi-tools-bulk-3h","title":"Step 2.3: Aggiungere Nuovi Tools Bulk (3h)","text":"<p>Nuovi tools da aggiungere:</p> <pre><code>@mcp.tool()\ndef sf_bulk_insert(ctx: Context, sobject: str, records: List[Dict],\n                   wait: bool = True):\n    \"\"\"Bulk insert records (new records only).\"\"\"\n    client = get_client_for_session(ctx)\n    result = client.bulk.insert(sobject, records)\n    return format_bulk_result(result)\n\n@mcp.tool()\ndef sf_bulk_update(ctx: Context, sobject: str, records: List[Dict],\n                   wait: bool = True):\n    \"\"\"Bulk update records (requires Id field).\"\"\"\n    client = get_client_for_session(ctx)\n    result = client.bulk.update(sobject, records)\n    return format_bulk_result(result)\n\n@mcp.tool()\ndef sf_bulk_delete(ctx: Context, sobject: str, ids: List[str],\n                   wait: bool = True):\n    \"\"\"Bulk delete records.\"\"\"\n    client = get_client_for_session(ctx)\n    result = client.bulk.delete(sobject, ids)\n    return format_bulk_result(result)\n\n@mcp.tool()\ndef sf_bulk_query(ctx: Context, soql: str):\n    \"\"\"Bulk query for exporting large datasets (&gt;10k records).\"\"\"\n    client = get_client_for_session(ctx)\n    result = client.bulk.query(soql)\n    return {\n        \"record_count\": len(result.records),\n        \"locator\": result.locator,  # Per paginazione\n        \"records\": result.records[:100]  # Prime 100 righe\n    }\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-24-aggiornare-dependency-version-05h","title":"Step 2.4: Aggiornare Dependency Version (0.5h)","text":"<p>File: <code>kineticmcp/requirements.txt</code></p> <pre><code>- kinetic-core&gt;=1.1.0\n+ kinetic-core&gt;=2.0.0\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-25-aggiornare-documentazione-1h","title":"Step 2.5: Aggiornare Documentazione (1h)","text":"<p>File da aggiornare: - <code>kineticmcp/README.md</code> - Nuove features Bulk API - <code>kineticmcp/docs/tools.md</code> - Documentazione nuovi tools - <code>kineticmcp/CHANGELOG.md</code> - Note di rilascio</p> <p>Totale Step 2: ~7.5 ore</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#fase-3-funzionalita-aggiuntive-salesforce","title":"FASE 3: Funzionalit\u00e0 Aggiuntive Salesforce","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-31-metadata-api-4h","title":"Step 3.1: Metadata API (4h)","text":"<p>Nuove funzionalit\u00e0: <pre><code># kinetic_core/metadata/client.py\nclass MetadataClient:\n    def deploy_components(self, metadata_zip: bytes) -&gt; DeployResult\n    def retrieve_components(self, package_xml: str) -&gt; bytes\n    def create_custom_object(self, definition: Dict) -&gt; str\n    def create_custom_field(self, sobject: str, field_def: Dict) -&gt; str\n</code></pre></p> <p>MCP Tools: - <code>sf_deploy_metadata</code> - Deploy custom objects/fields - <code>sf_retrieve_metadata</code> - Retrieve org metadata - <code>sf_create_custom_field</code> - Create fields programmatically</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-32-streaming-api-5h","title":"Step 3.2: Streaming API (5h)","text":"<p>Nuove funzionalit\u00e0: <pre><code># kinetic_core/streaming/client.py\nclass StreamingClient:\n    def subscribe_pushtopic(self, topic: str, callback: Callable)\n    def subscribe_platform_event(self, event: str, callback: Callable)\n    def subscribe_change_data_capture(self, sobject: str, callback: Callable)\n</code></pre></p> <p>MCP Tools: - <code>sf_subscribe_changes</code> - Monitor record changes in real-time - <code>sf_publish_event</code> - Publish platform events</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-33-apex-rest-api-3h","title":"Step 3.3: Apex REST API (3h)","text":"<p>Nuove funzionalit\u00e0: <pre><code># kinetic_core/apex/client.py\nclass ApexClient:\n    def execute_anonymous(self, apex_code: str) -&gt; ApexResult\n    def call_rest_service(self, url_path: str, method: str, data: Dict)\n</code></pre></p> <p>MCP Tools: - <code>sf_execute_apex</code> - Execute Apex code - <code>sf_call_apex_rest</code> - Call custom Apex REST endpoints</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-34-tooling-api-3h","title":"Step 3.4: Tooling API (3h)","text":"<p>Nuove funzionalit\u00e0: <pre><code># kinetic_core/tooling/client.py\nclass ToolingClient:\n    def query_tooling(self, soql: str) -&gt; List[Dict]\n    def get_logs(self, user_id: str) -&gt; List[LogEntry]\n    def run_tests(self, class_ids: List[str]) -&gt; TestResult\n</code></pre></p> <p>MCP Tools: - <code>sf_query_tooling</code> - Query Tooling API - <code>sf_get_debug_logs</code> - Retrieve debug logs - <code>sf_run_apex_tests</code> - Execute Apex tests</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-35-smart-routing-2h","title":"Step 3.5: Smart Routing (2h)","text":"<p>Auto-selezione metodo migliore:</p> <pre><code># kinetic_core/core/client.py\ndef smart_create(self, sobject: str, records: List[Dict]) -&gt; List[Dict]:\n    \"\"\"Auto-select best method based on record count.\"\"\"\n    count = len(records)\n\n    if count == 1:\n        # Single REST API\n        return [{\"id\": self.create(sobject, records[0])}]\n\n    elif count &lt;= 200:\n        # Composite API (sincrono, veloce)\n        return self.create_batch(sobject, records)\n\n    elif count &lt;= 10000:\n        # Bulk API v2 con attesa (threshold configurabile)\n        return self.bulk.insert(sobject, records)\n\n    else:\n        # Bulk API v2 async (ritorna job_id)\n        job_id = self.bulk.insert_async(sobject, records)\n        return {\"job_id\": job_id, \"use\": \"sf_bulk_status to check\"}\n</code></pre> <p>Totale Step 3: ~17 ore</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#fase-4-testing-documentation","title":"FASE 4: Testing &amp; Documentation","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-41-integration-tests-completi-4h","title":"Step 4.1: Integration Tests Completi (4h)","text":"<p>Test per tutte le nuove funzionalit\u00e0: - Bulk API (insert, update, upsert, delete, query) - Metadata API - Streaming API - Apex API - Tooling API - Smart Routing</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-42-performance-benchmarks-2h","title":"Step 4.2: Performance Benchmarks (2h)","text":"<p>Confronti: - Single REST vs Composite vs Bulk - Diversi volumi (10, 100, 1000, 10000 record) - Metriche: tempo, throughput, error rate</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-43-documentazione-completa-3h","title":"Step 4.3: Documentazione Completa (3h)","text":"<p>File da creare/aggiornare: - <code>docs/BULK_API_GUIDE.md</code> - Guida Bulk API v2 - <code>docs/METADATA_API_GUIDE.md</code> - Guida Metadata API - <code>docs/STREAMING_API_GUIDE.md</code> - Guida Streaming API - <code>docs/PERFORMANCE_GUIDE.md</code> - Best practices performance - <code>README.md</code> - Aggiornamento features</p> <p>Totale Step 4: ~9 ore</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#fase-5-pubblicazione-kinetic-core-su-pypi","title":"FASE 5: Pubblicazione kinetic-core su PyPI","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-51-preparare-setuppy-per-v200-1h","title":"Step 5.1: Preparare setup.py per v2.0.0 (1h)","text":"<p>File: <code>kinetic_core/setup.py</code></p> <p>Modifiche necessarie:</p> <pre><code>from setuptools import setup, find_packages\n\nsetup(\n    name=\"kinetic-core\",\n    version=\"2.0.0\",  # \u26a0\ufe0f BUMP MAJOR VERSION\n    author=\"Your Name\",\n    author_email=\"your.email@example.com\",\n    description=\"Salesforce integration library with Bulk API v2 support\",\n    long_description=open(\"README.md\").read(),\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/yourusername/kinetic-core\",\n    packages=find_packages(),\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Topic :: Software Development :: Libraries :: Python Modules\",\n    ],\n    python_requires=\"&gt;=3.8\",\n    install_requires=[\n        \"requests&gt;=2.31.0\",\n        \"PyJWT&gt;=2.8.0\",\n        \"cryptography&gt;=41.0.0\",\n        \"python-dotenv&gt;=1.0.0\",\n    ],\n    extras_require={\n        \"dev\": [\n            \"pytest&gt;=7.4.0\",\n            \"pytest-cov&gt;=4.1.0\",\n            \"black&gt;=23.0.0\",\n            \"flake8&gt;=6.0.0\",\n            \"mypy&gt;=1.4.0\",\n        ],\n    },\n)\n</code></pre> <p>Checklist: - [ ] Version bumped to 2.0.0 - [ ] Long description aggiornato con nuove features - [ ] Classifiers aggiornati - [ ] Dependencies verificate - [ ] Extras per development</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-52-aggiornare-version-e-all-05h","title":"Step 5.2: Aggiornare version e all (0.5h)","text":"<p>File: <code>kinetic_core/__init__.py</code></p> <pre><code>\"\"\"\nKinetic Core - Salesforce Integration Library\n\nSupports:\n- JWT &amp; OAuth authentication\n- REST API (CRUD operations)\n- Composite API (batch operations)\n- Bulk API v2 (large-scale data operations) \u2b50 NEW\n- Metadata API \u2b50 NEW\n- Streaming API \u2b50 NEW\n- Apex REST API \u2b50 NEW\n- Tooling API \u2b50 NEW\n\"\"\"\n\n__version__ = \"2.0.0\"\n__author__ = \"Your Name\"\n__license__ = \"MIT\"\n\n# Core exports\nfrom .auth import JWTAuthenticator, OAuthAuthenticator\nfrom .core import SalesforceClient, Session\nfrom .mapping import FieldMapper\nfrom .pipeline import SyncPipeline, SyncMode\n\n# New exports in v2.0.0\nfrom .bulk import BulkV2Client, BulkJob, BulkResult\nfrom .metadata import MetadataClient\nfrom .streaming import StreamingClient\nfrom .apex import ApexClient\nfrom .tooling import ToolingClient\n\n__all__ = [\n    # Authentication\n    \"JWTAuthenticator\",\n    \"OAuthAuthenticator\",\n\n    # Core\n    \"SalesforceClient\",\n    \"Session\",\n\n    # Mapping &amp; Pipeline\n    \"FieldMapper\",\n    \"SyncPipeline\",\n    \"SyncMode\",\n\n    # Bulk API v2 (NEW)\n    \"BulkV2Client\",\n    \"BulkJob\",\n    \"BulkResult\",\n\n    # Advanced APIs (NEW)\n    \"MetadataClient\",\n    \"StreamingClient\",\n    \"ApexClient\",\n    \"ToolingClient\",\n]\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-53-creare-changelogmd-1h","title":"Step 5.3: Creare CHANGELOG.md (1h)","text":"<p>File: <code>kinetic_core/CHANGELOG.md</code></p> <pre><code># Changelog\n\nAll notable changes to Kinetic Core will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [2.0.0] - 2025-01-XX\n\n### Added \u2b50\n\n#### Bulk API v2 Support\n- **NEW**: Native Bulk API v2 implementation in `kinetic_core.bulk`\n- `BulkV2Client` with operations:\n  - `insert()` - Bulk insert records\n  - `update()` - Bulk update records\n  - `upsert()` - Bulk upsert with external ID\n  - `delete()` - Bulk delete records\n  - `hard_delete()` - Bulk hard delete (permanent)\n  - `query()` - Bulk query for large exports\n- Auto-retry with exponential backoff\n- Automatic job polling until completion\n- CSV serialization/deserialization\n- Detailed error reporting per record\n- Progress callbacks support\n\n#### Metadata API Support\n- **NEW**: `MetadataClient` for org customization\n- Deploy/retrieve metadata components\n- Create custom objects and fields programmatically\n\n#### Streaming API Support\n- **NEW**: `StreamingClient` for real-time events\n- Subscribe to PushTopics\n- Subscribe to Platform Events\n- Subscribe to Change Data Capture\n\n#### Apex REST API Support\n- **NEW**: `ApexClient` for custom logic\n- Execute anonymous Apex code\n- Call custom Apex REST endpoints\n\n#### Tooling API Support\n- **NEW**: `ToolingClient` for development tasks\n- Query Tooling API objects\n- Retrieve debug logs\n- Run Apex tests\n\n#### Smart Routing\n- **NEW**: `smart_create()` auto-selects best API method\n  - 1 record \u2192 REST API\n  - 2-200 records \u2192 Composite API\n  - 201-10,000 records \u2192 Bulk API v2 (sync)\n  - 10,000+ records \u2192 Bulk API v2 (async)\n\n### Changed\n\n- `SalesforceClient` now has `.bulk` property for Bulk API access\n- All existing methods remain unchanged (100% backward compatible)\n\n### Performance Improvements \ud83d\ude80\n\n- **3x faster** for 100 records (6s \u2192 2s)\n- **12x faster** for 1,000 records (60s \u2192 5s)\n- **20x faster** for 10,000 records (10min \u2192 30s)\n- **50x faster** for 100,000 records (1h 40min \u2192 2min)\n- **98% reduction** in API calls for large volumes\n\n### Documentation\n\n- Complete Bulk API v2 guide\n- Metadata API guide\n- Streaming API guide\n- Performance best practices\n- Migration guide from v1.x\n\n### Breaking Changes\n\n\u274c **NONE** - This release is 100% backward compatible with v1.x\n\n## [1.1.0] - 2025-12-XX\n\n### Added\n- JWT Bearer Flow authentication\n- OAuth 2.0 Password Flow authentication\n- CRUD operations (create, read, update, delete)\n- Composite API batch operations\n- Field mapping utilities\n- Sync pipeline for ETL workflows\n\n### Fixed\n- Various bug fixes and improvements\n\n## [1.0.0] - 2025-11-XX\n\n### Added\n- Initial release\n- Basic Salesforce REST API client\n- Session management\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-54-preparare-manifestin-05h","title":"Step 5.4: Preparare MANIFEST.in (0.5h)","text":"<p>File: <code>kinetic_core/MANIFEST.in</code></p> <pre><code># Include documentation\ninclude README.md\ninclude LICENSE\ninclude CHANGELOG.md\n\n# Include test requirements\ninclude requirements-dev.txt\n\n# Include package data\nrecursive-include kinetic_core *.py\nrecursive-include docs *.md\nrecursive-include tests *.py\n\n# Exclude unnecessary files\nglobal-exclude __pycache__\nglobal-exclude *.py[cod]\nglobal-exclude .DS_Store\nglobal-exclude .env\nglobal-exclude secrets/*\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-55-build-test-package-locally-1h","title":"Step 5.5: Build &amp; Test Package Locally (1h)","text":"<p>Comandi da eseguire:</p> <pre><code># Clean previous builds\nrm -rf dist/ build/ *.egg-info/\n\n# Install build tools\npip install --upgrade build twine\n\n# Build source distribution and wheel\npython -m build\n\n# Verify package contents\ntar -tzf dist/kinetic-core-2.0.0.tar.gz\nunzip -l dist/kinetic_core-2.0.0-py3-none-any.whl\n\n# Test installation in clean virtualenv\npython -m venv test_env\nsource test_env/bin/activate  # Windows: test_env\\Scripts\\activate\npip install dist/kinetic_core-2.0.0-py3-none-any.whl\n\n# Quick test\npython -c \"from kinetic_core import SalesforceClient, BulkV2Client; print('OK')\"\n\n# Test import all new modules\npython -c \"from kinetic_core import *; print('All imports OK')\"\n\n# Deactivate\ndeactivate\nrm -rf test_env\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-56-creare-github-release-15h","title":"Step 5.6: Creare GitHub Release (1.5h)","text":"<p>Processo completo:</p> <ol> <li>Tag della release</li> </ol> <pre><code># Create annotated tag\ngit tag -a v2.0.0 -m \"Release v2.0.0 - Bulk API v2 + Advanced Features\"\n\n# Push tag to GitHub\ngit push origin v2.0.0\n</code></pre> <ol> <li>Creare release su GitHub</li> </ol> <p>Andare su: <code>https://github.com/yourusername/kinetic-core/releases/new</code></p> <p>Release Title: <code>v2.0.0 - Bulk API v2 Support + Advanced Features</code></p> <p>Release Description:</p> <pre><code># Kinetic Core v2.0.0 \ud83d\ude80\n\n## Major New Features\n\n### Bulk API v2 Support \u2b50\nNative support for Salesforce Bulk API v2 - process millions of records efficiently!\n\n**Performance Improvements:**\n- 20-50x faster for large datasets\n- 98% reduction in API calls\n- Automatic job polling and error handling\n\n**New Methods:**\n```python\nclient = SalesforceClient(session)\n\n# Bulk operations via .bulk property\nresult = client.bulk.insert(\"Account\", records)\nresult = client.bulk.update(\"Account\", records)\nresult = client.bulk.upsert(\"Account\", records, \"External_ID__c\")\nresult = client.bulk.delete(\"Account\", ids)\ndata = client.bulk.query(\"SELECT Id, Name FROM Account\")\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#advanced-salesforce-apis","title":"Advanced Salesforce APIs \u2b50","text":"<ul> <li>Metadata API - Deploy/retrieve org customizations</li> <li>Streaming API - Real-time event subscriptions</li> <li>Apex REST API - Execute custom Apex logic</li> <li>Tooling API - Development and debugging tools</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#smart-routing","title":"Smart Routing \u2b50","text":"<p>Auto-selects the best API method based on record count: <pre><code># Automatically uses REST, Composite, or Bulk API\nresult = client.smart_create(\"Account\", records)\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#backward-compatibility_1","title":"Backward Compatibility","text":"<p>\u2705 100% backward compatible with v1.x - all existing code continues to work!</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#installation","title":"Installation","text":"<pre><code>pip install --upgrade kinetic-core\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#documentation","title":"Documentation","text":"<ul> <li>Bulk API v2 Guide</li> <li>Metadata API Guide</li> <li>Streaming API Guide</li> <li>Performance Guide</li> <li>Migration Guide from v1.x</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#whats-changed","title":"What's Changed","text":"<p>See CHANGELOG.md for complete details.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#breaking-changes","title":"Breaking Changes","text":"<p>\u274c NONE - This is a fully backward-compatible release.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#contributors","title":"Contributors","text":"<p>Thanks to all contributors who made this release possible!</p> <p>Full Changelog: https://github.com/yourusername/kinetic-core/compare/v1.1.0...v2.0.0 <pre><code>3. **Allegare assets alla release**\n\nUpload dei seguenti file:\n- `kinetic-core-2.0.0.tar.gz` (source distribution)\n- `kinetic_core-2.0.0-py3-none-any.whl` (wheel)\n- `CHANGELOG.md`\n\n---\n\n#### Step 5.7: Pubblicare su PyPI (1.5h)\n\n**Step-by-step publication:**\n\n1. **Setup PyPI credentials**\n\nCreate `~/.pypirc`:\n\n```ini\n[distutils]\nindex-servers =\n    pypi\n    testpypi\n\n[pypi]\nusername = __token__\npassword = pypi-YOUR-API-TOKEN-HERE\n\n[testpypi]\nrepository = https://test.pypi.org/legacy/\nusername = __token__\npassword = pypi-YOUR-TEST-API-TOKEN-HERE\n</code></pre></p> <ol> <li>Test su TestPyPI (prima pubblicazione)</li> </ol> <pre><code># Upload to Test PyPI\npython -m twine upload --repository testpypi dist/*\n\n# Verify on TestPyPI\n# Visit: https://test.pypi.org/project/kinetic-core/\n\n# Test installation from TestPyPI\npip install --index-url https://test.pypi.org/simple/ kinetic-core==2.0.0\n\n# Quick test\npython -c \"from kinetic_core import BulkV2Client; print('TestPyPI OK')\"\n</code></pre> <ol> <li>Pubblicazione su PyPI Production</li> </ol> <pre><code># Upload to Production PyPI\npython -m twine upload dist/*\n\n# Verify upload\n# Visit: https://pypi.org/project/kinetic-core/\n\n# Check package page shows v2.0.0\n</code></pre> <ol> <li>Verificare installazione</li> </ol> <pre><code># In clean environment\npip install kinetic-core==2.0.0\n\n# Verify version\npython -c \"import kinetic_core; print(kinetic_core.__version__)\"\n# Output: 2.0.0\n\n# Test Bulk API import\npython -c \"from kinetic_core import BulkV2Client; print('Production PyPI OK')\"\n</code></pre> <ol> <li>Annuncio pubblicazione</li> </ol> <p>Post su: - GitHub Discussions - Twitter/X - LinkedIn - Reddit (r/salesforce, r/python) - Dev.to / Medium article</p> <p>Totale Step 5: ~7 ore</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#fase-6-documentazione-kineticmcp","title":"FASE 6: Documentazione KineticMCP","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-61-creare-tools-reference-completa-2h","title":"Step 6.1: Creare Tools Reference Completa (2h)","text":"<p>File: <code>kineticmcp/docs/TOOLS_REFERENCE.md</code></p> <pre><code># KineticMCP Tools Reference - v2.0.0\n\nComplete reference for all 28 Salesforce MCP tools.\n\n## Table of Contents\n\n- [Authentication Tools](#authentication-tools) (3)\n- [CRUD Operations](#crud-operations) (6)\n- [Batch Operations](#batch-operations) (1)\n- [Bulk API v2 Operations](#bulk-api-v2-operations) (6) \u2b50 NEW\n- [Metadata Operations](#metadata-operations) (4)\n- [Streaming Operations](#streaming-operations) (2) \u2b50 NEW\n- [Apex Operations](#apex-operations) (2) \u2b50 NEW\n- [Tooling Operations](#tooling-operations) (3) \u2b50 NEW\n- [Pipeline Operations](#pipeline-operations) (1)\n\n---\n\n## Authentication Tools\n\n### sf_configure\nConfigure Salesforce connection credentials.\n\n**Parameters:**\n- `client_id` (str): OAuth Consumer Key\n- `username` (str): Salesforce username\n- `auth_method` (str): \"jwt\" or \"oauth\"\n- `private_key_path` (str): Path to JWT private key (for JWT auth)\n- `password` (str): Salesforce password (for OAuth)\n- `security_token` (str): Security token (for OAuth)\n\n**Returns:**\n```json\n{\n  \"status\": \"configured\",\n  \"auth_method\": \"jwt\",\n  \"username\": \"user@example.com.sandbox\"\n}\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_login","title":"sf_login","text":"<p>Authenticate to Salesforce.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_logout","title":"sf_logout","text":"<p>End Salesforce session.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#crud-operations","title":"CRUD Operations","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_query","title":"sf_query","text":"<p>Execute SOQL query.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_get","title":"sf_get","text":"<p>Get single record by ID.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_create","title":"sf_create","text":"<p>Create single record.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_update","title":"sf_update","text":"<p>Update single record.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_upsert","title":"sf_upsert","text":"<p>Upsert single record.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_delete","title":"sf_delete","text":"<p>Delete single record.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#batch-operations","title":"Batch Operations","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_create_batch","title":"sf_create_batch","text":"<p>Create multiple records using Composite API (max 200).</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#bulk-api-v2-operations-new","title":"Bulk API v2 Operations \u2b50 NEW","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_bulk_insert","title":"sf_bulk_insert","text":"<p>Bulk insert records (millions supported).</p> <p>Parameters: - <code>sobject</code> (str): Salesforce object name - <code>records</code> (List[Dict]): Records to insert - <code>wait</code> (bool): Wait for completion (default: true)</p> <p>Returns: <pre><code>{\n  \"success_count\": 9800,\n  \"failed_count\": 200,\n  \"total\": 10000,\n  \"errors\": [\n    {\n      \"fields\": [\"Name\"],\n      \"message\": \"Required field missing\",\n      \"status_code\": \"REQUIRED_FIELD_MISSING\"\n    }\n  ]\n}\n</code></pre></p> <p>Example: <pre><code># Insert 10,000 accounts\nrecords = [{\"Name\": f\"Account {i}\"} for i in range(10000)]\nresult = sf_bulk_insert(\"Account\", records)\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_bulk_update","title":"sf_bulk_update","text":"<p>Bulk update records (requires Id field).</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_bulk_upsert","title":"sf_bulk_upsert","text":"<p>Bulk upsert using external ID field.</p> <p>Parameters: - <code>sobject</code> (str): Object name - <code>records</code> (List[Dict]): Records with external ID - <code>external_id_field</code> (str): External ID field name - <code>wait</code> (bool): Wait for completion</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_bulk_delete","title":"sf_bulk_delete","text":"<p>Bulk delete records.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_bulk_query","title":"sf_bulk_query","text":"<p>Bulk query for large exports (&gt;10k records).</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_bulk_status","title":"sf_bulk_status","text":"<p>Check status of async bulk job.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#metadata-operations","title":"Metadata Operations","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_describe","title":"sf_describe","text":"<p>Get object metadata.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_find_related_fields","title":"sf_find_related_fields","text":"<p>Find relationships between objects.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_deploy_metadata-new","title":"sf_deploy_metadata \u2b50 NEW","text":"<p>Deploy metadata components.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_retrieve_metadata-new","title":"sf_retrieve_metadata \u2b50 NEW","text":"<p>Retrieve org metadata.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#streaming-operations-new","title":"Streaming Operations \u2b50 NEW","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_subscribe_changes","title":"sf_subscribe_changes","text":"<p>Subscribe to Change Data Capture events.</p> <p>Parameters: - <code>sobject</code> (str): Object to monitor - <code>callback_url</code> (str): Webhook URL for events</p> <p>Example: <pre><code># Monitor Account changes in real-time\nsf_subscribe_changes(\"Account\", \"https://myapp.com/webhook\")\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_publish_event","title":"sf_publish_event","text":"<p>Publish Platform Event.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#apex-operations-new","title":"Apex Operations \u2b50 NEW","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_execute_apex","title":"sf_execute_apex","text":"<p>Execute anonymous Apex code.</p> <p>Parameters: - <code>apex_code</code> (str): Apex code to execute</p> <p>Example: <pre><code>code = '''\nSystem.debug('Hello from Apex');\nAccount a = new Account(Name='Test');\ninsert a;\n'''\nresult = sf_execute_apex(code)\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_call_apex_rest","title":"sf_call_apex_rest","text":"<p>Call custom Apex REST endpoint.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#tooling-operations-new","title":"Tooling Operations \u2b50 NEW","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_query_tooling","title":"sf_query_tooling","text":"<p>Query Tooling API objects.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_get_debug_logs","title":"sf_get_debug_logs","text":"<p>Retrieve debug logs for user.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_run_apex_tests","title":"sf_run_apex_tests","text":"<p>Execute Apex test classes.</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#pipeline-operations","title":"Pipeline Operations","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#sf_sync_records","title":"sf_sync_records","text":"<p>Execute full ETL sync pipeline.</p> <p><pre><code>---\n\n#### Step 6.2: Creare Usage Examples (2h)\n\n**File:** `kineticmcp/docs/USAGE_EXAMPLES.md`\n\n```markdown\n# KineticMCP Usage Examples\n\nReal-world examples using KineticMCP with Claude Desktop.\n\n## Basic CRUD Operations\n\n### Query Accounts\n</code></pre> User: \"Query the first 10 accounts\"</p> <p>Claude: [Uses sf_query] SELECT Id, Name, Industry FROM Account LIMIT 10 <pre><code>### Create Single Record\n</code></pre> User: \"Create a new account named Acme Corp\"</p> <p>Claude: [Uses sf_create] {   \"Name\": \"Acme Corp\",   \"Industry\": \"Technology\" } <pre><code>## Bulk Operations \u2b50 NEW\n\n### Bulk Insert 10,000 Records\n</code></pre> User: \"Create 10,000 test accounts\"</p> <p>Claude: [Uses sf_bulk_insert instead of sf_create_batch] Preparing bulk insert for 10,000 records... \u2713 Success: 9,998 records created \u2717 Failed: 2 records (validation errors) Completed in 30 seconds <pre><code>### Bulk Update\n</code></pre> User: \"Update all accounts with Industry=Technology to set Rating=Hot\"</p> <p>Claude: Step 1: [Uses sf_query]   SELECT Id FROM Account WHERE Industry='Technology'   Found: 5,000 accounts</p> <p>Step 2: [Uses sf_bulk_update]   Bulk updating 5,000 records...   \u2713 Success: 5,000 updated   Completed in 15 seconds <pre><code>### Bulk Upsert with External ID\n</code></pre> User: \"Upsert these 1000 accounts using External_ID__c field\"</p> <p>Claude: [Uses sf_bulk_upsert] External ID field: External_ID__c Processing 1,000 records... \u2713 Inserted: 300 new records \u2713 Updated: 700 existing records <pre><code>## Advanced Features \u2b50 NEW\n\n### Real-time Monitoring\n</code></pre> User: \"Monitor all Account changes in real-time\"</p> <p>Claude: [Uses sf_subscribe_changes] Subscribed to Account Change Data Capture Monitoring events... \ud83d\udd14 Event: Account created - Name: New Corp \ud83d\udd14 Event: Account updated - Id: 001xxx, Field: Industry <pre><code>### Execute Apex Code\n</code></pre> User: \"Run this Apex code to calculate account revenue\"</p> <p>Claude: [Uses sf_execute_apex] Executing Apex... \u2713 Execution successful Debug log:   Total accounts: 1,250   Total revenue: $15,750,000   Average: $12,600 <pre><code>### Deploy Metadata\n</code></pre> User: \"Create a custom field Phone_Verified__c on Account\"</p> <p>Claude: [Uses sf_deploy_metadata] Creating custom field... Field details:   - Name: Phone_Verified__c   - Type: Checkbox   - Default: false \u2713 Deployment successful <pre><code>## Performance Comparison\n\n### Before (v1.x): Create 10,000 Records\n</code></pre> Using sf_create_batch (Composite API): - 50 API calls (200 records each) - Time: ~10 minutes - Rate limit impact: HIGH <pre><code>### After (v2.0): Create 10,000 Records\n</code></pre> Using sf_bulk_insert (Bulk API v2): - 1 API call - Time: ~30 seconds - Rate limit impact: MINIMAL \u26a1 20x faster! <pre><code>\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-63-aggiornare-readmemd-principale-15h","title":"Step 6.3: Aggiornare README.md principale (1.5h)","text":"<p>File: <code>kineticmcp/README.md</code></p> <p>Aggiungere sezioni:</p> <pre><code># KineticMCP v2.0.0 - Salesforce MCP Server\n\nAI-powered Salesforce integration via Claude Desktop with **Bulk API v2 support**.\n\n## \u2b50 What's New in v2.0\n\n### Bulk API v2 Support\n- Process **millions of records** efficiently\n- **20-50x faster** than Composite API\n- **98% reduction** in API calls\n- 6 new bulk tools: insert, update, upsert, delete, query, status\n\n### Advanced Salesforce APIs\n- **Metadata API** - Deploy/retrieve customizations\n- **Streaming API** - Real-time event monitoring\n- **Apex REST API** - Execute custom logic\n- **Tooling API** - Development tools\n\n### Enhanced Performance\n- Smart routing auto-selects best API method\n- Async job support for large operations\n- Progress tracking and detailed error reporting\n\n## Features\n\n- \ud83d\udd10 Secure authentication (JWT Bearer Flow / OAuth 2.0)\n- \ud83d\udcca **28 MCP tools** for Salesforce operations\n- \u26a1 **Bulk API v2** for large-scale operations (NEW)\n- \ud83d\udd04 Real-time streaming (NEW)\n- \ud83d\udee0\ufe0f Metadata deployment (NEW)\n- \ud83d\udcbb Apex execution (NEW)\n- \ud83c\udfaf Smart API routing (NEW)\n- \ud83d\udd0d Comprehensive CRUD operations\n- \ud83d\ude80 High-performance batch processing\n\n## Installation\n\n```bash\npip install kineticmcp\n</code></pre> <p>Requirements: - Python 3.8+ - kinetic-core &gt;= 2.0.0</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#quick-start","title":"Quick Start","text":"<p>[... existing quick start ...]</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#available-tools-28-total","title":"Available Tools (28 total)","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#authentication-3","title":"Authentication (3)","text":"<ul> <li><code>sf_configure</code> - Configure credentials</li> <li><code>sf_login</code> - Authenticate</li> <li><code>sf_logout</code> - End session</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#crud-operations-6","title":"CRUD Operations (6)","text":"<ul> <li><code>sf_query</code> - SOQL queries</li> <li><code>sf_get</code> - Get by ID</li> <li><code>sf_create</code> - Create record</li> <li><code>sf_update</code> - Update record</li> <li><code>sf_upsert</code> - Upsert record</li> <li><code>sf_delete</code> - Delete record</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#batch-operations-1","title":"Batch Operations (1)","text":"<ul> <li><code>sf_create_batch</code> - Batch create (Composite API, max 200)</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#bulk-api-v2-6-new","title":"Bulk API v2 (6) \u2b50 NEW","text":"<ul> <li><code>sf_bulk_insert</code> - Bulk insert (millions)</li> <li><code>sf_bulk_update</code> - Bulk update</li> <li><code>sf_bulk_upsert</code> - Bulk upsert</li> <li><code>sf_bulk_delete</code> - Bulk delete</li> <li><code>sf_bulk_query</code> - Bulk export</li> <li><code>sf_bulk_status</code> - Check job status</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#metadata-4","title":"Metadata (4)","text":"<ul> <li><code>sf_describe</code> - Object metadata</li> <li><code>sf_find_related_fields</code> - Find relationships</li> <li><code>sf_deploy_metadata</code> - Deploy customizations \u2b50 NEW</li> <li><code>sf_retrieve_metadata</code> - Retrieve metadata \u2b50 NEW</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#streaming-2-new","title":"Streaming (2) \u2b50 NEW","text":"<ul> <li><code>sf_subscribe_changes</code> - Monitor changes</li> <li><code>sf_publish_event</code> - Publish events</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#apex-2-new","title":"Apex (2) \u2b50 NEW","text":"<ul> <li><code>sf_execute_apex</code> - Run Apex code</li> <li><code>sf_call_apex_rest</code> - Call REST endpoints</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#tooling-3-new","title":"Tooling (3) \u2b50 NEW","text":"<ul> <li><code>sf_query_tooling</code> - Tooling queries</li> <li><code>sf_get_debug_logs</code> - Debug logs</li> <li><code>sf_run_apex_tests</code> - Run tests</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#pipeline-1","title":"Pipeline (1)","text":"<ul> <li><code>sf_sync_records</code> - ETL sync</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#performance-benchmarks","title":"Performance Benchmarks","text":"Records v1.x (Composite) v2.0 (Bulk) Improvement 100 6s 2s 3x faster 1,000 60s 5s 12x faster 10,000 600s 30s 20x faster 100,000 6,000s 120s 50x faster"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#documentation_1","title":"Documentation","text":"<ul> <li>Tools Reference</li> <li>Usage Examples</li> <li>Bulk API Guide</li> <li>Performance Guide</li> </ul>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#migration-from-v1x","title":"Migration from v1.x","text":"<p>v2.0 is 100% backward compatible. All existing tools continue to work.</p> <p>New features are opt-in via new tools (sf_bulk_*, sf_execute_apex, etc.).</p> <p>See MIGRATION.md for details. <pre><code>---\n\n#### Step 6.4: Creare CHANGELOG per KineticMCP (1h)\n\n**File:** `kineticmcp/CHANGELOG.md`\n\n```markdown\n# Changelog - KineticMCP\n\n## [2.0.0] - 2025-01-XX\n\n### Added \u2b50\n\n#### Bulk API v2 Tools\n- `sf_bulk_insert` - Bulk insert millions of records\n- `sf_bulk_update` - Bulk update operations\n- `sf_bulk_upsert` - Bulk upsert with external ID\n- `sf_bulk_delete` - Bulk delete operations\n- `sf_bulk_query` - Bulk export large datasets\n- `sf_bulk_status` - Check async job status\n\n#### Metadata Tools\n- `sf_deploy_metadata` - Deploy metadata components\n- `sf_retrieve_metadata` - Retrieve org metadata\n\n#### Streaming Tools\n- `sf_subscribe_changes` - Real-time Change Data Capture\n- `sf_publish_event` - Publish Platform Events\n\n#### Apex Tools\n- `sf_execute_apex` - Execute anonymous Apex\n- `sf_call_apex_rest` - Call custom Apex REST\n\n#### Tooling Tools\n- `sf_query_tooling` - Query Tooling API\n- `sf_get_debug_logs` - Retrieve debug logs\n- `sf_run_apex_tests` - Execute Apex tests\n\n### Changed\n\n- Updated dependency: `kinetic-core&gt;=2.0.0`\n- Removed duplicate Bulk API implementation (now uses kinetic-core native)\n- Enhanced `sf_bulk_upsert` with sync/async modes\n\n### Performance\n\n- 20-50x faster for large operations via Bulk API v2\n- 98% reduction in API calls for 10k+ records\n- Smart routing automatically selects best API method\n\n### Documentation\n\n- Complete tools reference\n- Usage examples for all new features\n- Migration guide from v1.x\n- Performance benchmarks\n\n### Breaking Changes\n\n\u274c **NONE** - Fully backward compatible with v1.x\n\n## [1.0.0] - 2025-12-XX\n\nInitial release with 15 tools.\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#step-65-creare-migration-guide-15h","title":"Step 6.5: Creare Migration Guide (1.5h)","text":"<p>File: <code>kineticmcp/docs/MIGRATION.md</code></p> <pre><code># Migration Guide: KineticMCP v1.x \u2192 v2.0\n\n## Overview\n\nKineticMCP v2.0 is **100% backward compatible** with v1.x.\n\nAll existing tools continue to work exactly as before. New features are opt-in.\n\n## What's Changed\n\n### Dependency Update\n\nUpdate `requirements.txt`:\n\n```diff\n- kinetic-core&gt;=1.1.0\n+ kinetic-core&gt;=2.0.0\n</code></pre> <p>Then reinstall: <pre><code>pip install --upgrade kineticmcp\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#new-tools-available","title":"New Tools Available","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#bulk-operations-recommended-for-200-records","title":"Bulk Operations (Recommended for &gt;200 records)","text":"<p>Before (v1.x): <pre><code># Create 1000 records using sf_create_batch\n# Limited to 200 per call, requires 5 calls\nfor i in range(0, 1000, 200):\n    sf_create_batch(\"Account\", records[i:i+200])\n# Time: ~60 seconds\n</code></pre></p> <p>After (v2.0): <pre><code># Create 1000 records using sf_bulk_insert\n# Single call, all records\nsf_bulk_insert(\"Account\", records)\n# Time: ~5 seconds (12x faster!)\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#when-to-use-each-tool","title":"When to Use Each Tool","text":"Record Count Recommended Tool API Used Speed 1 <code>sf_create</code> REST Instant 2-200 <code>sf_create_batch</code> Composite Fast 201-10,000 <code>sf_bulk_insert</code> Bulk v2 Very Fast 10,000+ <code>sf_bulk_insert</code> Bulk v2 Ultra Fast"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#advanced-features","title":"Advanced Features","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#metadata-deployment","title":"Metadata Deployment","text":"<pre><code># v2.0 NEW: Deploy custom fields programmatically\nsf_deploy_metadata({\n    \"type\": \"CustomField\",\n    \"object\": \"Account\",\n    \"name\": \"Phone_Verified__c\",\n    \"type\": \"Checkbox\"\n})\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#real-time-monitoring","title":"Real-time Monitoring","text":"<pre><code># v2.0 NEW: Subscribe to account changes\nsf_subscribe_changes(\"Account\", callback_url)\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#apex-execution","title":"Apex Execution","text":"<pre><code># v2.0 NEW: Execute Apex code\nsf_execute_apex('''\n    System.debug('Hello from Apex');\n''')\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#no-breaking-changes","title":"No Breaking Changes","text":"<p>All v1.x code continues to work: - \u2705 <code>sf_query</code> - Unchanged - \u2705 <code>sf_create</code> - Unchanged - \u2705 <code>sf_update</code> - Unchanged - \u2705 <code>sf_create_batch</code> - Unchanged - \u2705 All authentication tools - Unchanged</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#recommended-updates","title":"Recommended Updates","text":"<p>While not required, consider these optimizations:</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#1-use-bulk-tools-for-large-operations","title":"1. Use Bulk Tools for Large Operations","text":"<pre><code>- # Old way (still works)\n- sf_create_batch(\"Account\", large_records)\n\n+ # New way (much faster)\n+ sf_bulk_insert(\"Account\", large_records)\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#2-monitor-critical-objects","title":"2. Monitor Critical Objects","text":"<pre><code># NEW: Get notified of Account changes\nsf_subscribe_changes(\"Account\", \"https://myapp.com/webhook\")\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#3-automate-metadata-changes","title":"3. Automate Metadata Changes","text":"<pre><code># NEW: Deploy fields without clicking\nsf_deploy_metadata(field_definition)\n</code></pre>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#troubleshooting","title":"Troubleshooting","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#issue-import-errors-after-upgrade","title":"Issue: Import errors after upgrade","text":"<p>Solution: Reinstall with clean environment <pre><code>pip uninstall kineticmcp kinetic-core\npip install kineticmcp\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#issue-bulk-operations-not-available","title":"Issue: Bulk operations not available","text":"<p>Solution: Verify kinetic-core version <pre><code>import kinetic_core\nprint(kinetic_core.__version__)\n# Should be: 2.0.0 or higher\n</code></pre></p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#support","title":"Support","text":"<ul> <li>Tools Reference</li> <li>Usage Examples</li> <li>GitHub Issues <pre><code>**Totale Step 6:** ~8 ore\n\n---\n\n## \ud83d\udcca TIMELINE COMPLETO (AGGIORNATO)\n\n### Breakdown per Fase\n\n| Fase | Descrizione | Ore | Priorit\u00e0 |\n|------|-------------|-----|----------|\n| **FASE 1** | Bulk API v2 in kinetic-core | 13h | \ud83d\udd34 Critica |\n| **FASE 2** | Aggiornamento KineticMCP | 7.5h | \ud83d\udd34 Critica |\n| **FASE 3** | Funzionalit\u00e0 aggiuntive | 17h | \ud83d\udfe1 Alta |\n| **FASE 4** | Testing &amp; Docs kinetic-core | 9h | \ud83d\udfe1 Alta |\n| **FASE 5** | \ud83d\udce6 Pubblicazione PyPI + GitHub Release | 7h | \ud83d\udd34 **CRITICA** |\n| **FASE 6** | \ud83d\udcda Documentazione KineticMCP Completa | 8h | \ud83d\udd34 **CRITICA** |\n| **TOTALE** | | **61.5h** | |\n\n### Sprint Planning (3 settimane)\n\n**Sprint 1 (Settimana 1):** Bulk API Core + Release Prep\n- Giorni 1-2: Fase 1 (Bulk API v2) \u2705 Critico\n- Giorni 3-4: Fase 2 (KineticMCP update) \u2705 Critico\n- Giorno 5: Fase 4 (Testing base)\n\n**Sprint 2 (Settimana 2):** Funzionalit\u00e0 avanzate\n- Giorni 1-2: Fase 3.1-3.2 (Metadata + Streaming)\n- Giorni 3-4: Fase 3.3-3.5 (Apex + Tooling + Smart Routing)\n- Giorno 5: Fase 4 (Testing avanzato &amp; Docs)\n\n**Sprint 3 (Settimana 3):** Pubblicazione &amp; Documentazione\n- Giorni 1-2: Fase 5 (Preparazione package + PyPI)\n- Giorni 3-4: Fase 6 (Documentazione KineticMCP completa)\n- Giorno 5: Release finale + Annunci\n\n---\n\n## \ud83c\udfaf DELIVERABLES FINALI\n\n### kinetic-core v2.0.0\n\n**Nuovi Moduli:**\n</code></pre> kinetic_core/ \u251c\u2500\u2500 bulk/                  \u2b50 Bulk API v2 completo \u251c\u2500\u2500 metadata/              \u2b50 Metadata API \u251c\u2500\u2500 streaming/             \u2b50 Streaming API \u251c\u2500\u2500 apex/                  \u2b50 Apex REST API \u2514\u2500\u2500 tooling/               \u2b50 Tooling API <pre><code>**Nuovi Metodi SalesforceClient:**\n- `client.bulk.*` - Tutte operazioni bulk\n- `client.metadata.*` - Deploy/retrieve metadata\n- `client.streaming.*` - Subscribe eventi\n- `client.apex.*` - Execute Apex\n- `client.tooling.*` - Tooling queries\n- `client.smart_create()` - Auto-routing\n\n### KineticMCP v2.0.0\n\n**Nuovi Tools (totale: 25+):**\n\n| Categoria | Tools | Count |\n|-----------|-------|-------|\n| **Auth** | configure, login, logout | 3 |\n| **CRUD** | query, get, create, update, upsert, delete | 6 |\n| **Batch** | create_batch | 1 |\n| **Bulk** | bulk_insert, bulk_update, bulk_upsert, bulk_delete, bulk_query, bulk_status | 6 |\n| **Metadata** | describe, find_related_fields, deploy_metadata, retrieve_metadata | 4 |\n| **Streaming** | subscribe_changes, publish_event | 2 |\n| **Apex** | execute_apex, call_apex_rest | 2 |\n| **Tooling** | query_tooling, get_debug_logs, run_tests | 3 |\n| **Pipeline** | sync_records | 1 |\n| **TOTALE** | | **28 tools** |\n\n---\n\n## \ud83d\udcc8 PERFORMANCE IMPROVEMENTS\n\n### Before vs After\n\n| Operation | Before (v1.1.0) | After (v2.0.0) | Improvement |\n|-----------|-----------------|----------------|-------------|\n| **100 record insert** | 6s (Composite) | 2s (Bulk) | 3x faster |\n| **1,000 record insert** | 60s (Composite chunks) | 5s (Bulk) | 12x faster |\n| **10,000 record insert** | 600s (10min) | 30s (Bulk) | 20x faster |\n| **100,000 record insert** | 6,000s (1h 40min) | 120s (2min) | 50x faster |\n\n### Cost Savings\n\n**API Call Reduction:**\n- 10,000 record: 50 Composite calls \u2192 1 Bulk job\n- 100,000 record: 500 Composite calls \u2192 1 Bulk job\n\n**Risparmio:** ~98% API calls per grandi volumi\n\n---\n\n## \u26a0\ufe0f RISCHI E MITIGAZIONI\n\n### Rischio 1: Breaking Changes\n\n**Probabilit\u00e0:** BASSA\n**Impatto:** ALTO\n\n**Mitigazione:**\n- \u2705 Mantenere 100% backward compatibility\n- \u2705 Solo aggiunte, nessuna modifica API esistente\n- \u2705 Deprecation warnings per funzionalit\u00e0 obsolete\n\n### Rischio 2: Performance Regression\n\n**Probabilit\u00e0:** BASSA\n**Impatto:** MEDIO\n\n**Mitigazione:**\n- \u2705 Extensive performance testing\n- \u2705 Benchmarks prima/dopo\n- \u2705 Smart routing automatico\n\n### Rischio 3: Salesforce API Limits\n\n**Probabilit\u00e0:** MEDIA\n**Impatto:** MEDIO\n\n**Mitigazione:**\n- \u2705 Rate limiting implementato\n- \u2705 Retry con exponential backoff\n- \u2705 Monitoring API usage\n\n### Rischio 4: Complessit\u00e0 Implementazione\n\n**Probabilit\u00e0:** MEDIA\n**Impatto:** BASSO\n\n**Mitigazione:**\n- \u2705 Architettura modulare\n- \u2705 Test-driven development\n- \u2705 Code review rigoroso\n\n---\n\n## \u2705 ACCEPTANCE CRITERIA\n\n### Must Have (Release Blocker) - FASE 1+2+5\n\n- [ ] Bulk API v2 insert/update/upsert/delete funzionanti\n- [ ] KineticMCP aggiornato e funzionante con nuovi tools\n- [ ] 100% backward compatibility (nessun breaking change)\n- [ ] Test coverage &gt;80% per Bulk API\n- [ ] **kinetic-core v2.0.0 pubblicato su PyPI** \u2b50\n- [ ] **GitHub release v2.0.0 creata con assets** \u2b50\n- [ ] **CHANGELOG.md completo** \u2b50\n- [ ] Documentazione base Bulk API\n- [ ] Performance 10x+ migliore su 10k+ record\n- [ ] **Dependency in KineticMCP aggiornata a kinetic-core&gt;=2.0.0** \u2b50\n\n### Should Have (Nice to Have) - FASE 3+4+6\n\n- [ ] Metadata API implementata\n- [ ] Streaming API implementata\n- [ ] Smart routing automatico\n- [ ] Apex REST API\n- [ ] Tooling API\n- [ ] **Documentazione KineticMCP completa** (Tools Reference, Examples, Migration Guide) \u2b50\n- [ ] Performance benchmarks documentati\n- [ ] Guide complete per tutte le nuove API\n\n### Could Have (Future Release)\n\n- [ ] Bulk API v2 query avanzate\n- [ ] Parallel job execution\n- [ ] Progress streaming real-time\n- [ ] Advanced error recovery\n- [ ] Video tutorials\n- [ ] Interactive examples\n\n---\n\n## \ud83d\ude80 NEXT STEPS\n\n### Immediate Actions (Pre-Development)\n\n1. **Configurare Salesforce per Bulk API**\n   - Aggiungere scope OAuth \"full\" alla Connected App\n   - Creare Permission Set con Bulk permissions\n   - Testare configurazione con script di verifica\n   - Documentare setup in SALESFORCE_BULK_CONFIG.md\n\n2. **Setup Development Environment**\n   - Branch: `feature/bulk-api-v2` per kinetic-core\n   - Branch: `feature/v2-integration` per kineticmcp\n   - Tests setup + fixtures\n   - CI/CD pipeline (GitHub Actions)\n\n3. **Preparare Infrastructure di Release**\n   - Creare account PyPI (se non presente)\n   - Generare API token per PyPI\n   - Setup `.pypirc` con credenziali\n   - Testare build process su TestPyPI\n\n### Week 1 Goals (Sprint 1)\n\n- \u2705 Bulk API v2 implementato in kinetic-core\n- \u2705 KineticMCP aggiornato con integrazione native Bulk\n- \u2705 Test suite base per Bulk API\n- \u2705 Rimozione codice duplicato da KineticMCP\n\n### Week 2 Goals (Sprint 2)\n\n- \u2705 Metadata + Streaming API implementate\n- \u2705 Apex + Tooling API implementate\n- \u2705 Smart routing funzionante\n- \u2705 Test suite completa per tutte le API\n- \u2705 Performance benchmarks eseguiti\n\n### Week 3 Goals (Sprint 3) \u2b50 **CRITICO**\n\n- \u2705 **setup.py aggiornato a v2.0.0**\n- \u2705 **CHANGELOG.md completo**\n- \u2705 **MANIFEST.in configurato**\n- \u2705 **Build package e test locale**\n- \u2705 **GitHub release v2.0.0 pubblicata**\n- \u2705 **kinetic-core v2.0.0 pubblicato su PyPI**\n- \u2705 **KineticMCP dependency aggiornata**\n- \u2705 **Documentazione KineticMCP completa** (TOOLS_REFERENCE, USAGE_EXAMPLES, MIGRATION)\n- \u2705 **Annunci pubblici**\n\n---\n\n## \ud83d\udcde CONCLUSIONE\n\n### Summary\n\n**Impatto totale:** \ud83d\udd34 **ALTO** ma gestibile\n\n**Effort richiesto:** ~61.5 ore (3 settimane sprint)\n\n**Breakdown:**\n- Sviluppo: 46.5h (Fasi 1-4)\n- Pubblicazione: 7h (Fase 5) \u2b50 **CRITICO**\n- Documentazione: 8h (Fase 6) \u2b50 **CRITICO**\n\n**Benefici:**\n- \u2705 Performance 20-50x migliori\n- \u2705 Supporto completo Salesforce API\n- \u2705 28 tools MCP vs 15 attuali\n- \u2705 Architettura pi\u00f9 robusta\n- \u2705 Manutenibilit\u00e0 migliorata\n- \u2705 **Package pubblicato su PyPI** (raggiungere community)\n- \u2705 **Release GitHub professionale** (versioning chiaro)\n- \u2705 **Documentazione enterprise-grade** (adozione facilitata)\n\n**Raccomandazione:** \u2705 **PROCEDERE CON IMPLEMENTAZIONE COMPLETA**\n\n### Perch\u00e9 l'upgrade \u00e8 necessario\n\n1. **Eliminare codice duplicato**\n   - KineticMCP ha 104 linee di Bulk API manuale\n   - kinetic-core non ha supporto nativo\n   - Duplicazione = manutenzione doppia + bug potenziali\n\n2. **Supportare grandi volumi**\n   - Clienti enterprise necessitano milioni di record\n   - Composite API limita a 200 record/batch\n   - Bulk API v2 = competitive advantage\n\n3. **Fornire feature complete Salesforce**\n   - Metadata API = automazione deployment\n   - Streaming API = real-time capabilities\n   - Apex/Tooling API = developer experience completa\n\n4. **Rendere KineticMCP production-ready enterprise**\n   - Copertura API completa\n   - Performance professionali\n   - Documentazione enterprise\n\n### Perch\u00e9 FASE 5 e 6 sono critiche \u2b50\n\n**Senza Fase 5 (Pubblicazione PyPI):**\n- \u274c KineticMCP non pu\u00f2 usare kinetic-core v2.0.0\n- \u274c Utenti non possono installare con `pip install kinetic-core`\n- \u274c Dependency `kinetic-core&gt;=2.0.0` fallisce\n- \u274c **Tutto il lavoro \u00e8 inutilizzabile**\n\n**Senza Fase 6 (Documentazione KineticMCP):**\n- \u274c Utenti non sanno come usare i 13 nuovi tools\n- \u274c Nessuna migration guide = confusione\n- \u274c Bassa adozione delle nuove features\n- \u274c Support overhead alto (domande ripetitive)\n\n### Critical Path\n</code></pre> FASE 1-2-3-4 (Sviluppo)     \u2193 FASE 5 (PyPI) \u2b50 BLOCCA TUTTO     \u2193 FASE 6 (Docs) \u2b50 ABILITA ADOZIONE     \u2193 SUCCESS \u2705 ```</li> </ul> <p>Senza Fase 5: Il progetto non funziona Senza Fase 6: Il progetto funziona ma nessuno sa come usarlo</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#deliverables-finali-garantiti","title":"Deliverables Finali Garantiti","text":"<p>\u2705 kinetic-core v2.0.0 - Pubblicato su PyPI - GitHub release con assets - CHANGELOG completo - Installabile con <code>pip install kinetic-core==2.0.0</code></p> <p>\u2705 KineticMCP v2.0.0 - 28 tools (da 15) - Dependency aggiornata - Documentazione completa:   - TOOLS_REFERENCE.md (reference per tutti i tools)   - USAGE_EXAMPLES.md (esempi pratici)   - MIGRATION.md (guida migrazione)   - CHANGELOG.md (note di rilascio)</p> <p>\u2705 Visibilit\u00e0 &amp; Adozione - Package su PyPI = discovery organica - GitHub release = professionalit\u00e0 - Docs = self-service support - Annunci = awareness community</p> <p>Documento creato: 2025-12-28 Ultimo aggiornamento: 2026-01-01 Autore: Code Analysis + Planning Status: \u2705 Ready for Implementation (Complete Plan) Next: Kickoff Sprint 1</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#appendice-checklist-pubblicazione","title":"\ud83d\udcda APPENDICE: Checklist Pubblicazione","text":""},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#pre-publication-checklist-fase-5","title":"Pre-Publication Checklist (Fase 5)","text":"<p>Setup PyPI: - [ ] Account PyPI creato - [ ] API token generato - [ ] <code>.pypirc</code> configurato - [ ] Account TestPyPI creato (per testing)</p> <p>Preparazione Package: - [ ] <code>setup.py</code> version = \"2.0.0\" - [ ] <code>__init__.py</code> version = \"2.0.0\" - [ ] <code>CHANGELOG.md</code> completato - [ ] <code>MANIFEST.in</code> configurato - [ ] <code>README.md</code> aggiornato con nuove features</p> <p>Testing Locale: - [ ] <code>python -m build</code> completa senza errori - [ ] Verifica contenuti <code>.tar.gz</code> e <code>.whl</code> - [ ] Test installazione in virtualenv pulito - [ ] Import tutti i nuovi moduli funzionano</p> <p>TestPyPI: - [ ] Upload a TestPyPI riuscito - [ ] Installazione da TestPyPI funziona - [ ] Quick test imports funzionano</p> <p>GitHub Release: - [ ] Tag <code>v2.0.0</code> creato - [ ] Release description completa - [ ] Assets allegati (tar.gz, whl, CHANGELOG) - [ ] Release pubblicata</p> <p>PyPI Production: - [ ] Upload a PyPI riuscito - [ ] Package visibile su pypi.org - [ ] Installazione <code>pip install kinetic-core==2.0.0</code> funziona - [ ] Quick test completo</p> <p>Post-Publication: - [ ] Annunci pubblicati (GitHub, social media) - [ ] Dependency in KineticMCP aggiornata - [ ] Documentation links verificati</p>"},{"location":"roadmap/KINETICMCP_UPGRADE_IMPACT/#documentation-checklist-fase-6","title":"Documentation Checklist (Fase 6)","text":"<p>KineticMCP Docs: - [ ] <code>TOOLS_REFERENCE.md</code> completo (28 tools documentati) - [ ] <code>USAGE_EXAMPLES.md</code> con esempi reali - [ ] <code>MIGRATION.md</code> con guida v1\u2192v2 - [ ] <code>CHANGELOG.md</code> completo - [ ] <code>README.md</code> aggiornato</p> <p>Guide Avanzate: - [ ] <code>BULK_API_GUIDE.md</code> per kinetic-core - [ ] <code>PERFORMANCE_GUIDE.md</code> con benchmarks - [ ] Link documentation incrociati</p> <p>Verifica Qualit\u00e0: - [ ] Tutti i code examples testati - [ ] Screenshots/output aggiornati - [ ] Links funzionanti - [ ] Grammatica/spelling corretti - [ ] Formatting consistente</p> <p>PIANO COMPLETO - READY TO EXECUTE \u2705</p>"}]}